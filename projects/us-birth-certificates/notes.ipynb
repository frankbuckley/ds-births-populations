{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T18:42:05.044762Z",
     "start_time": "2025-11-01T18:42:04.152232Z"
    }
   },
   "source": [
    "import chance\n",
    "import duckdb\n",
    "import pyarrow as pa\n",
    "import pyarrow.compute as pc\n",
    "import pandas as pd\n",
    "from graphviz import Digraph\n",
    "from fields import Fields"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Data cleaning and optimisation"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T18:42:16.032761Z",
     "start_time": "2025-11-01T18:42:05.051755Z"
    }
   },
   "cell_type": "code",
   "source": "df = pd.read_parquet(\"./data/us_births_combined.parquet\", dtype_backend=\"pyarrow\")",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T18:42:16.838470Z",
     "start_time": "2025-11-01T18:42:16.835047Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def constrain_pa_series_to_uint8(series: pd.Series, min: int = 0, max: int = 255) -> pd.Series:\n",
    "    arr = pa.array(series, type=pa.float64())\n",
    "    arr_i8 = constrain_pa_array_to_uint8(arr, min=min, max=max)\n",
    "    return pd.Series(arr_i8, dtype=\"uint8[pyarrow]\")\n",
    "\n",
    "\n",
    "def constrain_pa_series_to_uint16(series: pd.Series, min: int = 0, max: int = 65535) -> pd.Series:\n",
    "    arr = pa.array(series, type=pa.float64())\n",
    "    arr_i16 = constrain_pa_array_to_uint16(arr, min=min, max=max)\n",
    "    return pd.Series(arr_i16, dtype=\"uint16[pyarrow]\")\n",
    "\n",
    "\n",
    "def constrain_pa_array_to_uint8(arr: pa.Array, min: int = 0, max: int = 255) -> pa.Array:\n",
    "    trunc = pc.round(arr, ndigits=0, round_mode=\"towards_zero\")\n",
    "    is_finite = pc.is_finite(trunc)\n",
    "    lo = pa.scalar(min, type=pa.float64())\n",
    "    hi = pa.scalar(max, type=pa.float64())\n",
    "    ge_lo = pc.greater_equal(trunc, lo)\n",
    "    le_hi = pc.less_equal(trunc, hi)\n",
    "    in_range = pc.and_kleene(ge_lo, le_hi)\n",
    "    keep = pc.and_kleene(is_finite, in_range)\n",
    "    trunc_masked = pc.if_else(keep, trunc, pa.scalar(None, type=pa.float64()))\n",
    "    arr_i8 = pc.cast(trunc_masked, pa.uint8(), safe=False)\n",
    "    return arr_i8\n",
    "\n",
    "\n",
    "def constrain_pa_array_to_uint16(arr: pa.Array, min: int = 0, max: int = 65535) -> pa.Array:\n",
    "    trunc = pc.round(arr, ndigits=0, round_mode=\"towards_zero\")\n",
    "    is_finite = pc.is_finite(trunc)\n",
    "    lo = pa.scalar(min, type=pa.float64())\n",
    "    hi = pa.scalar(max, type=pa.float64())\n",
    "    ge_lo = pc.greater_equal(trunc, lo)\n",
    "    le_hi = pc.less_equal(trunc, hi)\n",
    "    in_range = pc.and_kleene(ge_lo, le_hi)\n",
    "    keep = pc.and_kleene(is_finite, in_range)\n",
    "    trunc_masked = pc.if_else(keep, trunc, pa.scalar(None, type=pa.float64()))\n",
    "    arr_i16 = pc.cast(trunc_masked, pa.uint16(), safe=False)\n",
    "    return arr_i16"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T18:42:47.522549Z",
     "start_time": "2025-11-01T18:42:16.932127Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df[Fields.DOB_YY] = constrain_pa_series_to_uint16(df[Fields.DOB_YY], min=1989)\n",
    "df[Fields.DOB_MM] = constrain_pa_series_to_uint8(df[Fields.DOB_MM], min=1, max=12)\n",
    "df[Fields.BFACIL] = constrain_pa_series_to_uint8(df[Fields.BFACIL], min=1, max=9)\n",
    "df[Fields.F_BFACIL] = constrain_pa_series_to_uint8(df[Fields.BFACIL], min=0, max=1)\n",
    "df[Fields.MAGE_IMPFLG] = constrain_pa_series_to_uint8(df[Fields.MAGE_IMPFLG], min=0, max=1)\n",
    "df[Fields.MAGE_REPFLG] = constrain_pa_series_to_uint8(pd.to_numeric(df[Fields.MAGE_REPFLG], errors=\"coerce\"), min=0,\n",
    "                                                      max=1)\n",
    "df[Fields.MAGER] = constrain_pa_series_to_uint8(df[Fields.MAGER], min=12, max=50)\n",
    "df[Fields.MAGER14] = constrain_pa_series_to_uint8(df[Fields.MAGER14], min=1, max=14)\n",
    "df[Fields.MAGER9] = constrain_pa_series_to_uint8(df[Fields.MAGER9], min=1, max=14)\n",
    "df[Fields.MBSTATE_REC] = constrain_pa_series_to_uint8(df[Fields.MBSTATE_REC], min=1, max=3)\n",
    "df[Fields.RESTATUS] = constrain_pa_series_to_uint8(df[Fields.RESTATUS], min=1, max=2)\n",
    "df[Fields.MRACE31] = constrain_pa_series_to_uint8(df[Fields.MRACE31], min=1, max=31)\n",
    "df[Fields.MRACE6] = constrain_pa_series_to_uint8(df[Fields.MRACE6], min=1, max=6)\n",
    "df[Fields.MRACE15] = constrain_pa_series_to_uint8(df[Fields.MRACE15], min=1, max=15)\n",
    "df[Fields.MRACEIMP] = constrain_pa_series_to_uint8(df[Fields.MRACEIMP], min=1, max=2)\n",
    "df[Fields.MHISPX] = constrain_pa_series_to_uint8(df[Fields.MHISPX], min=0, max=9)\n",
    "df[Fields.MHISP_R] = constrain_pa_series_to_uint8(df[Fields.MHISP_R], min=0, max=9)\n",
    "df[Fields.F_MHISP] = constrain_pa_series_to_uint8(df[Fields.F_MHISP], min=0, max=1)\n",
    "df[Fields.MRACEHISP] = constrain_pa_series_to_uint8(df[Fields.MRACEHISP], min=1, max=8)\n",
    "df[Fields.MAR_P] = df[Fields.MAR_P].astype(pd.ArrowDtype(pa.string()))\n",
    "df[Fields.DMAR] = df[Fields.DMAR].astype(pd.ArrowDtype(pa.string()))\n",
    "df[Fields.MAR_IMP] = df[Fields.MAR_IMP].astype(pd.ArrowDtype(pa.string()))\n",
    "df[Fields.F_MAR_P] = constrain_pa_series_to_uint8(df[Fields.F_MAR_P], min=0, max=1)\n",
    "df[Fields.MEDUC] = constrain_pa_series_to_uint8(df[Fields.MEDUC], min=1, max=9)\n",
    "df[Fields.F_MEDUC] = constrain_pa_series_to_uint8(df[Fields.F_MEDUC], min=0, max=1)\n",
    "df[Fields.FAGERPT_FLG] = df[Fields.FAGERPT_FLG].astype(pd.ArrowDtype(pa.string()))\n",
    "df[Fields.FAGECOMB] = constrain_pa_series_to_uint8(df[Fields.FAGECOMB], min=0, max=99)\n",
    "df[Fields.FAGEREC11] = constrain_pa_series_to_uint8(df[Fields.FAGEREC11], min=0, max=11)\n",
    "df[Fields.FRACE31] = constrain_pa_series_to_uint8(df[Fields.FRACE31], min=1, max=99)\n",
    "df[Fields.FRACE6] = constrain_pa_series_to_uint8(df[Fields.FRACE6], min=1, max=9)\n",
    "df[Fields.FRACE15] = constrain_pa_series_to_uint8(df[Fields.FRACE15], min=1, max=99)\n",
    "df[Fields.FHISPX] = constrain_pa_series_to_uint8(df[Fields.FHISPX], min=0, max=9)\n",
    "df[Fields.FHISP_R] = constrain_pa_series_to_uint8(df[Fields.FHISP_R], min=0, max=9)\n",
    "df[Fields.F_FHISP] = constrain_pa_series_to_uint8(df[Fields.F_FHISP], min=0, max=1)\n",
    "df[Fields.FRACEHISP] = constrain_pa_series_to_uint8(df[Fields.FRACEHISP], min=1, max=9)\n",
    "df[Fields.FEDUC] = constrain_pa_series_to_uint8(df[Fields.FEDUC], min=1, max=9)\n",
    "df[Fields.PRIORLIVE] = constrain_pa_series_to_uint8(df[Fields.PRIORLIVE], min=0, max=99)\n",
    "df[Fields.PRIORDEAD] = constrain_pa_series_to_uint8(df[Fields.PRIORDEAD], min=0, max=99)\n",
    "df[Fields.PRIORTERM] = constrain_pa_series_to_uint8(df[Fields.PRIORTERM], min=0, max=99)\n",
    "df[Fields.LBO_REC] = constrain_pa_series_to_uint8(df[Fields.LBO_REC], min=1, max=9)\n",
    "df[Fields.TBO_REC] = constrain_pa_series_to_uint8(df[Fields.TBO_REC], min=1, max=9)\n",
    "df[Fields.PRECARE] = constrain_pa_series_to_uint8(df[Fields.PRECARE], min=1, max=9)\n",
    "df[Fields.PAY] = constrain_pa_series_to_uint8(df[Fields.PAY], min=1, max=9)\n",
    "df[Fields.PAY_REC] = constrain_pa_series_to_uint8(df[Fields.PAY_REC], min=1, max=9)\n",
    "df[Fields.F_PAY] = constrain_pa_series_to_uint8(df[Fields.F_PAY], min=0, max=1)\n",
    "df[Fields.F_PAY_REC] = constrain_pa_series_to_uint8(df[Fields.F_PAY_REC], min=0, max=1)\n",
    "df[Fields.SEX] = df[Fields.SEX].astype(pd.ArrowDtype(pa.string()))\n",
    "df[Fields.CA_ANEN] = df[Fields.CA_ANEN].astype(pd.ArrowDtype(pa.string()))\n",
    "df[Fields.CA_MNSB] = df[Fields.CA_MNSB].astype(pd.ArrowDtype(pa.string()))\n",
    "df[Fields.CA_CCHD] = df[Fields.CA_CCHD].astype(pd.ArrowDtype(pa.string()))\n",
    "df[Fields.CA_CDH] = df[Fields.CA_CDH].astype(pd.ArrowDtype(pa.string()))\n",
    "df[Fields.CA_OMPH] = df[Fields.CA_OMPH].astype(pd.ArrowDtype(pa.string()))\n",
    "df[Fields.CA_GAST] = df[Fields.CA_GAST].astype(pd.ArrowDtype(pa.string()))\n",
    "df[Fields.F_CA_ANEN] = constrain_pa_series_to_uint8(df[Fields.F_CA_ANEN], min=0, max=1)\n",
    "df[Fields.F_CA_MENIN] = constrain_pa_series_to_uint8(df[Fields.F_CA_MENIN], min=0, max=1)\n",
    "df[Fields.F_CA_HEART] = constrain_pa_series_to_uint8(df[Fields.F_CA_HEART], min=0, max=1)\n",
    "df[Fields.F_CA_HERNIA] = constrain_pa_series_to_uint8(df[Fields.F_CA_HERNIA], min=0, max=1)\n",
    "df[Fields.F_CA_OMPHA] = constrain_pa_series_to_uint8(df[Fields.F_CA_OMPHA], min=0, max=1)\n",
    "df[Fields.F_CA_GASTRO] = constrain_pa_series_to_uint8(df[Fields.F_CA_GASTRO], min=0, max=1)\n",
    "df[Fields.CA_LIMB] = df[Fields.CA_LIMB].astype(pd.ArrowDtype(pa.string()))\n",
    "df[Fields.CA_CLEFT] = df[Fields.CA_CLEFT].astype(pd.ArrowDtype(pa.string()))\n",
    "df[Fields.CA_CLPAL] = df[Fields.CA_CLPAL].astype(pd.ArrowDtype(pa.string()))\n",
    "df[Fields.DOWNS] = constrain_pa_series_to_uint8(df[Fields.DOWNS], min=0, max=255)\n",
    "df[Fields.UCA_DOWNS] = constrain_pa_series_to_uint8(df[Fields.UCA_DOWNS], min=1, max=9)\n",
    "df[Fields.CA_DOWN] = df[Fields.CA_DOWN].astype(pd.ArrowDtype(pa.string()))\n",
    "df[Fields.CA_DOWNS] = df[Fields.CA_DOWNS].astype(pd.ArrowDtype(pa.string()))\n",
    "# combine CA_DOWN and CA_DOWNS into CA_DOWN_C\n",
    "df[Fields.CA_DOWN_C] = df[Fields.CA_DOWN].combine_first(df[Fields.CA_DOWNS])\n",
    "\n",
    "# note: we only have MAGER from 2004  before then there is DMAGE:\n",
    "# \"This item is: a) computed using dates of birth of mother and of delivery;\n",
    "# b) reported; or c) imputed. This is the age item used in NCHS publications\"\n",
    "df[Fields.P_DS_LB_NT] = chance.get_ds_lb_nt_probability_array(df[Fields.MAGER])\n",
    "# where"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T18:42:51.657201Z",
     "start_time": "2025-11-01T18:42:47.539672Z"
    }
   },
   "cell_type": "code",
   "source": [
    "prevalence_df = pd.DataFrame({\n",
    "    Fields.DOB_YY: list(range(1989, 2025)),\n",
    "    Fields.P_DS_LB_WT: [\n",
    "        0.001038,\n",
    "        0.001055,\n",
    "        0.001077,\n",
    "        0.001083,\n",
    "        0.001093,\n",
    "        0.001102,\n",
    "        0.001121,\n",
    "        0.001099,\n",
    "        0.001124,\n",
    "        0.001136,\n",
    "        0.001153,\n",
    "        0.001149,\n",
    "        0.001179,\n",
    "        0.001216,\n",
    "        0.001219,\n",
    "        0.001218,\n",
    "        0.001236,\n",
    "        0.001244,\n",
    "        0.001261,\n",
    "        0.001257,\n",
    "        0.001262,\n",
    "        0.001244,\n",
    "        0.00127,\n",
    "        0.001265,\n",
    "        0.001283,\n",
    "        0.001302,\n",
    "        0.001265051,\n",
    "        0.001295784,\n",
    "        0.0013375,\n",
    "        0.001324215,\n",
    "        0.001324215,\n",
    "        0.001324215,\n",
    "        0.001324215,\n",
    "        0.001324215,\n",
    "        0.001324215,\n",
    "        0.001324215,\n",
    "    ],\n",
    "})\n",
    "\n",
    "df = df.merge(prevalence_df, on=Fields.DOB_YY, how=\"left\")"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df.sort_values(Fields.DOB_YY)",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_2004 = df[df[Fields.DOB_YY] >= 2004]",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_2004[[Fields.DOB_YY, Fields.P_DS_LB_NT, Fields.P_DS_LB_WT]].groupby(Fields.DOB_YY).sum()",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df[[Fields.DOB_YY, Fields.CA_DOWNS]].groupby(Fields.DOB_YY).value_counts().unstack(fill_value=0).sort_index()",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df.dtypes",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df.to_parquet(\"./data/us_births.parquet\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_2004.to_parquet(\"./data/us_births_2004_2024.parquet\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from graphviz import Digraph\n",
    "\n",
    "dag = Digraph()\n",
    "\n",
    "dag.attr(fontname=\"Helvetica\")\n",
    "dag.attr(\"node\", fontname=\"Helvetica\")\n",
    "dag.attr(\"edge\", fontname=\"Helvetica\")\n",
    "\n",
    "# set font sizes\n",
    "dag.attr(size=\"8,6\")\n",
    "dag.attr(\"node\", fontsize=\"14\", style=\"filled\", fillcolor=\"#99ccff\")\n",
    "dag.attr(\"edge\", fontsize=\"12\")\n",
    "\n",
    "dag.attr(rankdir=\"TB\", splines=\"spline\")  # Top-to-bottom flow\n",
    "dag.attr(\"node\", shape=\"circle\", fixedsize=\"true\", width=\"1.75\")\n",
    "\n",
    "edges = [\n",
    "    ('Age', 'Case'),\n",
    "    ('Age', 'Screening'),\n",
    "    ('Age', 'Termination'),\n",
    "    ('Age', 'Income'),\n",
    "    ('Income', 'Case'),\n",
    "    ('Case', 'Termination'),\n",
    "    ('Case', 'DS birth'),\n",
    "    ('Screening', 'Termination'),\n",
    "    ('Termination', 'DS birth'),\n",
    "    ('DS birth', 'Recorded'),\n",
    "]\n",
    "\n",
    "for src, dst in edges:\n",
    "    dag.edge(src, dst)\n",
    "\n",
    "dag\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "con = duckdb.connect(database=\"./data/us_births.db\", read_only=True)",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "con.execute(\n",
    "    \"\"\"\n",
    "    SELECT dob_yy, ca_down, count(*) as counts\n",
    "    FROM us_births\n",
    "    group by dob_yy, ca_down\n",
    "    order by dob_yy, ca_down\n",
    "    \"\"\"\n",
    ").df()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_2012 = pd.read_parquet(\"./data/us_births_2012.parquet\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# counts of each value of df_2012[\"uca_downs\"]\n",
    "df_2012[\"ca_downs\"].value_counts().sort_index()"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-stats-models-ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
