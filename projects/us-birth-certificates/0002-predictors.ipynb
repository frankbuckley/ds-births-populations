{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes 2 - Predictors of recorded DS live births\n",
    "\n",
    "Next:\n",
    "\n",
    "- Review data to see if we can go back further - check race\n",
    "- Hyperparameter tuning\n",
    "- Consider bagging vs GOSS"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Preparation"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import duckdb, joblib, optuna, os, shap\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from lightgbm import early_stopping, log_evaluation\n",
    "from scipy.spatial.distance import squareform\n",
    "from scipy.cluster import hierarchy\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import average_precision_score, roc_auc_score, brier_score_loss, log_loss, precision_recall_fscore_support\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from variables import Variables as vars\n",
    "import repl_utils, stats_utils\n",
    "\n",
    "pd.options.mode.copy_on_write = True\n",
    "\n",
    "plt.style.use(\"../../notebook.mplstyle\")\n",
    "\n",
    "os.makedirs(\"./output\", exist_ok=True)\n",
    "\n",
    "RANDOM_SEED = repl_utils.RANDOM_SEED\n",
    "np.random.seed(RANDOM_SEED)\n",
    "rng = np.random.default_rng(RANDOM_SEED)\n",
    "\n",
    "N_CORES = joblib.cpu_count(only_physical_cores=True)\n",
    "START_TIME = datetime.now()\n",
    "OUTPUT_DIR = f\"output/0002-predictors/{START_TIME:%Y%m%d-%H%M%S}\"\n",
    "\n",
    "SAVE_PLOTS = True\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "repl_utils.print_environment_info()\n",
    "\n",
    "print(f\"\\n--------------------\\nOutput directory: {OUTPUT_DIR}\\n--------------------\\n\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Options"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "START_YEAR = 2005\n",
    "# LightGBM threads\n",
    "NUM_THREADS = N_CORES\n",
    "# Splitting data for training, validation and calibration\n",
    "TRAINING_SPLIT = 0.5\n",
    "VALIDATION_SPLIT = 0.25\n",
    "CALIBRATION_SPLIT = 1 - TRAINING_SPLIT - VALIDATION_SPLIT\n",
    "#\n",
    "NUM_BOOST_ROUND = 10000\n",
    "EARLY_STOPPING_ROUNDS = 50\n",
    "# True to search for hyperparameters\n",
    "SELECT_HYPERPARAMETERS = True\n",
    "#\n",
    "OPTIMIZE_TRIALS = 50"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Load data"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "con = duckdb.connect(\"./data/us_births.db\", read_only=True)\n",
    "\n",
    "df = con.execute(\n",
    "    f\"\"\"\n",
    "    SELECT\n",
    "        -- (training label) indicated if C or P, otherwise not\n",
    "        CASE\n",
    "            WHEN COALESCE (ca_down, ca_downs) = 'C' THEN 1::UTINYINT\n",
    "            WHEN COALESCE (ca_down, ca_downs) = 'P' THEN 1::UTINYINT\n",
    "            ELSE 0::UTINYINT\n",
    "        END AS ca_down_c_or_p,\n",
    "        -- ==================== date of birth ====================\n",
    "        year,\n",
    "        -- month of birth\n",
    "        dob_mm,\n",
    "        -- day of week of birth (1-7)\n",
    "        dob_wk,\n",
    "        -- time of birth (0000-2359)\n",
    "        CASE\n",
    "            WHEN dob_tt >= 0 AND dob_tt <= 2359 THEN dob_tt\n",
    "            -- we ignore \"Not stated\" as we treat this variable as numeric rather than categorical\n",
    "            ELSE NULL\n",
    "        END AS dob_tt,\n",
    "        -- ==================== birth location ====================\n",
    "        -- birth place (1: hospital, 2: not hospital, 3: unknown/not stated)\n",
    "        bfacil3,\n",
    "        -- ==================== characteristics of baby ====================\n",
    "        -- sex of baby\n",
    "        CASE\n",
    "            WHEN sex = 'M' THEN 1::UTINYINT\n",
    "            WHEN sex = 'F' THEN 0::UTINYINT\n",
    "            ELSE NULL\n",
    "        END AS sex,\n",
    "        -- birth weight (grams)\n",
    "        CASE\n",
    "            WHEN dbwt >= 227 AND dbwt <= 8165 THEN dbwt\n",
    "            -- we ignore \"Not stated\" as we treat this variable as numeric rather than categorical\n",
    "            ELSE NULL\n",
    "        END AS dbwt,\n",
    "        -- ==================== characteristics of pregnancy ====================\n",
    "        -- plurality (1: single... 4 quadpruplet or higher)\n",
    "        dplural,\n",
    "        -- month prenatal care began (1 to 10, 0: no prenatal care)\n",
    "        CASE\n",
    "            WHEN precare >= 0 AND precare <= 10 THEN precare\n",
    "            WHEN precare = 99 THEN precare\n",
    "            ELSE NULL\n",
    "        END AS precare,\n",
    "        -- combined gestation estimate\n",
    "        CASE\n",
    "            WHEN gestrec10 >= 1 AND gestrec10 <= 10 THEN gestrec10\n",
    "            WHEN gestrec10 = 99 THEN gestrec10\n",
    "            ELSE NULL\n",
    "        END AS gestrec10,\n",
    "        -- pre-pregnancy weight recode (in pounds)\n",
    "        CASE\n",
    "            WHEN pwgt_r >= 75 AND pwgt_r <= 375 THEN pwgt_r\n",
    "            -- we ignore \"Unknown or not stated\" as we treat this variable as numeric rather than categorical\n",
    "            ELSE NULL\n",
    "        END AS pwgt_r,\n",
    "        -- weight gain in pounds (98 = 98+)\n",
    "        CASE\n",
    "            WHEN wtgain >= 0 AND wtgain <= 98 THEN wtgain\n",
    "            -- we ignore \"Unknown or not stated\" as we treat this variable as numeric rather than categorical\n",
    "            ELSE NULL\n",
    "        END AS wtgain,\n",
    "        -- maternal body mass index\n",
    "        CASE\n",
    "            WHEN bmi >= 13.0 AND bmi < 69.9 THEN bmi\n",
    "            -- we ignore \"Unknown or not stated\" as we treat this variable as numeric rather than categorical\n",
    "            ELSE NULL\n",
    "        END\n",
    "        AS bmi,\n",
    "        -- ==================== pregnancy risk factors ====================\n",
    "        -- pre-pregnancy diabetes\n",
    "        CASE\n",
    "            WHEN rf_pdiab = 'Y' THEN 1::UTINYINT\n",
    "            WHEN rf_pdiab = 'N' THEN 0::UTINYINT\n",
    "            ELSE NULL\n",
    "        END AS rf_pdiab,\n",
    "        -- gestational diabetes\n",
    "        CASE\n",
    "            WHEN rf_gdiab = 'Y' THEN 1::UTINYINT\n",
    "            WHEN rf_gdiab = 'N' THEN 0::UTINYINT\n",
    "            ELSE NULL\n",
    "        END AS rf_gdiab,\n",
    "        -- pre-pregnancy hypertension\n",
    "        CASE\n",
    "            WHEN rf_phype = 'Y' THEN 1::UTINYINT\n",
    "            WHEN rf_phype = 'N' THEN 0::UTINYINT\n",
    "            ELSE NULL\n",
    "        END AS rf_phype,\n",
    "        -- gestational hypertension\n",
    "        CASE\n",
    "            WHEN rf_ghype = 'Y' THEN 1::UTINYINT\n",
    "            WHEN rf_ghype = 'N' THEN 0::UTINYINT\n",
    "            ELSE NULL\n",
    "        END AS rf_ghype,\n",
    "        -- hypertension eclampsia\n",
    "        CASE\n",
    "            WHEN rf_ehype = 'Y' THEN 1::UTINYINT\n",
    "            WHEN rf_ehype = 'N' THEN 0::UTINYINT\n",
    "            ELSE NULL\n",
    "        END AS rf_ehype,\n",
    "        -- previous preterm birth\n",
    "        CASE\n",
    "            WHEN rf_ppterm = 'Y' THEN 1::UTINYINT\n",
    "            WHEN rf_ppterm = 'N' THEN 0::UTINYINT\n",
    "            ELSE NULL\n",
    "        END AS rf_ppterm,\n",
    "        -- infertility treatment used\n",
    "        CASE\n",
    "            WHEN rf_inftr = 'Y' THEN 1::UTINYINT\n",
    "            WHEN rf_inftr = 'N' THEN 0::UTINYINT\n",
    "            ELSE NULL\n",
    "        END AS rf_inftr,\n",
    "        -- fertility enhancing drugs\n",
    "        CASE\n",
    "            WHEN rf_fedrg = 'Y' THEN 1::UTINYINT\n",
    "            WHEN rf_fedrg = 'N' THEN 0::UTINYINT\n",
    "            ELSE NULL\n",
    "        END AS rf_fedrg,\n",
    "        -- asst. reproductive technology\n",
    "        CASE\n",
    "            WHEN rf_artec = 'Y' THEN 1::UTINYINT\n",
    "            WHEN rf_artec = 'N' THEN 0::UTINYINT\n",
    "            ELSE NULL\n",
    "        END AS rf_artec,\n",
    "        -- no risk factors reported\n",
    "        CASE\n",
    "            WHEN no_risks <= 1 THEN no_risks\n",
    "            ELSE NULL\n",
    "        END AS no_risks,\n",
    "        -- ==================== labor and delivery ====================\n",
    "        -- induction of labor\n",
    "        CASE\n",
    "            WHEN ld_indl = 'Y' THEN 1::UTINYINT\n",
    "            WHEN ld_indl = 'N' THEN 0::UTINYINT\n",
    "            ELSE NULL\n",
    "        END AS ld_indl,\n",
    "        -- augmentation of labor\n",
    "        CASE\n",
    "            WHEN ld_augm = 'Y' THEN 1::UTINYINT\n",
    "            WHEN ld_augm = 'N' THEN 0::UTINYINT\n",
    "            ELSE NULL\n",
    "        END AS ld_augm,\n",
    "        -- fetal presentation at delivery\n",
    "        CASE\n",
    "            WHEN me_pres >= 1 AND me_pres <= 3 THEN me_pres\n",
    "            WHEN me_pres = 9 THEN me_pres\n",
    "            ELSE NULL\n",
    "        END AS me_pres,\n",
    "        -- delivery method recode\n",
    "        CASE\n",
    "            WHEN dmeth_rec >= 1 AND dmeth_rec <= 2 THEN dmeth_rec\n",
    "            WHEN dmeth_rec = 9 THEN dmeth_rec\n",
    "            ELSE NULL\n",
    "        END AS dmeth_rec,\n",
    "        -- ==================== newborn health ====================\n",
    "        -- five minute apgar score\n",
    "        CASE\n",
    "            WHEN apgar5 >= 10 AND apgar5 <= 10 THEN apgar5\n",
    "            WHEN apgar5 = 99 THEN apgar5\n",
    "            ELSE NULL\n",
    "        END AS apgar5,\n",
    "        -- ten minute apgar score\n",
    "        CASE\n",
    "            WHEN apgar10 >= 10 AND apgar10 <= 10 THEN apgar10\n",
    "            WHEN apgar10 = 99 THEN apgar10\n",
    "            ELSE NULL\n",
    "        END AS apgar10,\n",
    "        -- assisted ventilation (immediately)\n",
    "        CASE\n",
    "            WHEN ab_aven1 = 'Y' THEN 1::UTINYINT\n",
    "            WHEN ab_aven1 = 'N' THEN 0::UTINYINT\n",
    "            ELSE NULL\n",
    "        END AS ab_aven1,\n",
    "        -- assisted ventilation > 6 hrs\n",
    "        CASE\n",
    "            WHEN ab_aven6 = 'Y' THEN 1::UTINYINT\n",
    "            WHEN ab_aven6 = 'N' THEN 0::UTINYINT\n",
    "            ELSE NULL\n",
    "        END AS ab_aven6,\n",
    "        -- admitted to nicu\n",
    "        CASE\n",
    "            WHEN ab_nicu = 'Y' THEN 1::UTINYINT\n",
    "            WHEN ab_nicu = 'N' THEN 0::UTINYINT\n",
    "            ELSE NULL\n",
    "        END AS ab_nicu,\n",
    "        -- surfactant\n",
    "        CASE\n",
    "            WHEN ab_surf = 'Y' THEN 1::UTINYINT\n",
    "            WHEN ab_surf = 'N' THEN 0::UTINYINT\n",
    "            ELSE NULL\n",
    "        END AS ab_surf,\n",
    "        -- antibiotics for newborn\n",
    "        CASE\n",
    "            WHEN ab_anti = 'Y' THEN 1::UTINYINT\n",
    "            WHEN ab_anti = 'N' THEN 0::UTINYINT\n",
    "            ELSE NULL\n",
    "        END AS ab_anti,\n",
    "        -- seizures\n",
    "        CASE\n",
    "            WHEN ab_seiz = 'Y' THEN 1::UTINYINT\n",
    "            WHEN ab_seiz = 'N' THEN 0::UTINYINT\n",
    "            ELSE NULL\n",
    "        END AS ab_seiz,\n",
    "        -- no_abnorm\n",
    "        CASE\n",
    "            WHEN no_abnorm >= 0 AND no_abnorm <= 1 THEN no_abnorm\n",
    "            WHEN no_abnorm = 9 THEN no_abnorm\n",
    "            ELSE NULL\n",
    "        END AS no_abnorm,\n",
    "        -- ==================== identified disorders ====================\n",
    "        -- congenital disorder\n",
    "        CASE\n",
    "            WHEN ca_disor = 'C' THEN 1::UTINYINT\n",
    "            WHEN ca_disor = 'P' THEN 2::UTINYINT\n",
    "            WHEN ca_disor = 'N' THEN 0::UTINYINT\n",
    "            ELSE NULL\n",
    "        END\n",
    "        AS ca_disor,\n",
    "        -- anencephaly\n",
    "        CASE\n",
    "            WHEN ca_anen = 'Y' THEN 1::UTINYINT\n",
    "            WHEN ca_anen = 'N' THEN 0::UTINYINT\n",
    "            ELSE NULL\n",
    "        END AS ca_anen,\n",
    "        -- meningomyelocele / spina bifida\n",
    "        CASE\n",
    "            WHEN ca_mnsb = 'Y' THEN 1::UTINYINT\n",
    "            WHEN ca_mnsb = 'N' THEN 0::UTINYINT\n",
    "            ELSE NULL\n",
    "        END AS ca_mnsb,\n",
    "        -- congenital heart defect\n",
    "        CASE\n",
    "            WHEN ca_cchd = 'Y' THEN 1::UTINYINT\n",
    "            WHEN ca_cchd = 'N' THEN 0::UTINYINT\n",
    "            ELSE NULL\n",
    "        END AS ca_cchd,\n",
    "        -- ca_cdh\n",
    "        CASE\n",
    "            WHEN ca_cdh = 'Y' THEN 1::UTINYINT\n",
    "            WHEN ca_cdh = 'N' THEN 0::UTINYINT\n",
    "            ELSE NULL\n",
    "        END AS ca_cdh,\n",
    "        -- omphalocele\n",
    "        CASE\n",
    "            WHEN ca_omph = 'Y' THEN 1::UTINYINT\n",
    "            WHEN ca_omph = 'N' THEN 0::UTINYINT\n",
    "            ELSE NULL\n",
    "        END AS ca_omph,\n",
    "        -- gastroschisis\n",
    "        CASE\n",
    "            WHEN ca_gast = 'Y' THEN 1::UTINYINT\n",
    "            WHEN ca_gast = 'N' THEN 0::UTINYINT\n",
    "            ELSE NULL\n",
    "        END AS ca_gast,\n",
    "        -- limb reduction defect\n",
    "        CASE\n",
    "            WHEN ca_limb = 'Y' THEN 1::UTINYINT\n",
    "            WHEN ca_limb = 'N' THEN 0::UTINYINT\n",
    "            ELSE NULL\n",
    "        END AS ca_limb,\n",
    "        -- cleft lip w/ or w/o cleft palate\n",
    "        CASE\n",
    "            WHEN ca_cleft = 'Y' THEN 1::UTINYINT\n",
    "            WHEN ca_cleft = 'N' THEN 0::UTINYINT\n",
    "            ELSE NULL\n",
    "        END AS ca_cleft,\n",
    "        -- cleft palate alone\n",
    "        CASE\n",
    "            WHEN ca_clpal = 'Y' THEN 1::UTINYINT\n",
    "            WHEN ca_clpal = 'N' THEN 0::UTINYINT\n",
    "            ELSE NULL\n",
    "        END AS ca_clpal,\n",
    "        -- Hypospadias\n",
    "        CASE\n",
    "            WHEN ca_hypo = 'Y' THEN 1::UTINYINT\n",
    "            WHEN ca_hypo = 'N' THEN 0::UTINYINT\n",
    "            ELSE NULL\n",
    "        END AS ca_hypo,\n",
    "        -- suspected chromosomal disorder\n",
    "        CASE\n",
    "            WHEN ca_disor = 'C' THEN 1::UTINYINT\n",
    "            WHEN ca_disor = 'P' THEN 2::UTINYINT\n",
    "            WHEN ca_disor = 'N' THEN 0::UTINYINT\n",
    "            WHEN ca_disor = 'U' THEN 9::UTINYINT\n",
    "            ELSE NULL\n",
    "        END AS ca_disor,\n",
    "        -- no_congen\n",
    "        CASE\n",
    "            WHEN no_congen >= 0 AND no_congen <= 1 THEN no_congen\n",
    "            WHEN no_congen = 9 THEN no_congen\n",
    "            ELSE NULL\n",
    "        END AS no_congen,\n",
    "        -- ==================== maternal characteristics ====================\n",
    "        -- maternal age in years\n",
    "        mage_c,\n",
    "        -- maternal education\n",
    "        CASE\n",
    "            WHEN meduc >= 0 AND meduc < 10 THEN meduc\n",
    "            ELSE NULL\n",
    "        END AS meduc,\n",
    "        -- maternal race\n",
    "        CASE\n",
    "            WHEN  mracehisp >= 1 AND mracehisp <= 8 THEN mracehisp\n",
    "            ELSE NULL\n",
    "        END AS mracehisp,\n",
    "        -- ==================== paternal characteristics ====================\n",
    "        -- father's combined age in years\n",
    "        CASE\n",
    "            WHEN fagecomb >= 9 AND fagecomb < 99 THEN fagecomb\n",
    "            ELSE NULL\n",
    "        END AS fagecomb,\n",
    "        -- paternal education\n",
    "        CASE\n",
    "            WHEN  feduc < 9 THEN feduc\n",
    "            ELSE NULL\n",
    "        END AS feduc,\n",
    "        -- paternal race\n",
    "        CASE\n",
    "            WHEN  fracehisp >= 1 AND fracehisp <= 10 THEN fracehisp\n",
    "            ELSE NULL\n",
    "        END AS fracehisp,\n",
    "        -- ==================== socio-economic indicators ====================\n",
    "        -- payment source recode\n",
    "        CASE\n",
    "            WHEN  pay_rec < 5 THEN pay_rec\n",
    "            ELSE NULL\n",
    "        END AS pay_rec,\n",
    "        -- supplemental nutrition program for women, infants, and children\n",
    "        CASE\n",
    "            WHEN wic = 'Y' THEN 1::UTINYINT\n",
    "            WHEN wic = 'N' THEN 0::UTINYINT\n",
    "            ELSE NULL\n",
    "        END AS wic\n",
    "    FROM\n",
    "        us_births\n",
    "    WHERE year >= {START_YEAR}\n",
    "    ORDER BY\n",
    "        year, dob_mm\n",
    "    \"\"\"\n",
    ").df()\n",
    "\n",
    "con.close()\n",
    "\n",
    "df.describe().T"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Define initial feature set"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "numeric = [\n",
    "    \"year\",\n",
    "    \"dbwt\",\n",
    "    \"pwgt_r\",\n",
    "    \"wtgain\",\n",
    "    \"bmi\",\n",
    "    \"mage_c\",\n",
    "    \"fagecomb\",\n",
    "]\n",
    "\n",
    "categorical = [\n",
    "    \"dob_mm\",\n",
    "    \"dob_wk\",\n",
    "    \"bfacil3\",\n",
    "    \"sex\",\n",
    "    \"precare\",\n",
    "    \"gestrec10\",\n",
    "    \"rf_pdiab\",\n",
    "    \"rf_gdiab\",\n",
    "    \"rf_phype\",\n",
    "    \"rf_ghype\",\n",
    "    \"rf_ehype\",\n",
    "    \"rf_ppterm\",\n",
    "    \"rf_inftr\",\n",
    "    \"rf_fedrg\",\n",
    "    \"rf_artec\",\n",
    "    \"no_risks\",\n",
    "    \"ld_indl\",\n",
    "    \"ld_augm\",\n",
    "    \"me_pres\",\n",
    "    \"dmeth_rec\",\n",
    "    \"apgar5\",\n",
    "    \"apgar10\",\n",
    "    \"ab_aven1\",\n",
    "    \"ab_aven6\",\n",
    "    \"ab_nicu\",\n",
    "    \"ab_surf\",\n",
    "    \"ab_anti\",\n",
    "    \"ab_seiz\",\n",
    "    \"no_abnorm\",\n",
    "    \"ca_anen\",\n",
    "    \"ca_mnsb\",\n",
    "    \"ca_cchd\",\n",
    "    \"ca_cdh\",\n",
    "    \"ca_omph\",\n",
    "    \"ca_gast\",\n",
    "    \"ca_limb\",\n",
    "    \"ca_cleft\",\n",
    "    \"ca_clpal\",\n",
    "    \"ca_hypo\",\n",
    "    \"ca_disor\",\n",
    "    \"no_congen\",\n",
    "    \"meduc\",\n",
    "    \"mracehisp\",\n",
    "    \"feduc\",\n",
    "    \"fracehisp\",\n",
    "    \"pay_rec\",\n",
    "    \"wic\",\n",
    "]\n",
    "\n",
    "features = categorical + numeric\n",
    "\n",
    "X = df[features]\n",
    "y = df[\"ca_down_c_or_p\"]\n",
    "\n",
    "X[categorical] = X[categorical].astype(\"category\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": ""
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-18T18:32:28.226742800Z",
     "start_time": "2025-12-18T18:32:28.153848900Z"
    }
   },
   "cell_type": "markdown",
   "source": "### Split training, validation and calibration data"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# use half the data for the training set\n",
    "X_train, X_tmp, y_train, y_tmp = train_test_split(\n",
    "    X, y, test_size=TRAINING_SPLIT, stratify=y, random_state=RANDOM_SEED\n",
    ")\n",
    "\n",
    "# use a quarter of the data for training validation and a quarter for calibration\n",
    "X_valid, X_cal, y_valid, y_cal = train_test_split(\n",
    "    X_tmp, y_tmp, test_size=(VALIDATION_SPLIT/TRAINING_SPLIT), stratify=y_tmp, random_state=RANDOM_SEED\n",
    ")\n",
    "\n",
    "train_data = lgb.Dataset(\n",
    "    X_train,\n",
    "    label=y_train,\n",
    "    categorical_feature=categorical,\n",
    "    free_raw_data=False\n",
    ")\n",
    "\n",
    "valid_data = lgb.Dataset(\n",
    "    X_valid,\n",
    "    label=y_valid,\n",
    "    categorical_feature=categorical,\n",
    "    reference=train_data,\n",
    "    free_raw_data=False\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "neg_count_train = (y_train == 0).count()\n",
    "pos_count_train = (y_train == 1).count()\n",
    "scale_pos_weight = neg_count_train / pos_count_train\n",
    "\n",
    "base_params = {\n",
    "    \"objective\": \"binary\",\n",
    "    \"metric\": [\"average_precision\", \"binary_logloss\"],\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    \"max_bin\": 255, # common GPU-friendly values are 63/127; CPU often 255)\n",
    "\n",
    "    \"scale_pos_weight\": scale_pos_weight,\n",
    "    \"force_col_wise\": True,\n",
    "\n",
    "    \"seed\": RANDOM_SEED,\n",
    "\n",
    "    \"num_threads\": NUM_THREADS,\n",
    "    \"verbosity\": 1,\n",
    "}\n",
    "\n",
    "last_best_params = {\n",
    "    \"learning_rate\": 0.03288937496333823,\n",
    "    \"num_leaves\": 77,\n",
    "    \"min_data_in_leaf\": 1197,\n",
    "    \"min_gain_to_split\": 0.03854952333592927,\n",
    "    \"feature_fraction\": 0.9941146127703994,\n",
    "    \"bagging_fraction\": 0.7633278333686699,\n",
    "    \"bagging_freq\": 1,\n",
    "    \"lambda_l1\": 0.027645583503818516,\n",
    "    \"lambda_l2\": 13.817083262722434\n",
    "}"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-18T18:34:50.475698Z",
     "start_time": "2025-12-18T18:34:50.385061200Z"
    }
   },
   "cell_type": "markdown",
   "source": "## Hyperparameter tuning"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def objective(trial):\n",
    "    trial_params = {\n",
    "        # required to change min_data_in_leaf across trials without rebuilding the Dataset\n",
    "        \"feature_pre_filter\": False,\n",
    "\n",
    "        # Speed / stability\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.1, log=True),\n",
    "\n",
    "        # Tree complexity\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 32, 512, log=True),\n",
    "        \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 500, 25000, log=True),\n",
    "        \"min_gain_to_split\": trial.suggest_float(\"min_gain_to_split\", 0.0, 1.0),\n",
    "\n",
    "        # Sampling\n",
    "        \"feature_fraction\": trial.suggest_float(\"feature_fraction\", 0.6, 1.0),\n",
    "        \"bagging_fraction\": trial.suggest_float(\"bagging_fraction\", 0.6, 1.0),\n",
    "        \"bagging_freq\": trial.suggest_int(\"bagging_freq\", 1, 10),\n",
    "\n",
    "        # Regularization\n",
    "        \"lambda_l1\": trial.suggest_float(\"lambda_l1\", 1e-8, 10.0, log=True),\n",
    "        \"lambda_l2\": trial.suggest_float(\"lambda_l2\", 1e-8, 10.0, log=True),\n",
    "    }\n",
    "\n",
    "    # Merge: base_params always present; trial_params override if same key exists\n",
    "    params = {**base_params, **trial_params}\n",
    "\n",
    "    pruning_cb = optuna.integration.LightGBMPruningCallback(trial, \"average_precision\")\n",
    "\n",
    "    gbm = lgb.train(\n",
    "        params,\n",
    "        train_data,\n",
    "        num_boost_round=NUM_BOOST_ROUND,\n",
    "        valid_sets=[valid_data],\n",
    "        callbacks=[\n",
    "            lgb.early_stopping(stopping_rounds=EARLY_STOPPING_ROUNDS),\n",
    "            lgb.log_evaluation(period=1),\n",
    "            pruning_cb,\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    # Best score on validation\n",
    "    return gbm.best_score[\"valid_0\"][\"average_precision\"]\n",
    "\n",
    "if SELECT_HYPERPARAMETERS:\n",
    "    study = optuna.create_study(direction=\"maximize\",\n",
    "                                sampler=optuna.samplers.TPESampler(),\n",
    "                                pruner=optuna.pruners.HyperbandPruner())\n",
    "\n",
    "    study.optimize(objective, n_trials=OPTIMIZE_TRIALS)\n",
    "\n",
    "    print(study.best_params, study.best_value)\n",
    "\n",
    "    best = study.best_params\n",
    "else:\n",
    "    best = last_best_params\n",
    "\n",
    "# Merge (best overrides base if there are collisions)\n",
    "params = {**base_params, **best}\n",
    "params[\"feature_pre_filter\"] = True  # reset to default for final training\n",
    "\n",
    "print(\"Final parameters for training:\")\n",
    "for k, v in params.items():\n",
    "    print(f\"  \\\"{k}\\\": {v}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Train model"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model_idx = 0\n",
    "model_name = f\"Model {model_idx}\"\n",
    "\n",
    "gbm = lgb.train(\n",
    "    params,\n",
    "    train_data,\n",
    "    num_boost_round=NUM_BOOST_ROUND,\n",
    "    valid_sets=[train_data, valid_data],\n",
    "    valid_names=[\"train\", \"valid\"],\n",
    "    callbacks=[\n",
    "        early_stopping(stopping_rounds=EARLY_STOPPING_ROUNDS),\n",
    "        log_evaluation(period=5)\n",
    "    ]\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "best_iter = gbm.best_iteration\n",
    "gbm.save_model(f\"{OUTPUT_DIR}/model_{model_idx}_{datetime.now().strftime(\"%Y%m%d%H%M\")}.txt\", num_iteration=best_iter)\n",
    "print(\"best_iteration:\", best_iter)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Predict\n",
    "\n",
    "Produce predictions on validation set"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "y_valid_predict = gbm.predict(X_valid, num_iteration=best_iter)",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Evaluate predictions"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "y_valid_predict_auc = roc_auc_score(y_valid, y_valid_predict)\n",
    "y_valid_predict_ap  = average_precision_score(y_valid, y_valid_predict)   # this is \"average_precision\"\n",
    "y_valid_predict_ll  = log_loss(y_valid, y_valid_predict, labels=[0, 1])   # this is \"binary_logloss\"\n",
    "\n",
    "print(f\"Validation AUC:      {y_valid_predict_auc:.4f}\")\n",
    "print(f\"Validation AP:       {y_valid_predict_ap:.6f}\")\n",
    "print(f\"Validation log loss: {y_valid_predict_ll:.6f}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "auc = roc_auc_score(y_valid, y_valid_predict)\n",
    "ap  = average_precision_score(y_valid, y_valid_predict)   # this is \"average_precision\"\n",
    "ll  = log_loss(y_valid, y_valid_predict, labels=[0, 1])   # this is \"binary_logloss\"\n",
    "\n",
    "print(f\"Validation AUC:      {auc:.4f}\")\n",
    "print(f\"Validation AP:       {ap:.6f}\")\n",
    "print(f\"Validation log loss: {ll:.6f}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "importance_gain = gbm.feature_importance(importance_type=\"gain\")\n",
    "\n",
    "df_imp_gain = pd.DataFrame({\n",
    "    \"feature\": features,\n",
    "    \"importance_gain\": importance_gain\n",
    "}).sort_values(\"importance_gain\", ascending=False)\n",
    "\n",
    "df_imp_gain.to_csv(f\"{OUTPUT_DIR}/model_{model_idx}_importance_gain_{datetime.now().strftime(\"%Y%m%d%H%M\")}.csv\", index=False)\n",
    "df_imp_gain"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Feature importance"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "importance_gain = gbm.feature_importance(importance_type=\"gain\")\n",
    "\n",
    "df_imp_gain = pd.DataFrame({\n",
    "    \"feature\": features,\n",
    "    \"importance_gain\": importance_gain\n",
    "}).sort_values(\"importance_gain\", ascending=False)\n",
    "\n",
    "df_imp_gain.to_csv(f\"./output/importance_gain_{datetime.now().strftime(\"%Y%m%d%H%M\")}.csv\", index=False)\n",
    "df_imp_gain"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Evaluation subset for permutation importances and SHAP analysis"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "result = permutation_importance(\n",
    "    model_wrapped,\n",
    "    X_eval,\n",
    "    y_eval,\n",
    "    scoring=ap_scorer,\n",
    "    n_repeats=10,\n",
    "    n_jobs=NUM_THREADS,\n",
    "    random_state=RANDOM_SEED,\n",
    ")\n",
    "\n",
    "perm_importance = pd.DataFrame({\n",
    "    \"feature\": X_eval.columns,\n",
    "    \"importance_mean\": result.importances_mean,\n",
    "    \"importance_std\": result.importances_std,\n",
    "}).sort_values(\"importance_mean\", ascending=False)\n",
    "\n",
    "perm_importance.to_csv(f\"{OUTPUT_DIR}/permutation_importance_{datetime.now().strftime(\"%Y%m%d%H%M\")}.csv\", index=False)\n",
    "perm_importance"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def ap_scorer(estimator, X, y):\n",
    "    proba = estimator.predict_proba(X)[:, 1]\n",
    "    return average_precision_score(y, proba)\n",
    "\n",
    "\n",
    "class LGBMWrapper:\n",
    "    def __init__(self, booster):\n",
    "        self.booster = booster\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # Required by sklearn API; we don't actually train here.\n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        # LightGBM Booster.predict gives P(y=1) for binary by default\n",
    "        p1 = self.booster.predict(X)\n",
    "        p0 = 1.0 - p1\n",
    "        return np.column_stack([p0, p1])\n",
    "\n",
    "    def predict(self, X):\n",
    "        p1 = self.booster.predict(X)\n",
    "        return (p1 >= 0.5).astype(int)\n",
    "\n",
    "\n",
    "model_wrapped = LGBMWrapper(gbm)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "result = permutation_importance(\n",
    "    model_wrapped,\n",
    "    X_eval,\n",
    "    y_eval,\n",
    "    scoring=ap_scorer,\n",
    "    n_repeats=5,\n",
    "    n_jobs=4,\n",
    "    random_state=RANDOM_SEED,\n",
    ")\n",
    "\n",
    "perm_importance = pd.DataFrame({\n",
    "    \"feature\": X_eval.columns,\n",
    "    \"importance_mean\": result.importances_mean,\n",
    "    \"importance_std\": result.importances_std,\n",
    "}).sort_values(\"importance_mean\", ascending=False)\n",
    "\n",
    "perm_importance.to_csv(f\"./output/permutation_importance_{datetime.now().strftime(\"%Y%m%d%H%M\")}.csv\", index=False)\n",
    "perm_importance"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "# need not NA - some columns have many NAs\n",
    "distance_0, corr_0 = stats_utils.distance_corr_dissimilarity(X_eval)\n",
    "condensed_0 = squareform(distance_0, checks=True)\n",
    "dist_linkage_0 = hierarchy.ward(condensed_0)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.figure(figsize=(8, 20))\n",
    "dendro_0 = hierarchy.dendrogram(dist_linkage_0, labels=X_eval.columns.to_list(), orientation=\"right\", ax=plt.axes())\n",
    "plt.vlines(0.5, 0, 500, linestyle=\"--\", color=\"#b2b4549f\", linewidth=2)\n",
    "plt.xlabel(\"Ward linkage distance (increase in within-cluster variance)\")\n",
    "plt.ylabel(\"Predictors\")\n",
    "plt.title(f\"Model 0: Hierarchical clustering of predictors\")\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "dendro_0_idx = np.arange(0, len(dendro_0[\"ivl\"]))\n",
    "\n",
    "with plt.rc_context({'ytick.labelsize': 12, 'xtick.labelsize': 12, 'axes.titlesize': 12}):\n",
    "    plt.figure(figsize=(18, 18))\n",
    "    plt.set_cmap(\"viridis\")\n",
    "    ax = plt.axes()\n",
    "    im = ax.imshow(corr_0[dendro_0[\"leaves\"], :][:, dendro_0[\"leaves\"]])\n",
    "    ax.set_title(f\"Model: Correlation heatmap of predictors\")\n",
    "    ax.set_xticks(dendro_0_idx)\n",
    "    ax.set_yticks(dendro_0_idx)\n",
    "    ax.set_xticklabels(dendro_0[\"ivl\"], rotation=\"vertical\")\n",
    "    ax.set_yticklabels(dendro_0[\"ivl\"])\n",
    "    plt.colorbar(im, ax=ax, fraction=0.03, pad=0.025)\n",
    "    plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Tell SHAP this is a LightGBM model\n",
    "explainer = shap.TreeExplainer(gbm)\n",
    "explanation = explainer(X_eval)\n",
    "clustering_0 = shap.utils.hclust(X_eval, y_eval, linkage=\"average\", random_state=RANDOM_SEED)\n",
    "shap_values = explanation.values\n",
    "\n",
    "# Handle both cases: list or array\n",
    "if isinstance(shap_values, list):\n",
    "    shap_pos = shap_values[1]  # SHAP values for positive class\n",
    "else:\n",
    "    shap_pos = shap_values  # already positive class\n",
    "\n",
    "# Global importance: mean |SHAP|\n",
    "shap_importance = pd.DataFrame({\n",
    "    \"feature\": X_shap.columns,\n",
    "    \"mean_abs_shap\": np.mean(np.abs(shap_pos), axis=0),\n",
    "}).sort_values(\"mean_abs_shap\", ascending=False)\n",
    "\n",
    "shap_importance.to_csv(f\"{OUTPUT_DIR}/model_{model_idx}_shap_importance_{datetime.now().strftime(\"%Y%m%d%H%M\")}.csv\", index=False)\n",
    "shap_importance"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We cannot plot millions of observations, so for SHAP analysis, we take a random selection of 10,000 positives and 50,000 negatives."
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Tell SHAP this is a LightGBM model\n",
    "explainer = shap.TreeExplainer(gbm)\n",
    "explanation = explainer(X_eval)\n",
    "clustering_0 = shap.utils.hclust(X_eval, y_eval, linkage=\"average\", random_state=RANDOM_SEED)\n",
    "shap_values = explanation.values\n",
    "\n",
    "# Handle both cases: list or array\n",
    "if isinstance(shap_values, list):\n",
    "    shap_pos = shap_values[1]  # SHAP values for positive class\n",
    "else:\n",
    "    shap_pos = shap_values  # already positive class\n",
    "\n",
    "# Global importance: mean |SHAP|\n",
    "shap_importance = pd.DataFrame({\n",
    "    \"feature\": X_shap.columns,\n",
    "    \"mean_abs_shap\": np.mean(np.abs(shap_pos), axis=0),\n",
    "}).sort_values(\"mean_abs_shap\", ascending=False)\n",
    "\n",
    "shap_importance.to_csv(f\"./output/shap_importance_{datetime.now().strftime(\"%Y%m%d%H%M\")}.csv\", index=False)\n",
    "shap_importance"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "with plt.rc_context({'axes.titlesize': 12}):\n",
    "    plot = plt.figure(figsize=(8, 16))\n",
    "    ax = plot.subplots()\n",
    "    ax.set_title(f\"Model 0: SHAP values for predictor variables across all samples\")\n",
    "    shap.plots.bar(explanation, max_display=40, ax=ax) # clustering=clustering_0,"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "with plt.rc_context({'axes.titlesize': 12}):\n",
    "    plot = plt.figure()\n",
    "    ax = plot.subplots()\n",
    "    ax.set_title(f\"Model 0: SHAP values for predictor variables across all samples\")\n",
    "    shap.plots.beeswarm(explanation, max_display=40, plot_size=(12, 20))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "X_shap_fp = X_shap.astype(\"float64\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "shap.plots.scatter(explanation[:, \"year\"], color=explanation)",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Calibration"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Top-K precision (what fraction of the top K are truly positive?)\n",
    "order = np.argsort(-y_valid_predict)\n",
    "y_sorted = y_valid.to_numpy()[order]\n",
    "\n",
    "K = 100000\n",
    "precision_at_k = y_sorted[:K].mean()\n",
    "recall_at_k = y_sorted[:K].sum() / y_valid.sum()\n",
    "precision_at_k, recall_at_k\n",
    "\n",
    "print(f\"Precision at {K}: {precision_at_k}\")\n",
    "print(f\"Recall at {K}: {recall_at_k}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Precision/recall at a chosen threshold\n",
    "thr = 0.01\n",
    "y_hat = (y_valid_predict >= thr).astype(int)\n",
    "prec, rec, f1, _ = precision_recall_fscore_support(y_valid, y_hat, average=\"binary\")\n",
    "prec, rec, f1\n",
    "\n",
    "print(f\"Precision (threshold={thr}): {prec}\")\n",
    "print(f\"Recall (threshold={thr}): {rec}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Top-K precision (what fraction of the top K are truly positive?)\n",
    "order = np.argsort(-y_valid_predict)\n",
    "y_sorted = y_valid.to_numpy()[order]\n",
    "\n",
    "K = 100000\n",
    "precision_at_k = y_sorted[:K].mean()\n",
    "recall_at_k = y_sorted[:K].sum() / y_valid.sum()\n",
    "precision_at_k, recall_at_k\n",
    "\n",
    "print(f\"Precision at {K}: {precision_at_k}\")\n",
    "print(f\"Recall at {K}: {recall_at_k}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Precision/recall at a chosen threshold\n",
    "thr = 0.01\n",
    "y_hat = (y_valid_predict >= thr).astype(int)\n",
    "prec, rec, f1, _ = precision_recall_fscore_support(y_valid, y_hat, average=\"binary\")\n",
    "prec, rec, f1\n",
    "\n",
    "print(f\"Precision (threshold={thr}): {prec}\")\n",
    "print(f\"Recall (threshold={thr}): {rec}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Prediction"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def predict_proba_calibrated(gbm, calibrator, X_new, num_iteration=None):\n",
    "    p_raw = gbm.predict(X_new, num_iteration=num_iteration)\n",
    "    return calibrator.predict_proba(p_raw.reshape(-1, 1))[:, 1]\n",
    "\n",
    "# p_new = predict_proba_calibrated(gbm, calibrator, X_new, num_iteration=best_iter)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-stats-models-ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
