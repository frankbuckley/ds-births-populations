{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes 2 - Predictors of recorded DS live births\n",
    "\n",
    "Next:\n",
    "\n",
    "- Review data to see if we can go back further - check race\n",
    "- Hyperparameter tuning\n",
    "- Consider bagging vs GOSS"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Preparation"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T13:01:27.212853Z",
     "start_time": "2025-12-19T13:01:16.478410Z"
    }
   },
   "source": [
    "import duckdb, joblib, optuna, os, shap\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from lightgbm import early_stopping, log_evaluation\n",
    "from scipy.spatial.distance import squareform\n",
    "from scipy.cluster import hierarchy\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import average_precision_score, roc_auc_score, brier_score_loss, log_loss, precision_recall_fscore_support\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from variables import Variables as vars\n",
    "import repl_utils, stats_utils\n",
    "\n",
    "pd.options.mode.copy_on_write = True\n",
    "\n",
    "plt.style.use(\"../../notebook.mplstyle\")\n",
    "\n",
    "os.makedirs(\"./output\", exist_ok=True)\n",
    "\n",
    "RANDOM_SEED = repl_utils.RANDOM_SEED\n",
    "np.random.seed(RANDOM_SEED)\n",
    "rng = np.random.default_rng(RANDOM_SEED)\n",
    "\n",
    "N_CORES = joblib.cpu_count(only_physical_cores=True)\n",
    "START_TIME = datetime.now()\n",
    "OUTPUT_DIR = f\"output/0002-predictors/{START_TIME:%Y%m%d-%H%M%S}\"\n",
    "\n",
    "SAVE_PLOTS = True\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "repl_utils.print_environment_info()\n",
    "\n",
    "print(f\"\\n--------------------\\nOutput directory: {OUTPUT_DIR}\\n--------------------\\n\")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Environment Information --------------------\n",
      "date: 2025-12-19T13:01:27.184106\n",
      "platform: macOS-26.1-arm64-arm-64bit-Mach-O\n",
      "platform_version: Darwin Kernel Version 25.1.0: Mon Oct 20 19:30:01 PDT 2025; root:xnu-12377.41.6~2/RELEASE_ARM64_T6031\n",
      "cpu: arm\n",
      "cores: 16\n",
      "physical_cores: 16\n",
      "ram: 48 GB\n",
      "ram_available: 27 GB\n",
      "cuda: False\n",
      "cuda_device_count: 0\n",
      "cuda_device_0: False\n",
      "python: 3.13.11 | packaged by conda-forge | (main, Dec  6 2025, 11:28:54) [Clang 19.1.7 ]\n",
      "numpy: 2.3.5\n",
      "pandas: 2.3.3\n",
      "scipy: 1.16.3\n",
      "sklearn: 1.8.0\n",
      "pytorch: 2.9.1\n",
      "pymc: 5.26.1\n",
      "pytensor: 2.35.1\n",
      "arviz: 0.23.0\n",
      "\n",
      "--------------------\n",
      "Output directory: output/0002-predictors/20251219-130127\n",
      "--------------------\n",
      "\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Options"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T13:01:27.232309Z",
     "start_time": "2025-12-19T13:01:27.216301Z"
    }
   },
   "cell_type": "code",
   "source": [
    "START_YEAR = 2005\n",
    "# LightGBM threads\n",
    "NUM_THREADS = N_CORES\n",
    "# Splitting data for training, validation and calibration\n",
    "TRAINING_SPLIT = 0.5\n",
    "VALIDATION_SPLIT = 0.25\n",
    "CALIBRATION_SPLIT = 1 - TRAINING_SPLIT - VALIDATION_SPLIT\n",
    "#\n",
    "NUM_BOOST_ROUND = 10000\n",
    "EARLY_STOPPING_ROUNDS = 50\n",
    "# True to search for hyperparameters\n",
    "SELECT_HYPERPARAMETERS = True\n",
    "#\n",
    "OPTIMIZE_TRIALS = 50"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Load data"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T13:02:25.255143Z",
     "start_time": "2025-12-19T13:01:27.233501Z"
    }
   },
   "source": [
    "con = duckdb.connect(\"./data/us_births.db\", read_only=True)\n",
    "\n",
    "df = con.execute(\n",
    "    f\"\"\"\n",
    "    SELECT\n",
    "        -- (training label) indicated if C or P, otherwise not\n",
    "        CASE\n",
    "            WHEN COALESCE (ca_down, ca_downs) = 'C' THEN 1::UTINYINT\n",
    "            WHEN COALESCE (ca_down, ca_downs) = 'P' THEN 1::UTINYINT\n",
    "            ELSE 0::UTINYINT\n",
    "        END AS ca_down_c_or_p,\n",
    "        -- ==================== date of birth ====================\n",
    "        year,\n",
    "        -- month of birth\n",
    "        dob_mm,\n",
    "        -- day of week of birth (1-7)\n",
    "        dob_wk,\n",
    "        -- time of birth (0000-2359)\n",
    "        CASE\n",
    "            WHEN dob_tt >= 0 AND dob_tt <= 2359 THEN dob_tt\n",
    "            -- we ignore \"Not stated\" as we treat this variable as numeric rather than categorical\n",
    "            ELSE NULL\n",
    "        END AS dob_tt,\n",
    "        -- ==================== birth location ====================\n",
    "        -- birth place (1: hospital, 2: not hospital, 3: unknown/not stated)\n",
    "        bfacil3,\n",
    "        -- ==================== characteristics of baby ====================\n",
    "        -- sex of baby\n",
    "        CASE\n",
    "            WHEN sex = 'M' THEN 1::UTINYINT\n",
    "            WHEN sex = 'F' THEN 0::UTINYINT\n",
    "            ELSE NULL\n",
    "        END AS sex,\n",
    "        -- birth weight (grams)\n",
    "        CASE\n",
    "            WHEN dbwt >= 227 AND dbwt <= 8165 THEN dbwt\n",
    "            -- we ignore \"Not stated\" as we treat this variable as numeric rather than categorical\n",
    "            ELSE NULL\n",
    "        END AS dbwt,\n",
    "        -- ==================== characteristics of pregnancy ====================\n",
    "        -- plurality (1: single... 4 quadpruplet or higher)\n",
    "        dplural,\n",
    "        -- month prenatal care began (1 to 10, 0: no prenatal care)\n",
    "        CASE\n",
    "            WHEN precare >= 0 AND precare <= 10 THEN precare\n",
    "            WHEN precare = 99 THEN precare\n",
    "            ELSE NULL\n",
    "        END AS precare,\n",
    "        -- combined gestation estimate\n",
    "        CASE\n",
    "            WHEN gestrec10 >= 1 AND gestrec10 <= 10 THEN gestrec10\n",
    "            WHEN gestrec10 = 99 THEN gestrec10\n",
    "            ELSE NULL\n",
    "        END AS gestrec10,\n",
    "        -- pre-pregnancy weight recode (in pounds)\n",
    "        CASE\n",
    "            WHEN pwgt_r >= 75 AND pwgt_r <= 375 THEN pwgt_r\n",
    "            -- we ignore \"Unknown or not stated\" as we treat this variable as numeric rather than categorical\n",
    "            ELSE NULL\n",
    "        END AS pwgt_r,\n",
    "        -- weight gain in pounds (98 = 98+)\n",
    "        CASE\n",
    "            WHEN wtgain >= 0 AND wtgain <= 98 THEN wtgain\n",
    "            -- we ignore \"Unknown or not stated\" as we treat this variable as numeric rather than categorical\n",
    "            ELSE NULL\n",
    "        END AS wtgain,\n",
    "        -- maternal body mass index\n",
    "        CASE\n",
    "            WHEN bmi >= 13.0 AND bmi < 69.9 THEN bmi\n",
    "            -- we ignore \"Unknown or not stated\" as we treat this variable as numeric rather than categorical\n",
    "            ELSE NULL\n",
    "        END\n",
    "        AS bmi,\n",
    "        -- ==================== pregnancy risk factors ====================\n",
    "        -- pre-pregnancy diabetes\n",
    "        CASE\n",
    "            WHEN rf_pdiab = 'Y' THEN 1::UTINYINT\n",
    "            WHEN rf_pdiab = 'N' THEN 0::UTINYINT\n",
    "            ELSE NULL\n",
    "        END AS rf_pdiab,\n",
    "        -- gestational diabetes\n",
    "        CASE\n",
    "            WHEN rf_gdiab = 'Y' THEN 1::UTINYINT\n",
    "            WHEN rf_gdiab = 'N' THEN 0::UTINYINT\n",
    "            ELSE NULL\n",
    "        END AS rf_gdiab,\n",
    "        -- pre-pregnancy hypertension\n",
    "        CASE\n",
    "            WHEN rf_phype = 'Y' THEN 1::UTINYINT\n",
    "            WHEN rf_phype = 'N' THEN 0::UTINYINT\n",
    "            ELSE NULL\n",
    "        END AS rf_phype,\n",
    "        -- gestational hypertension\n",
    "        CASE\n",
    "            WHEN rf_ghype = 'Y' THEN 1::UTINYINT\n",
    "            WHEN rf_ghype = 'N' THEN 0::UTINYINT\n",
    "            ELSE NULL\n",
    "        END AS rf_ghype,\n",
    "        -- hypertension eclampsia\n",
    "        CASE\n",
    "            WHEN rf_ehype = 'Y' THEN 1::UTINYINT\n",
    "            WHEN rf_ehype = 'N' THEN 0::UTINYINT\n",
    "            ELSE NULL\n",
    "        END AS rf_ehype,\n",
    "        -- previous preterm birth\n",
    "        CASE\n",
    "            WHEN rf_ppterm = 'Y' THEN 1::UTINYINT\n",
    "            WHEN rf_ppterm = 'N' THEN 0::UTINYINT\n",
    "            ELSE NULL\n",
    "        END AS rf_ppterm,\n",
    "        -- infertility treatment used\n",
    "        CASE\n",
    "            WHEN rf_inftr = 'Y' THEN 1::UTINYINT\n",
    "            WHEN rf_inftr = 'N' THEN 0::UTINYINT\n",
    "            ELSE NULL\n",
    "        END AS rf_inftr,\n",
    "        -- fertility enhancing drugs\n",
    "        CASE\n",
    "            WHEN rf_fedrg = 'Y' THEN 1::UTINYINT\n",
    "            WHEN rf_fedrg = 'N' THEN 0::UTINYINT\n",
    "            ELSE NULL\n",
    "        END AS rf_fedrg,\n",
    "        -- asst. reproductive technology\n",
    "        CASE\n",
    "            WHEN rf_artec = 'Y' THEN 1::UTINYINT\n",
    "            WHEN rf_artec = 'N' THEN 0::UTINYINT\n",
    "            ELSE NULL\n",
    "        END AS rf_artec,\n",
    "        -- no risk factors reported\n",
    "        CASE\n",
    "            WHEN no_risks <= 1 THEN no_risks\n",
    "            ELSE NULL\n",
    "        END AS no_risks,\n",
    "        -- ==================== labor and delivery ====================\n",
    "        -- induction of labor\n",
    "        CASE\n",
    "            WHEN ld_indl = 'Y' THEN 1::UTINYINT\n",
    "            WHEN ld_indl = 'N' THEN 0::UTINYINT\n",
    "            ELSE NULL\n",
    "        END AS ld_indl,\n",
    "        -- augmentation of labor\n",
    "        CASE\n",
    "            WHEN ld_augm = 'Y' THEN 1::UTINYINT\n",
    "            WHEN ld_augm = 'N' THEN 0::UTINYINT\n",
    "            ELSE NULL\n",
    "        END AS ld_augm,\n",
    "        -- fetal presentation at delivery\n",
    "        CASE\n",
    "            WHEN me_pres >= 1 AND me_pres <= 3 THEN me_pres\n",
    "            WHEN me_pres = 9 THEN me_pres\n",
    "            ELSE NULL\n",
    "        END AS me_pres,\n",
    "        -- delivery method recode\n",
    "        CASE\n",
    "            WHEN dmeth_rec >= 1 AND dmeth_rec <= 2 THEN dmeth_rec\n",
    "            WHEN dmeth_rec = 9 THEN dmeth_rec\n",
    "            ELSE NULL\n",
    "        END AS dmeth_rec,\n",
    "        -- ==================== newborn health ====================\n",
    "        -- five minute apgar score\n",
    "        CASE\n",
    "            WHEN apgar5 >= 10 AND apgar5 <= 10 THEN apgar5\n",
    "            WHEN apgar5 = 99 THEN apgar5\n",
    "            ELSE NULL\n",
    "        END AS apgar5,\n",
    "        -- ten minute apgar score\n",
    "        CASE\n",
    "            WHEN apgar10 >= 10 AND apgar10 <= 10 THEN apgar10\n",
    "            WHEN apgar10 = 99 THEN apgar10\n",
    "            ELSE NULL\n",
    "        END AS apgar10,\n",
    "        -- assisted ventilation (immediately)\n",
    "        CASE\n",
    "            WHEN ab_aven1 = 'Y' THEN 1::UTINYINT\n",
    "            WHEN ab_aven1 = 'N' THEN 0::UTINYINT\n",
    "            ELSE NULL\n",
    "        END AS ab_aven1,\n",
    "        -- assisted ventilation > 6 hrs\n",
    "        CASE\n",
    "            WHEN ab_aven6 = 'Y' THEN 1::UTINYINT\n",
    "            WHEN ab_aven6 = 'N' THEN 0::UTINYINT\n",
    "            ELSE NULL\n",
    "        END AS ab_aven6,\n",
    "        -- admitted to nicu\n",
    "        CASE\n",
    "            WHEN ab_nicu = 'Y' THEN 1::UTINYINT\n",
    "            WHEN ab_nicu = 'N' THEN 0::UTINYINT\n",
    "            ELSE NULL\n",
    "        END AS ab_nicu,\n",
    "        -- surfactant\n",
    "        CASE\n",
    "            WHEN ab_surf = 'Y' THEN 1::UTINYINT\n",
    "            WHEN ab_surf = 'N' THEN 0::UTINYINT\n",
    "            ELSE NULL\n",
    "        END AS ab_surf,\n",
    "        -- antibiotics for newborn\n",
    "        CASE\n",
    "            WHEN ab_anti = 'Y' THEN 1::UTINYINT\n",
    "            WHEN ab_anti = 'N' THEN 0::UTINYINT\n",
    "            ELSE NULL\n",
    "        END AS ab_anti,\n",
    "        -- seizures\n",
    "        CASE\n",
    "            WHEN ab_seiz = 'Y' THEN 1::UTINYINT\n",
    "            WHEN ab_seiz = 'N' THEN 0::UTINYINT\n",
    "            ELSE NULL\n",
    "        END AS ab_seiz,\n",
    "        -- no_abnorm\n",
    "        CASE\n",
    "            WHEN no_abnorm >= 0 AND no_abnorm <= 1 THEN no_abnorm\n",
    "            WHEN no_abnorm = 9 THEN no_abnorm\n",
    "            ELSE NULL\n",
    "        END AS no_abnorm,\n",
    "        -- ==================== identified disorders ====================\n",
    "        -- congenital disorder\n",
    "        CASE\n",
    "            WHEN ca_disor = 'C' THEN 1::UTINYINT\n",
    "            WHEN ca_disor = 'P' THEN 2::UTINYINT\n",
    "            WHEN ca_disor = 'N' THEN 0::UTINYINT\n",
    "            ELSE NULL\n",
    "        END\n",
    "        AS ca_disor,\n",
    "        -- anencephaly\n",
    "        CASE\n",
    "            WHEN ca_anen = 'Y' THEN 1::UTINYINT\n",
    "            WHEN ca_anen = 'N' THEN 0::UTINYINT\n",
    "            ELSE NULL\n",
    "        END AS ca_anen,\n",
    "        -- meningomyelocele / spina bifida\n",
    "        CASE\n",
    "            WHEN ca_mnsb = 'Y' THEN 1::UTINYINT\n",
    "            WHEN ca_mnsb = 'N' THEN 0::UTINYINT\n",
    "            ELSE NULL\n",
    "        END AS ca_mnsb,\n",
    "        -- congenital heart defect\n",
    "        CASE\n",
    "            WHEN ca_cchd = 'Y' THEN 1::UTINYINT\n",
    "            WHEN ca_cchd = 'N' THEN 0::UTINYINT\n",
    "            ELSE NULL\n",
    "        END AS ca_cchd,\n",
    "        -- ca_cdh\n",
    "        CASE\n",
    "            WHEN ca_cdh = 'Y' THEN 1::UTINYINT\n",
    "            WHEN ca_cdh = 'N' THEN 0::UTINYINT\n",
    "            ELSE NULL\n",
    "        END AS ca_cdh,\n",
    "        -- omphalocele\n",
    "        CASE\n",
    "            WHEN ca_omph = 'Y' THEN 1::UTINYINT\n",
    "            WHEN ca_omph = 'N' THEN 0::UTINYINT\n",
    "            ELSE NULL\n",
    "        END AS ca_omph,\n",
    "        -- gastroschisis\n",
    "        CASE\n",
    "            WHEN ca_gast = 'Y' THEN 1::UTINYINT\n",
    "            WHEN ca_gast = 'N' THEN 0::UTINYINT\n",
    "            ELSE NULL\n",
    "        END AS ca_gast,\n",
    "        -- limb reduction defect\n",
    "        CASE\n",
    "            WHEN ca_limb = 'Y' THEN 1::UTINYINT\n",
    "            WHEN ca_limb = 'N' THEN 0::UTINYINT\n",
    "            ELSE NULL\n",
    "        END AS ca_limb,\n",
    "        -- cleft lip w/ or w/o cleft palate\n",
    "        CASE\n",
    "            WHEN ca_cleft = 'Y' THEN 1::UTINYINT\n",
    "            WHEN ca_cleft = 'N' THEN 0::UTINYINT\n",
    "            ELSE NULL\n",
    "        END AS ca_cleft,\n",
    "        -- cleft palate alone\n",
    "        CASE\n",
    "            WHEN ca_clpal = 'Y' THEN 1::UTINYINT\n",
    "            WHEN ca_clpal = 'N' THEN 0::UTINYINT\n",
    "            ELSE NULL\n",
    "        END AS ca_clpal,\n",
    "        -- Hypospadias\n",
    "        CASE\n",
    "            WHEN ca_hypo = 'Y' THEN 1::UTINYINT\n",
    "            WHEN ca_hypo = 'N' THEN 0::UTINYINT\n",
    "            ELSE NULL\n",
    "        END AS ca_hypo,\n",
    "        -- suspected chromosomal disorder\n",
    "        CASE\n",
    "            WHEN ca_disor = 'C' THEN 1::UTINYINT\n",
    "            WHEN ca_disor = 'P' THEN 2::UTINYINT\n",
    "            WHEN ca_disor = 'N' THEN 0::UTINYINT\n",
    "            WHEN ca_disor = 'U' THEN 9::UTINYINT\n",
    "            ELSE NULL\n",
    "        END AS ca_disor,\n",
    "        -- no_congen\n",
    "        CASE\n",
    "            WHEN no_congen >= 0 AND no_congen <= 1 THEN no_congen\n",
    "            WHEN no_congen = 9 THEN no_congen\n",
    "            ELSE NULL\n",
    "        END AS no_congen,\n",
    "        -- ==================== maternal characteristics ====================\n",
    "        -- maternal age in years\n",
    "        mage_c,\n",
    "        -- maternal education\n",
    "        CASE\n",
    "            WHEN meduc >= 0 AND meduc < 10 THEN meduc\n",
    "            ELSE NULL\n",
    "        END AS meduc,\n",
    "        -- maternal race\n",
    "        CASE\n",
    "            WHEN  mracehisp >= 1 AND mracehisp <= 8 THEN mracehisp\n",
    "            ELSE NULL\n",
    "        END AS mracehisp,\n",
    "        -- ==================== paternal characteristics ====================\n",
    "        -- father's combined age in years\n",
    "        CASE\n",
    "            WHEN fagecomb >= 9 AND fagecomb < 99 THEN fagecomb\n",
    "            ELSE NULL\n",
    "        END AS fagecomb,\n",
    "        -- paternal education\n",
    "        CASE\n",
    "            WHEN  feduc < 9 THEN feduc\n",
    "            ELSE NULL\n",
    "        END AS feduc,\n",
    "        -- paternal race\n",
    "        CASE\n",
    "            WHEN  fracehisp >= 1 AND fracehisp <= 10 THEN fracehisp\n",
    "            ELSE NULL\n",
    "        END AS fracehisp,\n",
    "        -- ==================== socio-economic indicators ====================\n",
    "        -- payment source recode\n",
    "        CASE\n",
    "            WHEN  pay_rec < 5 THEN pay_rec\n",
    "            ELSE NULL\n",
    "        END AS pay_rec,\n",
    "        -- supplemental nutrition program for women, infants, and children\n",
    "        CASE\n",
    "            WHEN wic = 'Y' THEN 1::UTINYINT\n",
    "            WHEN wic = 'N' THEN 0::UTINYINT\n",
    "            ELSE NULL\n",
    "        END AS wic\n",
    "    FROM\n",
    "        us_births\n",
    "    WHERE year >= {START_YEAR}\n",
    "    ORDER BY\n",
    "        year, dob_mm\n",
    "    \"\"\"\n",
    ").df()\n",
    "\n",
    "con.close()\n",
    "\n",
    "df.describe().T"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1e90df92ae604ff9a16a235ce0dd1f1e"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "                     count         mean         std     min       25%     50%  \\\n",
       "ca_down_c_or_p  78581860.0     0.000434    0.020823     0.0       0.0     0.0   \n",
       "year            78581860.0   2014.19568     5.75756  2005.0    2009.0  2014.0   \n",
       "dob_mm          78581860.0     6.571376    3.418062     1.0       4.0     7.0   \n",
       "dob_wk          78581860.0     4.054093    1.842871     1.0       3.0     4.0   \n",
       "dob_tt           5054384.0   124.158803   82.184388     0.0      42.0   125.0   \n",
       "bfacil3         78581860.0     1.015508    0.124006     1.0       1.0     1.0   \n",
       "sex             78581860.0     0.511617    0.499865     0.0       0.0     1.0   \n",
       "dbwt            78506158.0  3260.970673  590.929803   227.0    2960.0  3300.0   \n",
       "dplural         78581121.0     1.034801     0.19004     1.0       1.0     1.0   \n",
       "precare         63557749.0     2.968252    1.546547     0.0       2.0     3.0   \n",
       "gestrec10       78581860.0     6.882924    2.854185     1.0       6.0     7.0   \n",
       "pwgt_r          56215443.0   158.140336   41.525609    75.0     130.0   150.0   \n",
       "wtgain          74195599.0    30.044682   14.982298     0.0      20.0    30.0   \n",
       "bmi             55942900.0     27.00655    6.697317    13.0  22.09375    25.5   \n",
       "rf_pdiab        41309903.0     0.010083    0.099907     0.0       0.0     0.0   \n",
       "rf_gdiab        41309903.0     0.070505    0.255996     0.0       0.0     0.0   \n",
       "rf_phype        41309903.0     0.023261     0.15073     0.0       0.0     0.0   \n",
       "rf_ghype        41309903.0     0.077344    0.267136     0.0       0.0     0.0   \n",
       "rf_ehype        41309903.0     0.002593    0.050851     0.0       0.0     0.0   \n",
       "rf_ppterm       64811117.0     0.030056    0.170742     0.0       0.0     0.0   \n",
       "rf_inftr        57624765.0     0.018476    0.134664     0.0       0.0     0.0   \n",
       "rf_fedrg          976909.0     0.430225    0.495108     0.0       0.0     0.0   \n",
       "rf_artec          976907.0     0.658157    0.474328     0.0       0.0     1.0   \n",
       "no_risks        28091903.0          1.0         0.0     1.0       1.0     1.0   \n",
       "ld_indl         64860473.0     0.266853    0.442315     0.0       0.0     0.0   \n",
       "ld_augm         64863257.0     0.208139    0.405976     0.0       0.0     0.0   \n",
       "me_pres         64970310.0     1.197347    1.038569     1.0       1.0     1.0   \n",
       "dmeth_rec       74436246.0     1.334077    0.557768     1.0       1.0     1.0   \n",
       "apgar5           3745206.0    45.208578   43.519191    10.0      10.0    10.0   \n",
       "apgar10           310336.0     97.32431   12.096651    10.0      99.0    99.0   \n",
       "ab_aven1        66041991.0     0.045419    0.208221     0.0       0.0     0.0   \n",
       "ab_aven6        66041993.0     0.013953    0.117298     0.0       0.0     0.0   \n",
       "ab_nicu         66041989.0       0.0844    0.277986     0.0       0.0     0.0   \n",
       "ab_surf         66041994.0     0.004411    0.066266     0.0       0.0     0.0   \n",
       "ab_anti         66041996.0     0.020306    0.141047     0.0       0.0     0.0   \n",
       "ab_seiz         66041995.0     0.000332    0.018224     0.0       0.0     0.0   \n",
       "no_abnorm       41430115.0     0.897862    0.448168     0.0       1.0     1.0   \n",
       "ca_disor        65977842.0     0.000714    0.035985     0.0       0.0     0.0   \n",
       "ca_anen         65977842.0     0.000103    0.010171     0.0       0.0     0.0   \n",
       "ca_mnsb         65977842.0     0.000145    0.012046     0.0       0.0     0.0   \n",
       "ca_cchd         65977842.0     0.000639    0.025277     0.0       0.0     0.0   \n",
       "ca_cdh          65977842.0      0.00013    0.011413     0.0       0.0     0.0   \n",
       "ca_omph         65977842.0     0.000096    0.009805     0.0       0.0     0.0   \n",
       "ca_gast         65977842.0     0.000243      0.0156     0.0       0.0     0.0   \n",
       "ca_limb         65977842.0     0.000134    0.011574     0.0       0.0     0.0   \n",
       "ca_cleft        65977842.0     0.000524    0.022882     0.0       0.0     0.0   \n",
       "ca_clpal        65977842.0     0.000229    0.015139     0.0       0.0     0.0   \n",
       "ca_hypo         65977842.0     0.000559    0.023633     0.0       0.0     0.0   \n",
       "ca_disor_1      66245328.0     0.037052    0.571822     0.0       0.0     0.0   \n",
       "no_congen       41285308.0     0.996552    0.058616     0.0       1.0     1.0   \n",
       "mage_c          78581860.0    28.394808    6.008326    12.0      24.0    28.0   \n",
       "meduc           66245328.0     4.296159    1.830862     1.0       3.0     4.0   \n",
       "mracehisp       78113765.0     4.084233    2.626037     1.0       1.0     6.0   \n",
       "fagecomb        58224393.0    31.381278    6.888958     9.0      27.0    31.0   \n",
       "feduc           49500198.0     4.202125    1.762679     1.0       3.0     4.0   \n",
       "fracehisp       78381253.0     4.657397    2.899511     1.0       1.0     6.0   \n",
       "pay_rec         57160229.0     1.699689    0.736063     1.0       1.0     2.0   \n",
       "wic             56806073.0     0.386459    0.486938     0.0       0.0     0.0   \n",
       "\n",
       "                     75%     max  \n",
       "ca_down_c_or_p       0.0     1.0  \n",
       "year              2019.0  2024.0  \n",
       "dob_mm               9.0    12.0  \n",
       "dob_wk               6.0     7.0  \n",
       "dob_tt             210.0   255.0  \n",
       "bfacil3              1.0     3.0  \n",
       "sex                  1.0     1.0  \n",
       "dbwt              3629.0  8165.0  \n",
       "dplural              1.0     4.0  \n",
       "precare              3.0    10.0  \n",
       "gestrec10            8.0    99.0  \n",
       "pwgt_r             180.0   375.0  \n",
       "wtgain              39.0    98.0  \n",
       "bmi             30.40625  69.875  \n",
       "rf_pdiab             0.0     1.0  \n",
       "rf_gdiab             0.0     1.0  \n",
       "rf_phype             0.0     1.0  \n",
       "rf_ghype             0.0     1.0  \n",
       "rf_ehype             0.0     1.0  \n",
       "rf_ppterm            0.0     1.0  \n",
       "rf_inftr             0.0     1.0  \n",
       "rf_fedrg             1.0     1.0  \n",
       "rf_artec             1.0     1.0  \n",
       "no_risks             1.0     1.0  \n",
       "ld_indl              1.0     1.0  \n",
       "ld_augm              0.0     1.0  \n",
       "me_pres              1.0     9.0  \n",
       "dmeth_rec            2.0     9.0  \n",
       "apgar5              99.0    99.0  \n",
       "apgar10             99.0    99.0  \n",
       "ab_aven1             0.0     1.0  \n",
       "ab_aven6             0.0     1.0  \n",
       "ab_nicu              0.0     1.0  \n",
       "ab_surf              0.0     1.0  \n",
       "ab_anti              0.0     1.0  \n",
       "ab_seiz              0.0     1.0  \n",
       "no_abnorm            1.0     9.0  \n",
       "ca_disor             0.0     2.0  \n",
       "ca_anen              0.0     1.0  \n",
       "ca_mnsb              0.0     1.0  \n",
       "ca_cchd              0.0     1.0  \n",
       "ca_cdh               0.0     1.0  \n",
       "ca_omph              0.0     1.0  \n",
       "ca_gast              0.0     1.0  \n",
       "ca_limb              0.0     1.0  \n",
       "ca_cleft             0.0     1.0  \n",
       "ca_clpal             0.0     1.0  \n",
       "ca_hypo              0.0     1.0  \n",
       "ca_disor_1           0.0     9.0  \n",
       "no_congen            1.0     1.0  \n",
       "mage_c              33.0    50.0  \n",
       "meduc                6.0     9.0  \n",
       "mracehisp            6.0     8.0  \n",
       "fagecomb            36.0    98.0  \n",
       "feduc                6.0     8.0  \n",
       "fracehisp            7.0     9.0  \n",
       "pay_rec              2.0     4.0  \n",
       "wic                  1.0     1.0  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ca_down_c_or_p</th>\n",
       "      <td>78581860.0</td>\n",
       "      <td>0.000434</td>\n",
       "      <td>0.020823</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <td>78581860.0</td>\n",
       "      <td>2014.19568</td>\n",
       "      <td>5.75756</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>2024.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dob_mm</th>\n",
       "      <td>78581860.0</td>\n",
       "      <td>6.571376</td>\n",
       "      <td>3.418062</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dob_wk</th>\n",
       "      <td>78581860.0</td>\n",
       "      <td>4.054093</td>\n",
       "      <td>1.842871</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dob_tt</th>\n",
       "      <td>5054384.0</td>\n",
       "      <td>124.158803</td>\n",
       "      <td>82.184388</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>255.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bfacil3</th>\n",
       "      <td>78581860.0</td>\n",
       "      <td>1.015508</td>\n",
       "      <td>0.124006</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex</th>\n",
       "      <td>78581860.0</td>\n",
       "      <td>0.511617</td>\n",
       "      <td>0.499865</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dbwt</th>\n",
       "      <td>78506158.0</td>\n",
       "      <td>3260.970673</td>\n",
       "      <td>590.929803</td>\n",
       "      <td>227.0</td>\n",
       "      <td>2960.0</td>\n",
       "      <td>3300.0</td>\n",
       "      <td>3629.0</td>\n",
       "      <td>8165.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dplural</th>\n",
       "      <td>78581121.0</td>\n",
       "      <td>1.034801</td>\n",
       "      <td>0.19004</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precare</th>\n",
       "      <td>63557749.0</td>\n",
       "      <td>2.968252</td>\n",
       "      <td>1.546547</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gestrec10</th>\n",
       "      <td>78581860.0</td>\n",
       "      <td>6.882924</td>\n",
       "      <td>2.854185</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pwgt_r</th>\n",
       "      <td>56215443.0</td>\n",
       "      <td>158.140336</td>\n",
       "      <td>41.525609</td>\n",
       "      <td>75.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>375.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wtgain</th>\n",
       "      <td>74195599.0</td>\n",
       "      <td>30.044682</td>\n",
       "      <td>14.982298</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>98.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bmi</th>\n",
       "      <td>55942900.0</td>\n",
       "      <td>27.00655</td>\n",
       "      <td>6.697317</td>\n",
       "      <td>13.0</td>\n",
       "      <td>22.09375</td>\n",
       "      <td>25.5</td>\n",
       "      <td>30.40625</td>\n",
       "      <td>69.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_pdiab</th>\n",
       "      <td>41309903.0</td>\n",
       "      <td>0.010083</td>\n",
       "      <td>0.099907</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_gdiab</th>\n",
       "      <td>41309903.0</td>\n",
       "      <td>0.070505</td>\n",
       "      <td>0.255996</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_phype</th>\n",
       "      <td>41309903.0</td>\n",
       "      <td>0.023261</td>\n",
       "      <td>0.15073</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_ghype</th>\n",
       "      <td>41309903.0</td>\n",
       "      <td>0.077344</td>\n",
       "      <td>0.267136</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_ehype</th>\n",
       "      <td>41309903.0</td>\n",
       "      <td>0.002593</td>\n",
       "      <td>0.050851</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_ppterm</th>\n",
       "      <td>64811117.0</td>\n",
       "      <td>0.030056</td>\n",
       "      <td>0.170742</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_inftr</th>\n",
       "      <td>57624765.0</td>\n",
       "      <td>0.018476</td>\n",
       "      <td>0.134664</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_fedrg</th>\n",
       "      <td>976909.0</td>\n",
       "      <td>0.430225</td>\n",
       "      <td>0.495108</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_artec</th>\n",
       "      <td>976907.0</td>\n",
       "      <td>0.658157</td>\n",
       "      <td>0.474328</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no_risks</th>\n",
       "      <td>28091903.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ld_indl</th>\n",
       "      <td>64860473.0</td>\n",
       "      <td>0.266853</td>\n",
       "      <td>0.442315</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ld_augm</th>\n",
       "      <td>64863257.0</td>\n",
       "      <td>0.208139</td>\n",
       "      <td>0.405976</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>me_pres</th>\n",
       "      <td>64970310.0</td>\n",
       "      <td>1.197347</td>\n",
       "      <td>1.038569</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dmeth_rec</th>\n",
       "      <td>74436246.0</td>\n",
       "      <td>1.334077</td>\n",
       "      <td>0.557768</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>apgar5</th>\n",
       "      <td>3745206.0</td>\n",
       "      <td>45.208578</td>\n",
       "      <td>43.519191</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>apgar10</th>\n",
       "      <td>310336.0</td>\n",
       "      <td>97.32431</td>\n",
       "      <td>12.096651</td>\n",
       "      <td>10.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ab_aven1</th>\n",
       "      <td>66041991.0</td>\n",
       "      <td>0.045419</td>\n",
       "      <td>0.208221</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ab_aven6</th>\n",
       "      <td>66041993.0</td>\n",
       "      <td>0.013953</td>\n",
       "      <td>0.117298</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ab_nicu</th>\n",
       "      <td>66041989.0</td>\n",
       "      <td>0.0844</td>\n",
       "      <td>0.277986</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ab_surf</th>\n",
       "      <td>66041994.0</td>\n",
       "      <td>0.004411</td>\n",
       "      <td>0.066266</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ab_anti</th>\n",
       "      <td>66041996.0</td>\n",
       "      <td>0.020306</td>\n",
       "      <td>0.141047</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ab_seiz</th>\n",
       "      <td>66041995.0</td>\n",
       "      <td>0.000332</td>\n",
       "      <td>0.018224</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no_abnorm</th>\n",
       "      <td>41430115.0</td>\n",
       "      <td>0.897862</td>\n",
       "      <td>0.448168</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca_disor</th>\n",
       "      <td>65977842.0</td>\n",
       "      <td>0.000714</td>\n",
       "      <td>0.035985</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca_anen</th>\n",
       "      <td>65977842.0</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>0.010171</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca_mnsb</th>\n",
       "      <td>65977842.0</td>\n",
       "      <td>0.000145</td>\n",
       "      <td>0.012046</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca_cchd</th>\n",
       "      <td>65977842.0</td>\n",
       "      <td>0.000639</td>\n",
       "      <td>0.025277</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca_cdh</th>\n",
       "      <td>65977842.0</td>\n",
       "      <td>0.00013</td>\n",
       "      <td>0.011413</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca_omph</th>\n",
       "      <td>65977842.0</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>0.009805</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca_gast</th>\n",
       "      <td>65977842.0</td>\n",
       "      <td>0.000243</td>\n",
       "      <td>0.0156</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca_limb</th>\n",
       "      <td>65977842.0</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>0.011574</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca_cleft</th>\n",
       "      <td>65977842.0</td>\n",
       "      <td>0.000524</td>\n",
       "      <td>0.022882</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca_clpal</th>\n",
       "      <td>65977842.0</td>\n",
       "      <td>0.000229</td>\n",
       "      <td>0.015139</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca_hypo</th>\n",
       "      <td>65977842.0</td>\n",
       "      <td>0.000559</td>\n",
       "      <td>0.023633</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca_disor_1</th>\n",
       "      <td>66245328.0</td>\n",
       "      <td>0.037052</td>\n",
       "      <td>0.571822</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no_congen</th>\n",
       "      <td>41285308.0</td>\n",
       "      <td>0.996552</td>\n",
       "      <td>0.058616</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mage_c</th>\n",
       "      <td>78581860.0</td>\n",
       "      <td>28.394808</td>\n",
       "      <td>6.008326</td>\n",
       "      <td>12.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meduc</th>\n",
       "      <td>66245328.0</td>\n",
       "      <td>4.296159</td>\n",
       "      <td>1.830862</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mracehisp</th>\n",
       "      <td>78113765.0</td>\n",
       "      <td>4.084233</td>\n",
       "      <td>2.626037</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fagecomb</th>\n",
       "      <td>58224393.0</td>\n",
       "      <td>31.381278</td>\n",
       "      <td>6.888958</td>\n",
       "      <td>9.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>98.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feduc</th>\n",
       "      <td>49500198.0</td>\n",
       "      <td>4.202125</td>\n",
       "      <td>1.762679</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fracehisp</th>\n",
       "      <td>78381253.0</td>\n",
       "      <td>4.657397</td>\n",
       "      <td>2.899511</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pay_rec</th>\n",
       "      <td>57160229.0</td>\n",
       "      <td>1.699689</td>\n",
       "      <td>0.736063</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wic</th>\n",
       "      <td>56806073.0</td>\n",
       "      <td>0.386459</td>\n",
       "      <td>0.486938</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Define initial feature set"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T13:02:35.833280Z",
     "start_time": "2025-12-19T13:02:25.357179Z"
    }
   },
   "source": [
    "numeric = [\n",
    "    \"year\",\n",
    "    \"dbwt\",\n",
    "    \"pwgt_r\",\n",
    "    \"wtgain\",\n",
    "    \"bmi\",\n",
    "    \"mage_c\",\n",
    "    \"fagecomb\",\n",
    "]\n",
    "\n",
    "categorical = [\n",
    "    \"dob_mm\",\n",
    "    \"dob_wk\",\n",
    "    \"bfacil3\",\n",
    "    \"sex\",\n",
    "    \"precare\",\n",
    "    \"gestrec10\",\n",
    "    \"rf_pdiab\",\n",
    "    \"rf_gdiab\",\n",
    "    \"rf_phype\",\n",
    "    \"rf_ghype\",\n",
    "    \"rf_ehype\",\n",
    "    \"rf_ppterm\",\n",
    "    \"rf_inftr\",\n",
    "    \"rf_fedrg\",\n",
    "    \"rf_artec\",\n",
    "    \"no_risks\",\n",
    "    \"ld_indl\",\n",
    "    \"ld_augm\",\n",
    "    \"me_pres\",\n",
    "    \"dmeth_rec\",\n",
    "    \"apgar5\",\n",
    "    \"apgar10\",\n",
    "    \"ab_aven1\",\n",
    "    \"ab_aven6\",\n",
    "    \"ab_nicu\",\n",
    "    \"ab_surf\",\n",
    "    \"ab_anti\",\n",
    "    \"ab_seiz\",\n",
    "    \"no_abnorm\",\n",
    "    \"ca_anen\",\n",
    "    \"ca_mnsb\",\n",
    "    \"ca_cchd\",\n",
    "    \"ca_cdh\",\n",
    "    \"ca_omph\",\n",
    "    \"ca_gast\",\n",
    "    \"ca_limb\",\n",
    "    \"ca_cleft\",\n",
    "    \"ca_clpal\",\n",
    "    \"ca_hypo\",\n",
    "    \"ca_disor\",\n",
    "    \"no_congen\",\n",
    "    \"meduc\",\n",
    "    \"mracehisp\",\n",
    "    \"feduc\",\n",
    "    \"fracehisp\",\n",
    "    \"pay_rec\",\n",
    "    \"wic\",\n",
    "]\n",
    "\n",
    "features = categorical + numeric\n",
    "\n",
    "X = df[features]\n",
    "y = df[\"ca_down_c_or_p\"]\n",
    "\n",
    "X[categorical] = X[categorical].astype(\"category\")"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": ""
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-18T18:32:28.226742800Z",
     "start_time": "2025-12-18T18:32:28.153848900Z"
    }
   },
   "cell_type": "markdown",
   "source": "### Split training, validation and calibration data"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T13:03:22.547384Z",
     "start_time": "2025-12-19T13:02:36.037737Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# use half the data for the training set\n",
    "X_train, X_tmp, y_train, y_tmp = train_test_split(\n",
    "    X, y, test_size=TRAINING_SPLIT, stratify=y, random_state=RANDOM_SEED\n",
    ")\n",
    "\n",
    "# use a quarter of the data for training validation and a quarter for calibration\n",
    "X_valid, X_cal, y_valid, y_cal = train_test_split(\n",
    "    X_tmp, y_tmp, test_size=(VALIDATION_SPLIT/TRAINING_SPLIT), stratify=y_tmp, random_state=RANDOM_SEED\n",
    ")\n",
    "\n",
    "train_data = lgb.Dataset(\n",
    "    X_train,\n",
    "    label=y_train,\n",
    "    categorical_feature=categorical,\n",
    "    free_raw_data=False\n",
    ")\n",
    "\n",
    "valid_data = lgb.Dataset(\n",
    "    X_valid,\n",
    "    label=y_valid,\n",
    "    categorical_feature=categorical,\n",
    "    reference=train_data,\n",
    "    free_raw_data=False\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T13:03:22.616798Z",
     "start_time": "2025-12-19T13:03:22.565075Z"
    }
   },
   "cell_type": "code",
   "source": [
    "neg_count_train = (y_train == 0).count()\n",
    "pos_count_train = (y_train == 1).count()\n",
    "scale_pos_weight = neg_count_train / pos_count_train\n",
    "\n",
    "base_params = {\n",
    "    \"objective\": \"binary\",\n",
    "    \"metric\": [\"average_precision\", \"binary_logloss\"],\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    \"max_bin\": 255, # common GPU-friendly values are 63/127; CPU often 255)\n",
    "\n",
    "    \"scale_pos_weight\": scale_pos_weight,\n",
    "    \"force_col_wise\": True,\n",
    "\n",
    "    \"seed\": RANDOM_SEED,\n",
    "\n",
    "    \"num_threads\": NUM_THREADS,\n",
    "    \"verbosity\": 1,\n",
    "}\n",
    "\n",
    "last_best_params = {\n",
    "    \"learning_rate\": 0.03288937496333823,\n",
    "    \"num_leaves\": 77,\n",
    "    \"min_data_in_leaf\": 1197,\n",
    "    \"min_gain_to_split\": 0.03854952333592927,\n",
    "    \"feature_fraction\": 0.9941146127703994,\n",
    "    \"bagging_fraction\": 0.7633278333686699,\n",
    "    \"bagging_freq\": 1,\n",
    "    \"lambda_l1\": 0.027645583503818516,\n",
    "    \"lambda_l2\": 13.817083262722434\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-18T18:34:50.475698Z",
     "start_time": "2025-12-18T18:34:50.385061200Z"
    }
   },
   "cell_type": "markdown",
   "source": "## Hyperparameter tuning"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-12-19T13:03:22.617775Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def objective(trial):\n",
    "    trial_params = {\n",
    "        # Speed / stability\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.1, log=True),\n",
    "\n",
    "        # Tree complexity\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 32, 512, log=True),\n",
    "        \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 500, 25000, log=True),\n",
    "        \"min_gain_to_split\": trial.suggest_float(\"min_gain_to_split\", 0.0, 1.0),\n",
    "\n",
    "        # Sampling\n",
    "        \"feature_fraction\": trial.suggest_float(\"feature_fraction\", 0.6, 1.0),\n",
    "        \"bagging_fraction\": trial.suggest_float(\"bagging_fraction\", 0.6, 1.0),\n",
    "        \"bagging_freq\": trial.suggest_int(\"bagging_freq\", 1, 10),\n",
    "\n",
    "        # Regularization\n",
    "        \"lambda_l1\": trial.suggest_float(\"lambda_l1\", 1e-8, 10.0, log=True),\n",
    "        \"lambda_l2\": trial.suggest_float(\"lambda_l2\", 1e-8, 10.0, log=True),\n",
    "    }\n",
    "\n",
    "    # Merge: base_params always present; trial_params override if same key exists\n",
    "    params = {**base_params, **trial_params}\n",
    "\n",
    "    pruning_cb = optuna.integration.LightGBMPruningCallback(trial, \"average_precision\")\n",
    "\n",
    "    gbm = lgb.train(\n",
    "        params,\n",
    "        train_data,\n",
    "        num_boost_round=NUM_BOOST_ROUND,\n",
    "        valid_sets=[valid_data],\n",
    "        callbacks=[\n",
    "            lgb.early_stopping(stopping_rounds=EARLY_STOPPING_ROUNDS),\n",
    "            lgb.log_evaluation(period=1),\n",
    "            pruning_cb,\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    # Best score on validation\n",
    "    return gbm.best_score[\"valid_0\"][\"average_precision\"]\n",
    "\n",
    "if SELECT_HYPERPARAMETERS:\n",
    "    study = optuna.create_study(direction=\"maximize\",\n",
    "                                sampler=optuna.samplers.TPESampler(),\n",
    "                                pruner=optuna.pruners.HyperbandPruner())\n",
    "\n",
    "    study.optimize(objective, n_trials=OPTIMIZE_TRIALS)\n",
    "\n",
    "    print(study.best_params, study.best_value)\n",
    "\n",
    "    best = study.best_params\n",
    "else:\n",
    "    best = last_best_params\n",
    "\n",
    "# Merge (best overrides base if there are collisions)\n",
    "params = {**base_params, **best}"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-19 13:03:22,621] A new study created in memory with name: no-name-8447308d-3baf-4559-a6ba-b50a6c3a5e8d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 17044, number of negative: 39273886\n",
      "[LightGBM] [Info] Total Bins 1181\n",
      "[LightGBM] [Info] Number of data points in the train set: 39290930, number of used features: 54\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000434 -> initscore=-7.742517\n",
      "[LightGBM] [Info] Start training from score -7.742517\n",
      "[1]\tvalid_0's average_precision: 0.240827\tvalid_0's binary_logloss: 0.00297655\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[2]\tvalid_0's average_precision: 0.32665\tvalid_0's binary_logloss: 0.00283343\n",
      "[3]\tvalid_0's average_precision: 0.355048\tvalid_0's binary_logloss: 0.0027373\n",
      "[4]\tvalid_0's average_precision: 0.355173\tvalid_0's binary_logloss: 0.00266571\n",
      "[5]\tvalid_0's average_precision: 0.361562\tvalid_0's binary_logloss: 0.00261077\n",
      "[6]\tvalid_0's average_precision: 0.382777\tvalid_0's binary_logloss: 0.00257111\n",
      "[7]\tvalid_0's average_precision: 0.392831\tvalid_0's binary_logloss: 0.00252176\n",
      "[8]\tvalid_0's average_precision: 0.393593\tvalid_0's binary_logloss: 0.00248326\n",
      "[9]\tvalid_0's average_precision: 0.397885\tvalid_0's binary_logloss: 0.0024404\n",
      "[10]\tvalid_0's average_precision: 0.399179\tvalid_0's binary_logloss: 0.00240519\n",
      "[11]\tvalid_0's average_precision: 0.39939\tvalid_0's binary_logloss: 0.00237281\n",
      "[12]\tvalid_0's average_precision: 0.399291\tvalid_0's binary_logloss: 0.00233954\n",
      "[13]\tvalid_0's average_precision: 0.440888\tvalid_0's binary_logloss: 0.00229668\n",
      "[14]\tvalid_0's average_precision: 0.447718\tvalid_0's binary_logloss: 0.00226176\n",
      "[15]\tvalid_0's average_precision: 0.446556\tvalid_0's binary_logloss: 0.00223374\n",
      "[16]\tvalid_0's average_precision: 0.454108\tvalid_0's binary_logloss: 0.00220301\n",
      "[17]\tvalid_0's average_precision: 0.454177\tvalid_0's binary_logloss: 0.00217764\n",
      "[18]\tvalid_0's average_precision: 0.454943\tvalid_0's binary_logloss: 0.00215488\n",
      "[19]\tvalid_0's average_precision: 0.45399\tvalid_0's binary_logloss: 0.00213358\n",
      "[20]\tvalid_0's average_precision: 0.457802\tvalid_0's binary_logloss: 0.00211066\n",
      "[21]\tvalid_0's average_precision: 0.459943\tvalid_0's binary_logloss: 0.00208904\n",
      "[22]\tvalid_0's average_precision: 0.464052\tvalid_0's binary_logloss: 0.00206873\n",
      "[23]\tvalid_0's average_precision: 0.469579\tvalid_0's binary_logloss: 0.00204929\n",
      "[24]\tvalid_0's average_precision: 0.476101\tvalid_0's binary_logloss: 0.00203075\n",
      "[25]\tvalid_0's average_precision: 0.484765\tvalid_0's binary_logloss: 0.00201147\n",
      "[26]\tvalid_0's average_precision: 0.493235\tvalid_0's binary_logloss: 0.00199302\n",
      "[27]\tvalid_0's average_precision: 0.500214\tvalid_0's binary_logloss: 0.00197642\n",
      "[28]\tvalid_0's average_precision: 0.509009\tvalid_0's binary_logloss: 0.0019594\n",
      "[29]\tvalid_0's average_precision: 0.512358\tvalid_0's binary_logloss: 0.00194559\n",
      "[30]\tvalid_0's average_precision: 0.523118\tvalid_0's binary_logloss: 0.0019287\n",
      "[31]\tvalid_0's average_precision: 0.529781\tvalid_0's binary_logloss: 0.00191458\n",
      "[32]\tvalid_0's average_precision: 0.54113\tvalid_0's binary_logloss: 0.00189881\n",
      "[33]\tvalid_0's average_precision: 0.552525\tvalid_0's binary_logloss: 0.00188397\n",
      "[34]\tvalid_0's average_precision: 0.563846\tvalid_0's binary_logloss: 0.00186988\n",
      "[35]\tvalid_0's average_precision: 0.571002\tvalid_0's binary_logloss: 0.00185682\n",
      "[36]\tvalid_0's average_precision: 0.576795\tvalid_0's binary_logloss: 0.00184465\n",
      "[37]\tvalid_0's average_precision: 0.587174\tvalid_0's binary_logloss: 0.00183072\n",
      "[38]\tvalid_0's average_precision: 0.590851\tvalid_0's binary_logloss: 0.00181837\n",
      "[39]\tvalid_0's average_precision: 0.594307\tvalid_0's binary_logloss: 0.00180662\n",
      "[40]\tvalid_0's average_precision: 0.597796\tvalid_0's binary_logloss: 0.00179601\n",
      "[41]\tvalid_0's average_precision: 0.600155\tvalid_0's binary_logloss: 0.00178496\n",
      "[42]\tvalid_0's average_precision: 0.602163\tvalid_0's binary_logloss: 0.00177427\n",
      "[43]\tvalid_0's average_precision: 0.604593\tvalid_0's binary_logloss: 0.00176335\n",
      "[44]\tvalid_0's average_precision: 0.607046\tvalid_0's binary_logloss: 0.00175451\n",
      "[45]\tvalid_0's average_precision: 0.609527\tvalid_0's binary_logloss: 0.00174564\n",
      "[46]\tvalid_0's average_precision: 0.610441\tvalid_0's binary_logloss: 0.0017373\n",
      "[47]\tvalid_0's average_precision: 0.61377\tvalid_0's binary_logloss: 0.0017269\n",
      "[48]\tvalid_0's average_precision: 0.615541\tvalid_0's binary_logloss: 0.00171833\n",
      "[49]\tvalid_0's average_precision: 0.617869\tvalid_0's binary_logloss: 0.00171002\n",
      "[50]\tvalid_0's average_precision: 0.619137\tvalid_0's binary_logloss: 0.00170136\n",
      "[51]\tvalid_0's average_precision: 0.620009\tvalid_0's binary_logloss: 0.00169295\n",
      "[52]\tvalid_0's average_precision: 0.620763\tvalid_0's binary_logloss: 0.00168456\n",
      "[53]\tvalid_0's average_precision: 0.621857\tvalid_0's binary_logloss: 0.00167591\n",
      "[54]\tvalid_0's average_precision: 0.622419\tvalid_0's binary_logloss: 0.00166761\n",
      "[55]\tvalid_0's average_precision: 0.622892\tvalid_0's binary_logloss: 0.00166004\n",
      "[56]\tvalid_0's average_precision: 0.624165\tvalid_0's binary_logloss: 0.00165214\n",
      "[57]\tvalid_0's average_precision: 0.624388\tvalid_0's binary_logloss: 0.0016448\n",
      "[58]\tvalid_0's average_precision: 0.625072\tvalid_0's binary_logloss: 0.00163718\n",
      "[59]\tvalid_0's average_precision: 0.625543\tvalid_0's binary_logloss: 0.00163037\n",
      "[60]\tvalid_0's average_precision: 0.625805\tvalid_0's binary_logloss: 0.00162289\n",
      "[61]\tvalid_0's average_precision: 0.625898\tvalid_0's binary_logloss: 0.00161581\n",
      "[62]\tvalid_0's average_precision: 0.625877\tvalid_0's binary_logloss: 0.00160981\n",
      "[63]\tvalid_0's average_precision: 0.626006\tvalid_0's binary_logloss: 0.00160279\n",
      "[64]\tvalid_0's average_precision: 0.626642\tvalid_0's binary_logloss: 0.0015952\n",
      "[65]\tvalid_0's average_precision: 0.626743\tvalid_0's binary_logloss: 0.00158926\n",
      "[66]\tvalid_0's average_precision: 0.626815\tvalid_0's binary_logloss: 0.00158392\n",
      "[67]\tvalid_0's average_precision: 0.626951\tvalid_0's binary_logloss: 0.00157685\n",
      "[68]\tvalid_0's average_precision: 0.627048\tvalid_0's binary_logloss: 0.00157083\n",
      "[69]\tvalid_0's average_precision: 0.627173\tvalid_0's binary_logloss: 0.00156432\n",
      "[70]\tvalid_0's average_precision: 0.627221\tvalid_0's binary_logloss: 0.00155831\n",
      "[71]\tvalid_0's average_precision: 0.627356\tvalid_0's binary_logloss: 0.00155106\n",
      "[72]\tvalid_0's average_precision: 0.627375\tvalid_0's binary_logloss: 0.00154566\n",
      "[73]\tvalid_0's average_precision: 0.627468\tvalid_0's binary_logloss: 0.00153989\n",
      "[74]\tvalid_0's average_precision: 0.627513\tvalid_0's binary_logloss: 0.00153373\n",
      "[75]\tvalid_0's average_precision: 0.62758\tvalid_0's binary_logloss: 0.00152821\n",
      "[76]\tvalid_0's average_precision: 0.627693\tvalid_0's binary_logloss: 0.001524\n",
      "[77]\tvalid_0's average_precision: 0.627678\tvalid_0's binary_logloss: 0.00151933\n",
      "[78]\tvalid_0's average_precision: 0.627701\tvalid_0's binary_logloss: 0.00151508\n",
      "[79]\tvalid_0's average_precision: 0.627756\tvalid_0's binary_logloss: 0.00151002\n",
      "[80]\tvalid_0's average_precision: 0.627753\tvalid_0's binary_logloss: 0.00150529\n",
      "[81]\tvalid_0's average_precision: 0.627808\tvalid_0's binary_logloss: 0.00149973\n",
      "[82]\tvalid_0's average_precision: 0.627927\tvalid_0's binary_logloss: 0.0014959\n",
      "[83]\tvalid_0's average_precision: 0.627984\tvalid_0's binary_logloss: 0.00149074\n",
      "[84]\tvalid_0's average_precision: 0.628052\tvalid_0's binary_logloss: 0.00148567\n",
      "[85]\tvalid_0's average_precision: 0.628114\tvalid_0's binary_logloss: 0.00148127\n",
      "[86]\tvalid_0's average_precision: 0.628167\tvalid_0's binary_logloss: 0.00147717\n",
      "[87]\tvalid_0's average_precision: 0.628157\tvalid_0's binary_logloss: 0.00147334\n",
      "[88]\tvalid_0's average_precision: 0.628231\tvalid_0's binary_logloss: 0.00146915\n",
      "[89]\tvalid_0's average_precision: 0.628305\tvalid_0's binary_logloss: 0.00146488\n",
      "[90]\tvalid_0's average_precision: 0.628359\tvalid_0's binary_logloss: 0.00146173\n",
      "[91]\tvalid_0's average_precision: 0.628392\tvalid_0's binary_logloss: 0.00145773\n",
      "[92]\tvalid_0's average_precision: 0.628504\tvalid_0's binary_logloss: 0.0014534\n",
      "[93]\tvalid_0's average_precision: 0.62862\tvalid_0's binary_logloss: 0.00144903\n",
      "[94]\tvalid_0's average_precision: 0.628645\tvalid_0's binary_logloss: 0.00144577\n",
      "[95]\tvalid_0's average_precision: 0.628888\tvalid_0's binary_logloss: 0.00144263\n",
      "[96]\tvalid_0's average_precision: 0.628983\tvalid_0's binary_logloss: 0.00143942\n",
      "[97]\tvalid_0's average_precision: 0.629198\tvalid_0's binary_logloss: 0.00143659\n",
      "[98]\tvalid_0's average_precision: 0.629315\tvalid_0's binary_logloss: 0.00143303\n",
      "[99]\tvalid_0's average_precision: 0.629413\tvalid_0's binary_logloss: 0.00142997\n",
      "[100]\tvalid_0's average_precision: 0.629494\tvalid_0's binary_logloss: 0.00142666\n",
      "[101]\tvalid_0's average_precision: 0.629529\tvalid_0's binary_logloss: 0.00142406\n",
      "[102]\tvalid_0's average_precision: 0.629648\tvalid_0's binary_logloss: 0.0014212\n",
      "[103]\tvalid_0's average_precision: 0.629784\tvalid_0's binary_logloss: 0.00141801\n",
      "[104]\tvalid_0's average_precision: 0.629919\tvalid_0's binary_logloss: 0.00141547\n",
      "[105]\tvalid_0's average_precision: 0.6301\tvalid_0's binary_logloss: 0.00141206\n",
      "[106]\tvalid_0's average_precision: 0.630314\tvalid_0's binary_logloss: 0.00140861\n",
      "[107]\tvalid_0's average_precision: 0.630445\tvalid_0's binary_logloss: 0.00140559\n",
      "[108]\tvalid_0's average_precision: 0.630572\tvalid_0's binary_logloss: 0.00140305\n",
      "[109]\tvalid_0's average_precision: 0.630701\tvalid_0's binary_logloss: 0.00140009\n",
      "[110]\tvalid_0's average_precision: 0.630826\tvalid_0's binary_logloss: 0.00139754\n",
      "[111]\tvalid_0's average_precision: 0.630993\tvalid_0's binary_logloss: 0.00139496\n",
      "[112]\tvalid_0's average_precision: 0.631223\tvalid_0's binary_logloss: 0.00139127\n",
      "[113]\tvalid_0's average_precision: 0.631397\tvalid_0's binary_logloss: 0.00138815\n",
      "[114]\tvalid_0's average_precision: 0.631727\tvalid_0's binary_logloss: 0.00138568\n",
      "[115]\tvalid_0's average_precision: 0.632076\tvalid_0's binary_logloss: 0.00138321\n",
      "[116]\tvalid_0's average_precision: 0.632351\tvalid_0's binary_logloss: 0.00138\n",
      "[117]\tvalid_0's average_precision: 0.632644\tvalid_0's binary_logloss: 0.00137783\n",
      "[118]\tvalid_0's average_precision: 0.632846\tvalid_0's binary_logloss: 0.0013751\n",
      "[119]\tvalid_0's average_precision: 0.633013\tvalid_0's binary_logloss: 0.00137275\n",
      "[120]\tvalid_0's average_precision: 0.63315\tvalid_0's binary_logloss: 0.00137057\n",
      "[121]\tvalid_0's average_precision: 0.633399\tvalid_0's binary_logloss: 0.00136856\n",
      "[122]\tvalid_0's average_precision: 0.633609\tvalid_0's binary_logloss: 0.00136632\n",
      "[123]\tvalid_0's average_precision: 0.633847\tvalid_0's binary_logloss: 0.00136384\n",
      "[124]\tvalid_0's average_precision: 0.634079\tvalid_0's binary_logloss: 0.00136191\n",
      "[125]\tvalid_0's average_precision: 0.63424\tvalid_0's binary_logloss: 0.00135939\n",
      "[126]\tvalid_0's average_precision: 0.634463\tvalid_0's binary_logloss: 0.00135662\n",
      "[127]\tvalid_0's average_precision: 0.634601\tvalid_0's binary_logloss: 0.00135464\n",
      "[128]\tvalid_0's average_precision: 0.634789\tvalid_0's binary_logloss: 0.00135246\n",
      "[129]\tvalid_0's average_precision: 0.634995\tvalid_0's binary_logloss: 0.00135026\n",
      "[130]\tvalid_0's average_precision: 0.635195\tvalid_0's binary_logloss: 0.00134804\n",
      "[131]\tvalid_0's average_precision: 0.635371\tvalid_0's binary_logloss: 0.00134591\n",
      "[132]\tvalid_0's average_precision: 0.635551\tvalid_0's binary_logloss: 0.00134382\n",
      "[133]\tvalid_0's average_precision: 0.635849\tvalid_0's binary_logloss: 0.00134189\n",
      "[134]\tvalid_0's average_precision: 0.636112\tvalid_0's binary_logloss: 0.00134017\n",
      "[135]\tvalid_0's average_precision: 0.636346\tvalid_0's binary_logloss: 0.00133783\n",
      "[136]\tvalid_0's average_precision: 0.63652\tvalid_0's binary_logloss: 0.00133591\n",
      "[137]\tvalid_0's average_precision: 0.636667\tvalid_0's binary_logloss: 0.00133372\n",
      "[138]\tvalid_0's average_precision: 0.636893\tvalid_0's binary_logloss: 0.00133171\n",
      "[139]\tvalid_0's average_precision: 0.637111\tvalid_0's binary_logloss: 0.00132979\n",
      "[140]\tvalid_0's average_precision: 0.63733\tvalid_0's binary_logloss: 0.00132764\n",
      "[141]\tvalid_0's average_precision: 0.637434\tvalid_0's binary_logloss: 0.00132619\n",
      "[142]\tvalid_0's average_precision: 0.637629\tvalid_0's binary_logloss: 0.00132426\n",
      "[143]\tvalid_0's average_precision: 0.637857\tvalid_0's binary_logloss: 0.00132244\n",
      "[144]\tvalid_0's average_precision: 0.638065\tvalid_0's binary_logloss: 0.00132067\n",
      "[145]\tvalid_0's average_precision: 0.638243\tvalid_0's binary_logloss: 0.00131873\n",
      "[146]\tvalid_0's average_precision: 0.638395\tvalid_0's binary_logloss: 0.00131701\n",
      "[147]\tvalid_0's average_precision: 0.638602\tvalid_0's binary_logloss: 0.00131593\n",
      "[148]\tvalid_0's average_precision: 0.638746\tvalid_0's binary_logloss: 0.00131446\n",
      "[149]\tvalid_0's average_precision: 0.638965\tvalid_0's binary_logloss: 0.00131268\n",
      "[150]\tvalid_0's average_precision: 0.63918\tvalid_0's binary_logloss: 0.00131102\n",
      "[151]\tvalid_0's average_precision: 0.639419\tvalid_0's binary_logloss: 0.00130935\n",
      "[152]\tvalid_0's average_precision: 0.639661\tvalid_0's binary_logloss: 0.00130771\n",
      "[153]\tvalid_0's average_precision: 0.639842\tvalid_0's binary_logloss: 0.00130643\n",
      "[154]\tvalid_0's average_precision: 0.640044\tvalid_0's binary_logloss: 0.00130488\n",
      "[155]\tvalid_0's average_precision: 0.64023\tvalid_0's binary_logloss: 0.00130351\n",
      "[156]\tvalid_0's average_precision: 0.640408\tvalid_0's binary_logloss: 0.0013024\n",
      "[157]\tvalid_0's average_precision: 0.640585\tvalid_0's binary_logloss: 0.00130114\n",
      "[158]\tvalid_0's average_precision: 0.640807\tvalid_0's binary_logloss: 0.00129985\n",
      "[159]\tvalid_0's average_precision: 0.641037\tvalid_0's binary_logloss: 0.00129848\n",
      "[160]\tvalid_0's average_precision: 0.641303\tvalid_0's binary_logloss: 0.00129723\n",
      "[161]\tvalid_0's average_precision: 0.641484\tvalid_0's binary_logloss: 0.00129604\n",
      "[162]\tvalid_0's average_precision: 0.641679\tvalid_0's binary_logloss: 0.00129504\n",
      "[163]\tvalid_0's average_precision: 0.641829\tvalid_0's binary_logloss: 0.00129399\n",
      "[164]\tvalid_0's average_precision: 0.641984\tvalid_0's binary_logloss: 0.00129287\n",
      "[165]\tvalid_0's average_precision: 0.642197\tvalid_0's binary_logloss: 0.00129185\n",
      "[166]\tvalid_0's average_precision: 0.642336\tvalid_0's binary_logloss: 0.00129124\n",
      "[167]\tvalid_0's average_precision: 0.642568\tvalid_0's binary_logloss: 0.00129003\n",
      "[168]\tvalid_0's average_precision: 0.642822\tvalid_0's binary_logloss: 0.00128874\n",
      "[169]\tvalid_0's average_precision: 0.643009\tvalid_0's binary_logloss: 0.00128768\n",
      "[170]\tvalid_0's average_precision: 0.643186\tvalid_0's binary_logloss: 0.00128662\n",
      "[171]\tvalid_0's average_precision: 0.643416\tvalid_0's binary_logloss: 0.0012854\n",
      "[172]\tvalid_0's average_precision: 0.643628\tvalid_0's binary_logloss: 0.00128444\n",
      "[173]\tvalid_0's average_precision: 0.643818\tvalid_0's binary_logloss: 0.00128331\n",
      "[174]\tvalid_0's average_precision: 0.644029\tvalid_0's binary_logloss: 0.00128223\n",
      "[175]\tvalid_0's average_precision: 0.644279\tvalid_0's binary_logloss: 0.00128102\n",
      "[176]\tvalid_0's average_precision: 0.644487\tvalid_0's binary_logloss: 0.00127992\n",
      "[177]\tvalid_0's average_precision: 0.644723\tvalid_0's binary_logloss: 0.00127876\n",
      "[178]\tvalid_0's average_precision: 0.644908\tvalid_0's binary_logloss: 0.00127779\n",
      "[179]\tvalid_0's average_precision: 0.645089\tvalid_0's binary_logloss: 0.0012769\n",
      "[180]\tvalid_0's average_precision: 0.645324\tvalid_0's binary_logloss: 0.00127581\n",
      "[181]\tvalid_0's average_precision: 0.645538\tvalid_0's binary_logloss: 0.00127482\n",
      "[182]\tvalid_0's average_precision: 0.645747\tvalid_0's binary_logloss: 0.00127384\n",
      "[183]\tvalid_0's average_precision: 0.645976\tvalid_0's binary_logloss: 0.00127281\n",
      "[184]\tvalid_0's average_precision: 0.646134\tvalid_0's binary_logloss: 0.00127229\n",
      "[185]\tvalid_0's average_precision: 0.646261\tvalid_0's binary_logloss: 0.00127151\n",
      "[186]\tvalid_0's average_precision: 0.646464\tvalid_0's binary_logloss: 0.0012706\n",
      "[187]\tvalid_0's average_precision: 0.64666\tvalid_0's binary_logloss: 0.00126986\n",
      "[188]\tvalid_0's average_precision: 0.646832\tvalid_0's binary_logloss: 0.00126922\n",
      "[189]\tvalid_0's average_precision: 0.646985\tvalid_0's binary_logloss: 0.00126844\n",
      "[190]\tvalid_0's average_precision: 0.647156\tvalid_0's binary_logloss: 0.00126762\n",
      "[191]\tvalid_0's average_precision: 0.64731\tvalid_0's binary_logloss: 0.00126687\n",
      "[192]\tvalid_0's average_precision: 0.647467\tvalid_0's binary_logloss: 0.00126611\n",
      "[193]\tvalid_0's average_precision: 0.64764\tvalid_0's binary_logloss: 0.00126547\n",
      "[194]\tvalid_0's average_precision: 0.647821\tvalid_0's binary_logloss: 0.00126479\n",
      "[195]\tvalid_0's average_precision: 0.647995\tvalid_0's binary_logloss: 0.00126404\n",
      "[196]\tvalid_0's average_precision: 0.64813\tvalid_0's binary_logloss: 0.00126337\n",
      "[197]\tvalid_0's average_precision: 0.648232\tvalid_0's binary_logloss: 0.00126283\n",
      "[198]\tvalid_0's average_precision: 0.648408\tvalid_0's binary_logloss: 0.00126208\n",
      "[199]\tvalid_0's average_precision: 0.648536\tvalid_0's binary_logloss: 0.00126144\n",
      "[200]\tvalid_0's average_precision: 0.648673\tvalid_0's binary_logloss: 0.00126076\n",
      "[201]\tvalid_0's average_precision: 0.648819\tvalid_0's binary_logloss: 0.00126034\n",
      "[202]\tvalid_0's average_precision: 0.648956\tvalid_0's binary_logloss: 0.0012599\n",
      "[203]\tvalid_0's average_precision: 0.649016\tvalid_0's binary_logloss: 0.00125929\n",
      "[204]\tvalid_0's average_precision: 0.64915\tvalid_0's binary_logloss: 0.00125891\n",
      "[205]\tvalid_0's average_precision: 0.649305\tvalid_0's binary_logloss: 0.0012583\n",
      "[206]\tvalid_0's average_precision: 0.64943\tvalid_0's binary_logloss: 0.00125765\n",
      "[207]\tvalid_0's average_precision: 0.649522\tvalid_0's binary_logloss: 0.00125684\n",
      "[208]\tvalid_0's average_precision: 0.649631\tvalid_0's binary_logloss: 0.00125627\n",
      "[209]\tvalid_0's average_precision: 0.649779\tvalid_0's binary_logloss: 0.00125562\n",
      "[210]\tvalid_0's average_precision: 0.64988\tvalid_0's binary_logloss: 0.00125508\n",
      "[211]\tvalid_0's average_precision: 0.649975\tvalid_0's binary_logloss: 0.00125476\n",
      "[212]\tvalid_0's average_precision: 0.65007\tvalid_0's binary_logloss: 0.00125428\n",
      "[213]\tvalid_0's average_precision: 0.65016\tvalid_0's binary_logloss: 0.00125381\n",
      "[214]\tvalid_0's average_precision: 0.650215\tvalid_0's binary_logloss: 0.00125324\n",
      "[215]\tvalid_0's average_precision: 0.650292\tvalid_0's binary_logloss: 0.00125265\n",
      "[216]\tvalid_0's average_precision: 0.650392\tvalid_0's binary_logloss: 0.00125235\n",
      "[217]\tvalid_0's average_precision: 0.650473\tvalid_0's binary_logloss: 0.00125174\n",
      "[218]\tvalid_0's average_precision: 0.650553\tvalid_0's binary_logloss: 0.00125111\n",
      "[219]\tvalid_0's average_precision: 0.650641\tvalid_0's binary_logloss: 0.00125069\n",
      "[220]\tvalid_0's average_precision: 0.650735\tvalid_0's binary_logloss: 0.00125024\n",
      "[221]\tvalid_0's average_precision: 0.65086\tvalid_0's binary_logloss: 0.0012499\n",
      "[222]\tvalid_0's average_precision: 0.650936\tvalid_0's binary_logloss: 0.00124949\n",
      "[223]\tvalid_0's average_precision: 0.651041\tvalid_0's binary_logloss: 0.00124914\n",
      "[224]\tvalid_0's average_precision: 0.651137\tvalid_0's binary_logloss: 0.00124874\n",
      "[225]\tvalid_0's average_precision: 0.651228\tvalid_0's binary_logloss: 0.00124834\n",
      "[226]\tvalid_0's average_precision: 0.651296\tvalid_0's binary_logloss: 0.00124797\n",
      "[227]\tvalid_0's average_precision: 0.651392\tvalid_0's binary_logloss: 0.00124753\n",
      "[228]\tvalid_0's average_precision: 0.651471\tvalid_0's binary_logloss: 0.00124717\n",
      "[229]\tvalid_0's average_precision: 0.651585\tvalid_0's binary_logloss: 0.00124645\n",
      "[230]\tvalid_0's average_precision: 0.65165\tvalid_0's binary_logloss: 0.0012459\n",
      "[231]\tvalid_0's average_precision: 0.651728\tvalid_0's binary_logloss: 0.00124539\n",
      "[232]\tvalid_0's average_precision: 0.651794\tvalid_0's binary_logloss: 0.00124498\n",
      "[233]\tvalid_0's average_precision: 0.651861\tvalid_0's binary_logloss: 0.00124463\n",
      "[234]\tvalid_0's average_precision: 0.651939\tvalid_0's binary_logloss: 0.00124415\n",
      "[235]\tvalid_0's average_precision: 0.65202\tvalid_0's binary_logloss: 0.00124361\n",
      "[236]\tvalid_0's average_precision: 0.652075\tvalid_0's binary_logloss: 0.00124313\n",
      "[237]\tvalid_0's average_precision: 0.652155\tvalid_0's binary_logloss: 0.00124253\n",
      "[238]\tvalid_0's average_precision: 0.652246\tvalid_0's binary_logloss: 0.00124226\n",
      "[239]\tvalid_0's average_precision: 0.652271\tvalid_0's binary_logloss: 0.00124196\n",
      "[240]\tvalid_0's average_precision: 0.652328\tvalid_0's binary_logloss: 0.00124151\n",
      "[241]\tvalid_0's average_precision: 0.652378\tvalid_0's binary_logloss: 0.00124128\n",
      "[242]\tvalid_0's average_precision: 0.65245\tvalid_0's binary_logloss: 0.00124093\n",
      "[243]\tvalid_0's average_precision: 0.652482\tvalid_0's binary_logloss: 0.00124062\n",
      "[244]\tvalid_0's average_precision: 0.652573\tvalid_0's binary_logloss: 0.00124028\n",
      "[245]\tvalid_0's average_precision: 0.65265\tvalid_0's binary_logloss: 0.00123991\n",
      "[246]\tvalid_0's average_precision: 0.652721\tvalid_0's binary_logloss: 0.00123957\n",
      "[247]\tvalid_0's average_precision: 0.652793\tvalid_0's binary_logloss: 0.00123907\n",
      "[248]\tvalid_0's average_precision: 0.652858\tvalid_0's binary_logloss: 0.00123861\n",
      "[249]\tvalid_0's average_precision: 0.652923\tvalid_0's binary_logloss: 0.00123818\n",
      "[250]\tvalid_0's average_precision: 0.652995\tvalid_0's binary_logloss: 0.00123788\n",
      "[251]\tvalid_0's average_precision: 0.653078\tvalid_0's binary_logloss: 0.00123756\n",
      "[252]\tvalid_0's average_precision: 0.653152\tvalid_0's binary_logloss: 0.00123728\n",
      "[253]\tvalid_0's average_precision: 0.653207\tvalid_0's binary_logloss: 0.0012369\n",
      "[254]\tvalid_0's average_precision: 0.653248\tvalid_0's binary_logloss: 0.00123658\n",
      "[255]\tvalid_0's average_precision: 0.653295\tvalid_0's binary_logloss: 0.00123638\n",
      "[256]\tvalid_0's average_precision: 0.653341\tvalid_0's binary_logloss: 0.00123608\n",
      "[257]\tvalid_0's average_precision: 0.653395\tvalid_0's binary_logloss: 0.00123566\n",
      "[258]\tvalid_0's average_precision: 0.65345\tvalid_0's binary_logloss: 0.00123547\n",
      "[259]\tvalid_0's average_precision: 0.653489\tvalid_0's binary_logloss: 0.00123525\n",
      "[260]\tvalid_0's average_precision: 0.653569\tvalid_0's binary_logloss: 0.00123501\n",
      "[261]\tvalid_0's average_precision: 0.653608\tvalid_0's binary_logloss: 0.00123464\n",
      "[262]\tvalid_0's average_precision: 0.653675\tvalid_0's binary_logloss: 0.0012344\n",
      "[263]\tvalid_0's average_precision: 0.653741\tvalid_0's binary_logloss: 0.00123422\n",
      "[264]\tvalid_0's average_precision: 0.653789\tvalid_0's binary_logloss: 0.00123402\n",
      "[265]\tvalid_0's average_precision: 0.653837\tvalid_0's binary_logloss: 0.00123381\n",
      "[266]\tvalid_0's average_precision: 0.653877\tvalid_0's binary_logloss: 0.00123367\n",
      "[267]\tvalid_0's average_precision: 0.65392\tvalid_0's binary_logloss: 0.00123332\n",
      "[268]\tvalid_0's average_precision: 0.653983\tvalid_0's binary_logloss: 0.00123304\n",
      "[269]\tvalid_0's average_precision: 0.654066\tvalid_0's binary_logloss: 0.00123282\n",
      "[270]\tvalid_0's average_precision: 0.654132\tvalid_0's binary_logloss: 0.00123262\n",
      "[271]\tvalid_0's average_precision: 0.654162\tvalid_0's binary_logloss: 0.00123247\n",
      "[272]\tvalid_0's average_precision: 0.654202\tvalid_0's binary_logloss: 0.00123231\n",
      "[273]\tvalid_0's average_precision: 0.654213\tvalid_0's binary_logloss: 0.00123214\n",
      "[274]\tvalid_0's average_precision: 0.654277\tvalid_0's binary_logloss: 0.00123194\n",
      "[275]\tvalid_0's average_precision: 0.654342\tvalid_0's binary_logloss: 0.00123169\n",
      "[276]\tvalid_0's average_precision: 0.65441\tvalid_0's binary_logloss: 0.00123147\n",
      "[277]\tvalid_0's average_precision: 0.654445\tvalid_0's binary_logloss: 0.00123122\n",
      "[278]\tvalid_0's average_precision: 0.654497\tvalid_0's binary_logloss: 0.00123085\n",
      "[279]\tvalid_0's average_precision: 0.654532\tvalid_0's binary_logloss: 0.00123071\n",
      "[280]\tvalid_0's average_precision: 0.654544\tvalid_0's binary_logloss: 0.00123063\n",
      "[281]\tvalid_0's average_precision: 0.654565\tvalid_0's binary_logloss: 0.00123052\n",
      "[282]\tvalid_0's average_precision: 0.654595\tvalid_0's binary_logloss: 0.00123029\n",
      "[283]\tvalid_0's average_precision: 0.654621\tvalid_0's binary_logloss: 0.00123015\n",
      "[284]\tvalid_0's average_precision: 0.654676\tvalid_0's binary_logloss: 0.00122999\n",
      "[285]\tvalid_0's average_precision: 0.654704\tvalid_0's binary_logloss: 0.00122987\n",
      "[286]\tvalid_0's average_precision: 0.654721\tvalid_0's binary_logloss: 0.00122959\n",
      "[287]\tvalid_0's average_precision: 0.654745\tvalid_0's binary_logloss: 0.00122931\n",
      "[288]\tvalid_0's average_precision: 0.65476\tvalid_0's binary_logloss: 0.00122908\n",
      "[289]\tvalid_0's average_precision: 0.654798\tvalid_0's binary_logloss: 0.00122897\n",
      "[290]\tvalid_0's average_precision: 0.654856\tvalid_0's binary_logloss: 0.00122879\n",
      "[291]\tvalid_0's average_precision: 0.654876\tvalid_0's binary_logloss: 0.0012287\n",
      "[292]\tvalid_0's average_precision: 0.654914\tvalid_0's binary_logloss: 0.00122834\n",
      "[293]\tvalid_0's average_precision: 0.654935\tvalid_0's binary_logloss: 0.00122824\n",
      "[294]\tvalid_0's average_precision: 0.654978\tvalid_0's binary_logloss: 0.0012281\n",
      "[295]\tvalid_0's average_precision: 0.655025\tvalid_0's binary_logloss: 0.00122789\n",
      "[296]\tvalid_0's average_precision: 0.655063\tvalid_0's binary_logloss: 0.00122758\n",
      "[297]\tvalid_0's average_precision: 0.655109\tvalid_0's binary_logloss: 0.00122739\n",
      "[298]\tvalid_0's average_precision: 0.65511\tvalid_0's binary_logloss: 0.00122716\n",
      "[299]\tvalid_0's average_precision: 0.655139\tvalid_0's binary_logloss: 0.00122704\n",
      "[300]\tvalid_0's average_precision: 0.655159\tvalid_0's binary_logloss: 0.00122696\n",
      "[301]\tvalid_0's average_precision: 0.655179\tvalid_0's binary_logloss: 0.00122686\n",
      "[302]\tvalid_0's average_precision: 0.655212\tvalid_0's binary_logloss: 0.00122675\n",
      "[303]\tvalid_0's average_precision: 0.655229\tvalid_0's binary_logloss: 0.00122666\n",
      "[304]\tvalid_0's average_precision: 0.65525\tvalid_0's binary_logloss: 0.00122657\n",
      "[305]\tvalid_0's average_precision: 0.655263\tvalid_0's binary_logloss: 0.0012265\n",
      "[306]\tvalid_0's average_precision: 0.655306\tvalid_0's binary_logloss: 0.00122635\n",
      "[307]\tvalid_0's average_precision: 0.655335\tvalid_0's binary_logloss: 0.00122621\n",
      "[308]\tvalid_0's average_precision: 0.655367\tvalid_0's binary_logloss: 0.0012261\n",
      "[309]\tvalid_0's average_precision: 0.655401\tvalid_0's binary_logloss: 0.00122594\n",
      "[310]\tvalid_0's average_precision: 0.655432\tvalid_0's binary_logloss: 0.0012258\n",
      "[311]\tvalid_0's average_precision: 0.655457\tvalid_0's binary_logloss: 0.00122553\n",
      "[312]\tvalid_0's average_precision: 0.655476\tvalid_0's binary_logloss: 0.00122531\n",
      "[313]\tvalid_0's average_precision: 0.655493\tvalid_0's binary_logloss: 0.0012252\n",
      "[314]\tvalid_0's average_precision: 0.655535\tvalid_0's binary_logloss: 0.00122504\n",
      "[315]\tvalid_0's average_precision: 0.655582\tvalid_0's binary_logloss: 0.00122491\n",
      "[316]\tvalid_0's average_precision: 0.655613\tvalid_0's binary_logloss: 0.0012248\n",
      "[317]\tvalid_0's average_precision: 0.655646\tvalid_0's binary_logloss: 0.00122466\n",
      "[318]\tvalid_0's average_precision: 0.655677\tvalid_0's binary_logloss: 0.00122457\n",
      "[319]\tvalid_0's average_precision: 0.655699\tvalid_0's binary_logloss: 0.00122444\n",
      "[320]\tvalid_0's average_precision: 0.655736\tvalid_0's binary_logloss: 0.00122434\n",
      "[321]\tvalid_0's average_precision: 0.655754\tvalid_0's binary_logloss: 0.00122427\n",
      "[322]\tvalid_0's average_precision: 0.655785\tvalid_0's binary_logloss: 0.00122405\n",
      "[323]\tvalid_0's average_precision: 0.655807\tvalid_0's binary_logloss: 0.00122397\n",
      "[324]\tvalid_0's average_precision: 0.65582\tvalid_0's binary_logloss: 0.0012239\n",
      "[325]\tvalid_0's average_precision: 0.65586\tvalid_0's binary_logloss: 0.00122382\n",
      "[326]\tvalid_0's average_precision: 0.655881\tvalid_0's binary_logloss: 0.00122376\n",
      "[327]\tvalid_0's average_precision: 0.655902\tvalid_0's binary_logloss: 0.0012237\n",
      "[328]\tvalid_0's average_precision: 0.655936\tvalid_0's binary_logloss: 0.00122359\n",
      "[329]\tvalid_0's average_precision: 0.655963\tvalid_0's binary_logloss: 0.00122346\n",
      "[330]\tvalid_0's average_precision: 0.655993\tvalid_0's binary_logloss: 0.0012234\n",
      "[331]\tvalid_0's average_precision: 0.65601\tvalid_0's binary_logloss: 0.00122327\n",
      "[332]\tvalid_0's average_precision: 0.656042\tvalid_0's binary_logloss: 0.00122316\n",
      "[333]\tvalid_0's average_precision: 0.656052\tvalid_0's binary_logloss: 0.00122311\n",
      "[334]\tvalid_0's average_precision: 0.656071\tvalid_0's binary_logloss: 0.00122305\n",
      "[335]\tvalid_0's average_precision: 0.656084\tvalid_0's binary_logloss: 0.00122302\n",
      "[336]\tvalid_0's average_precision: 0.656098\tvalid_0's binary_logloss: 0.00122297\n",
      "[337]\tvalid_0's average_precision: 0.656107\tvalid_0's binary_logloss: 0.00122291\n",
      "[338]\tvalid_0's average_precision: 0.656118\tvalid_0's binary_logloss: 0.00122287\n",
      "[339]\tvalid_0's average_precision: 0.656129\tvalid_0's binary_logloss: 0.00122282\n",
      "[340]\tvalid_0's average_precision: 0.656155\tvalid_0's binary_logloss: 0.00122276\n",
      "[341]\tvalid_0's average_precision: 0.656201\tvalid_0's binary_logloss: 0.00122261\n",
      "[342]\tvalid_0's average_precision: 0.656233\tvalid_0's binary_logloss: 0.00122251\n",
      "[343]\tvalid_0's average_precision: 0.656245\tvalid_0's binary_logloss: 0.00122244\n",
      "[344]\tvalid_0's average_precision: 0.65625\tvalid_0's binary_logloss: 0.0012224\n",
      "[345]\tvalid_0's average_precision: 0.656256\tvalid_0's binary_logloss: 0.00122237\n",
      "[346]\tvalid_0's average_precision: 0.656276\tvalid_0's binary_logloss: 0.00122231\n",
      "[347]\tvalid_0's average_precision: 0.656292\tvalid_0's binary_logloss: 0.00122228\n",
      "[348]\tvalid_0's average_precision: 0.656309\tvalid_0's binary_logloss: 0.00122223\n",
      "[349]\tvalid_0's average_precision: 0.656346\tvalid_0's binary_logloss: 0.00122211\n",
      "[350]\tvalid_0's average_precision: 0.656378\tvalid_0's binary_logloss: 0.00122201\n",
      "[351]\tvalid_0's average_precision: 0.656401\tvalid_0's binary_logloss: 0.00122192\n",
      "[352]\tvalid_0's average_precision: 0.656418\tvalid_0's binary_logloss: 0.00122186\n",
      "[353]\tvalid_0's average_precision: 0.65643\tvalid_0's binary_logloss: 0.00122181\n",
      "[354]\tvalid_0's average_precision: 0.656444\tvalid_0's binary_logloss: 0.00122175\n",
      "[355]\tvalid_0's average_precision: 0.656456\tvalid_0's binary_logloss: 0.00122168\n",
      "[356]\tvalid_0's average_precision: 0.656464\tvalid_0's binary_logloss: 0.00122163\n",
      "[357]\tvalid_0's average_precision: 0.656464\tvalid_0's binary_logloss: 0.00122151\n",
      "[358]\tvalid_0's average_precision: 0.656492\tvalid_0's binary_logloss: 0.00122144\n",
      "[359]\tvalid_0's average_precision: 0.656508\tvalid_0's binary_logloss: 0.00122138\n",
      "[360]\tvalid_0's average_precision: 0.656539\tvalid_0's binary_logloss: 0.00122126\n",
      "[361]\tvalid_0's average_precision: 0.656558\tvalid_0's binary_logloss: 0.00122122\n",
      "[362]\tvalid_0's average_precision: 0.656564\tvalid_0's binary_logloss: 0.00122119\n",
      "[363]\tvalid_0's average_precision: 0.656589\tvalid_0's binary_logloss: 0.00122115\n",
      "[364]\tvalid_0's average_precision: 0.656606\tvalid_0's binary_logloss: 0.00122111\n",
      "[365]\tvalid_0's average_precision: 0.656626\tvalid_0's binary_logloss: 0.00122105\n",
      "[366]\tvalid_0's average_precision: 0.65664\tvalid_0's binary_logloss: 0.00122099\n",
      "[367]\tvalid_0's average_precision: 0.656647\tvalid_0's binary_logloss: 0.00122091\n",
      "[368]\tvalid_0's average_precision: 0.656657\tvalid_0's binary_logloss: 0.00122086\n",
      "[369]\tvalid_0's average_precision: 0.656665\tvalid_0's binary_logloss: 0.00122077\n",
      "[370]\tvalid_0's average_precision: 0.656673\tvalid_0's binary_logloss: 0.00122074\n",
      "[371]\tvalid_0's average_precision: 0.656686\tvalid_0's binary_logloss: 0.00122069\n",
      "[372]\tvalid_0's average_precision: 0.656691\tvalid_0's binary_logloss: 0.00122064\n",
      "[373]\tvalid_0's average_precision: 0.656701\tvalid_0's binary_logloss: 0.0012206\n",
      "[374]\tvalid_0's average_precision: 0.656724\tvalid_0's binary_logloss: 0.00122052\n",
      "[375]\tvalid_0's average_precision: 0.656745\tvalid_0's binary_logloss: 0.00122045\n",
      "[376]\tvalid_0's average_precision: 0.656762\tvalid_0's binary_logloss: 0.00122039\n",
      "[377]\tvalid_0's average_precision: 0.656783\tvalid_0's binary_logloss: 0.00122024\n",
      "[378]\tvalid_0's average_precision: 0.656791\tvalid_0's binary_logloss: 0.00122018\n",
      "[379]\tvalid_0's average_precision: 0.656804\tvalid_0's binary_logloss: 0.00122014\n",
      "[380]\tvalid_0's average_precision: 0.656821\tvalid_0's binary_logloss: 0.00122009\n",
      "[381]\tvalid_0's average_precision: 0.656833\tvalid_0's binary_logloss: 0.00122006\n",
      "[382]\tvalid_0's average_precision: 0.656837\tvalid_0's binary_logloss: 0.00122004\n",
      "[383]\tvalid_0's average_precision: 0.656833\tvalid_0's binary_logloss: 0.00122002\n",
      "[384]\tvalid_0's average_precision: 0.656828\tvalid_0's binary_logloss: 0.00122\n",
      "[385]\tvalid_0's average_precision: 0.656855\tvalid_0's binary_logloss: 0.00121994\n",
      "[386]\tvalid_0's average_precision: 0.656879\tvalid_0's binary_logloss: 0.00121984\n",
      "[387]\tvalid_0's average_precision: 0.656904\tvalid_0's binary_logloss: 0.00121978\n",
      "[388]\tvalid_0's average_precision: 0.656907\tvalid_0's binary_logloss: 0.00121976\n",
      "[389]\tvalid_0's average_precision: 0.656922\tvalid_0's binary_logloss: 0.00121973\n",
      "[390]\tvalid_0's average_precision: 0.656924\tvalid_0's binary_logloss: 0.00121969\n",
      "[391]\tvalid_0's average_precision: 0.656948\tvalid_0's binary_logloss: 0.00121964\n",
      "[392]\tvalid_0's average_precision: 0.656958\tvalid_0's binary_logloss: 0.00121963\n",
      "[393]\tvalid_0's average_precision: 0.656965\tvalid_0's binary_logloss: 0.00121957\n",
      "[394]\tvalid_0's average_precision: 0.656977\tvalid_0's binary_logloss: 0.00121954\n",
      "[395]\tvalid_0's average_precision: 0.656991\tvalid_0's binary_logloss: 0.0012195\n",
      "[396]\tvalid_0's average_precision: 0.657007\tvalid_0's binary_logloss: 0.00121945\n",
      "[397]\tvalid_0's average_precision: 0.657006\tvalid_0's binary_logloss: 0.00121944\n",
      "[398]\tvalid_0's average_precision: 0.657011\tvalid_0's binary_logloss: 0.00121943\n",
      "[399]\tvalid_0's average_precision: 0.657017\tvalid_0's binary_logloss: 0.0012194\n",
      "[400]\tvalid_0's average_precision: 0.657035\tvalid_0's binary_logloss: 0.00121933\n",
      "[401]\tvalid_0's average_precision: 0.657052\tvalid_0's binary_logloss: 0.00121925\n",
      "[402]\tvalid_0's average_precision: 0.657059\tvalid_0's binary_logloss: 0.00121922\n",
      "[403]\tvalid_0's average_precision: 0.657089\tvalid_0's binary_logloss: 0.00121902\n",
      "[404]\tvalid_0's average_precision: 0.657106\tvalid_0's binary_logloss: 0.00121887\n",
      "[405]\tvalid_0's average_precision: 0.657142\tvalid_0's binary_logloss: 0.00121865\n",
      "[406]\tvalid_0's average_precision: 0.65715\tvalid_0's binary_logloss: 0.00121861\n",
      "[407]\tvalid_0's average_precision: 0.657153\tvalid_0's binary_logloss: 0.0012186\n",
      "[408]\tvalid_0's average_precision: 0.657163\tvalid_0's binary_logloss: 0.00121857\n",
      "[409]\tvalid_0's average_precision: 0.657177\tvalid_0's binary_logloss: 0.00121853\n",
      "[410]\tvalid_0's average_precision: 0.657184\tvalid_0's binary_logloss: 0.00121852\n",
      "[411]\tvalid_0's average_precision: 0.657192\tvalid_0's binary_logloss: 0.00121848\n",
      "[412]\tvalid_0's average_precision: 0.65722\tvalid_0's binary_logloss: 0.0012184\n",
      "[413]\tvalid_0's average_precision: 0.657233\tvalid_0's binary_logloss: 0.00121836\n",
      "[414]\tvalid_0's average_precision: 0.657242\tvalid_0's binary_logloss: 0.00121832\n",
      "[415]\tvalid_0's average_precision: 0.657258\tvalid_0's binary_logloss: 0.00121827\n",
      "[416]\tvalid_0's average_precision: 0.657267\tvalid_0's binary_logloss: 0.00121824\n",
      "[417]\tvalid_0's average_precision: 0.657275\tvalid_0's binary_logloss: 0.0012182\n",
      "[418]\tvalid_0's average_precision: 0.657286\tvalid_0's binary_logloss: 0.00121815\n",
      "[419]\tvalid_0's average_precision: 0.657291\tvalid_0's binary_logloss: 0.00121812\n",
      "[420]\tvalid_0's average_precision: 0.657304\tvalid_0's binary_logloss: 0.00121809\n",
      "[421]\tvalid_0's average_precision: 0.657308\tvalid_0's binary_logloss: 0.00121808\n",
      "[422]\tvalid_0's average_precision: 0.657314\tvalid_0's binary_logloss: 0.00121806\n",
      "[423]\tvalid_0's average_precision: 0.657322\tvalid_0's binary_logloss: 0.00121804\n",
      "[424]\tvalid_0's average_precision: 0.657324\tvalid_0's binary_logloss: 0.00121804\n",
      "[425]\tvalid_0's average_precision: 0.657323\tvalid_0's binary_logloss: 0.00121803\n",
      "[426]\tvalid_0's average_precision: 0.657331\tvalid_0's binary_logloss: 0.00121802\n",
      "[427]\tvalid_0's average_precision: 0.657343\tvalid_0's binary_logloss: 0.00121797\n",
      "[428]\tvalid_0's average_precision: 0.657346\tvalid_0's binary_logloss: 0.00121797\n",
      "[429]\tvalid_0's average_precision: 0.657353\tvalid_0's binary_logloss: 0.00121794\n",
      "[430]\tvalid_0's average_precision: 0.657377\tvalid_0's binary_logloss: 0.00121789\n",
      "[431]\tvalid_0's average_precision: 0.65739\tvalid_0's binary_logloss: 0.00121786\n",
      "[432]\tvalid_0's average_precision: 0.657404\tvalid_0's binary_logloss: 0.00121782\n",
      "[433]\tvalid_0's average_precision: 0.657411\tvalid_0's binary_logloss: 0.00121779\n",
      "[434]\tvalid_0's average_precision: 0.657409\tvalid_0's binary_logloss: 0.00121779\n",
      "[435]\tvalid_0's average_precision: 0.657417\tvalid_0's binary_logloss: 0.00121777\n",
      "[436]\tvalid_0's average_precision: 0.65742\tvalid_0's binary_logloss: 0.00121773\n",
      "[437]\tvalid_0's average_precision: 0.657425\tvalid_0's binary_logloss: 0.00121772\n",
      "[438]\tvalid_0's average_precision: 0.657431\tvalid_0's binary_logloss: 0.0012177\n",
      "[439]\tvalid_0's average_precision: 0.657423\tvalid_0's binary_logloss: 0.0012177\n",
      "[440]\tvalid_0's average_precision: 0.657432\tvalid_0's binary_logloss: 0.00121768\n",
      "[441]\tvalid_0's average_precision: 0.65743\tvalid_0's binary_logloss: 0.00121767\n",
      "[442]\tvalid_0's average_precision: 0.657433\tvalid_0's binary_logloss: 0.00121765\n",
      "[443]\tvalid_0's average_precision: 0.657432\tvalid_0's binary_logloss: 0.00121764\n",
      "[444]\tvalid_0's average_precision: 0.657436\tvalid_0's binary_logloss: 0.00121762\n",
      "[445]\tvalid_0's average_precision: 0.657451\tvalid_0's binary_logloss: 0.00121758\n",
      "[446]\tvalid_0's average_precision: 0.657465\tvalid_0's binary_logloss: 0.00121753\n",
      "[447]\tvalid_0's average_precision: 0.657471\tvalid_0's binary_logloss: 0.00121753\n",
      "[448]\tvalid_0's average_precision: 0.657471\tvalid_0's binary_logloss: 0.00121753\n",
      "[449]\tvalid_0's average_precision: 0.65747\tvalid_0's binary_logloss: 0.00121754\n",
      "[450]\tvalid_0's average_precision: 0.657468\tvalid_0's binary_logloss: 0.00121755\n",
      "[451]\tvalid_0's average_precision: 0.657472\tvalid_0's binary_logloss: 0.00121749\n",
      "[452]\tvalid_0's average_precision: 0.657469\tvalid_0's binary_logloss: 0.00121744\n",
      "[453]\tvalid_0's average_precision: 0.657471\tvalid_0's binary_logloss: 0.00121741\n",
      "[454]\tvalid_0's average_precision: 0.657472\tvalid_0's binary_logloss: 0.00121741\n",
      "[455]\tvalid_0's average_precision: 0.657476\tvalid_0's binary_logloss: 0.0012174\n",
      "[456]\tvalid_0's average_precision: 0.657474\tvalid_0's binary_logloss: 0.0012174\n",
      "[457]\tvalid_0's average_precision: 0.657477\tvalid_0's binary_logloss: 0.00121741\n",
      "[458]\tvalid_0's average_precision: 0.657481\tvalid_0's binary_logloss: 0.0012174\n",
      "[459]\tvalid_0's average_precision: 0.657493\tvalid_0's binary_logloss: 0.00121735\n",
      "[460]\tvalid_0's average_precision: 0.657515\tvalid_0's binary_logloss: 0.00121731\n",
      "[461]\tvalid_0's average_precision: 0.657511\tvalid_0's binary_logloss: 0.00121732\n",
      "[462]\tvalid_0's average_precision: 0.657515\tvalid_0's binary_logloss: 0.00121729\n",
      "[463]\tvalid_0's average_precision: 0.657509\tvalid_0's binary_logloss: 0.00121725\n",
      "[464]\tvalid_0's average_precision: 0.657517\tvalid_0's binary_logloss: 0.00121723\n",
      "[465]\tvalid_0's average_precision: 0.657514\tvalid_0's binary_logloss: 0.00121721\n",
      "[466]\tvalid_0's average_precision: 0.657523\tvalid_0's binary_logloss: 0.0012172\n",
      "[467]\tvalid_0's average_precision: 0.657526\tvalid_0's binary_logloss: 0.00121718\n",
      "[468]\tvalid_0's average_precision: 0.657544\tvalid_0's binary_logloss: 0.00121715\n",
      "[469]\tvalid_0's average_precision: 0.657544\tvalid_0's binary_logloss: 0.00121714\n",
      "[470]\tvalid_0's average_precision: 0.657549\tvalid_0's binary_logloss: 0.00121712\n",
      "[471]\tvalid_0's average_precision: 0.657553\tvalid_0's binary_logloss: 0.00121711\n",
      "[472]\tvalid_0's average_precision: 0.657579\tvalid_0's binary_logloss: 0.00121706\n",
      "[473]\tvalid_0's average_precision: 0.657591\tvalid_0's binary_logloss: 0.00121702\n",
      "[474]\tvalid_0's average_precision: 0.657594\tvalid_0's binary_logloss: 0.00121702\n",
      "[475]\tvalid_0's average_precision: 0.6576\tvalid_0's binary_logloss: 0.001217\n",
      "[476]\tvalid_0's average_precision: 0.657605\tvalid_0's binary_logloss: 0.001217\n",
      "[477]\tvalid_0's average_precision: 0.65761\tvalid_0's binary_logloss: 0.00121696\n",
      "[478]\tvalid_0's average_precision: 0.657622\tvalid_0's binary_logloss: 0.0012168\n",
      "[479]\tvalid_0's average_precision: 0.65765\tvalid_0's binary_logloss: 0.00121672\n",
      "[480]\tvalid_0's average_precision: 0.657659\tvalid_0's binary_logloss: 0.00121668\n",
      "[481]\tvalid_0's average_precision: 0.657674\tvalid_0's binary_logloss: 0.00121665\n",
      "[482]\tvalid_0's average_precision: 0.657684\tvalid_0's binary_logloss: 0.00121663\n",
      "[483]\tvalid_0's average_precision: 0.657687\tvalid_0's binary_logloss: 0.00121664\n",
      "[484]\tvalid_0's average_precision: 0.65769\tvalid_0's binary_logloss: 0.00121664\n",
      "[485]\tvalid_0's average_precision: 0.657696\tvalid_0's binary_logloss: 0.00121662\n",
      "[486]\tvalid_0's average_precision: 0.657696\tvalid_0's binary_logloss: 0.00121662\n",
      "[487]\tvalid_0's average_precision: 0.657696\tvalid_0's binary_logloss: 0.00121662\n",
      "[488]\tvalid_0's average_precision: 0.6577\tvalid_0's binary_logloss: 0.00121662\n",
      "[489]\tvalid_0's average_precision: 0.657703\tvalid_0's binary_logloss: 0.00121661\n",
      "[490]\tvalid_0's average_precision: 0.657709\tvalid_0's binary_logloss: 0.0012166\n",
      "[491]\tvalid_0's average_precision: 0.657719\tvalid_0's binary_logloss: 0.0012166\n",
      "[492]\tvalid_0's average_precision: 0.657721\tvalid_0's binary_logloss: 0.00121658\n",
      "[493]\tvalid_0's average_precision: 0.65772\tvalid_0's binary_logloss: 0.00121657\n",
      "[494]\tvalid_0's average_precision: 0.65772\tvalid_0's binary_logloss: 0.00121657\n",
      "[495]\tvalid_0's average_precision: 0.657719\tvalid_0's binary_logloss: 0.00121657\n",
      "[496]\tvalid_0's average_precision: 0.657737\tvalid_0's binary_logloss: 0.0012165\n",
      "[497]\tvalid_0's average_precision: 0.657766\tvalid_0's binary_logloss: 0.00121641\n",
      "[498]\tvalid_0's average_precision: 0.657769\tvalid_0's binary_logloss: 0.00121639\n",
      "[499]\tvalid_0's average_precision: 0.657782\tvalid_0's binary_logloss: 0.00121634\n",
      "[500]\tvalid_0's average_precision: 0.657801\tvalid_0's binary_logloss: 0.00121628\n",
      "[501]\tvalid_0's average_precision: 0.657805\tvalid_0's binary_logloss: 0.00121626\n",
      "[502]\tvalid_0's average_precision: 0.657807\tvalid_0's binary_logloss: 0.00121625\n",
      "[503]\tvalid_0's average_precision: 0.657817\tvalid_0's binary_logloss: 0.00121623\n",
      "[504]\tvalid_0's average_precision: 0.657828\tvalid_0's binary_logloss: 0.00121618\n",
      "[505]\tvalid_0's average_precision: 0.657833\tvalid_0's binary_logloss: 0.00121617\n",
      "[506]\tvalid_0's average_precision: 0.657848\tvalid_0's binary_logloss: 0.00121615\n",
      "[507]\tvalid_0's average_precision: 0.657861\tvalid_0's binary_logloss: 0.00121609\n",
      "[508]\tvalid_0's average_precision: 0.657862\tvalid_0's binary_logloss: 0.00121608\n",
      "[509]\tvalid_0's average_precision: 0.657861\tvalid_0's binary_logloss: 0.00121608\n",
      "[510]\tvalid_0's average_precision: 0.657869\tvalid_0's binary_logloss: 0.00121606\n",
      "[511]\tvalid_0's average_precision: 0.657887\tvalid_0's binary_logloss: 0.00121601\n",
      "[512]\tvalid_0's average_precision: 0.657905\tvalid_0's binary_logloss: 0.00121581\n",
      "[513]\tvalid_0's average_precision: 0.657907\tvalid_0's binary_logloss: 0.00121579\n",
      "[514]\tvalid_0's average_precision: 0.657904\tvalid_0's binary_logloss: 0.00121577\n",
      "[515]\tvalid_0's average_precision: 0.657905\tvalid_0's binary_logloss: 0.00121575\n",
      "[516]\tvalid_0's average_precision: 0.657912\tvalid_0's binary_logloss: 0.00121572\n",
      "[517]\tvalid_0's average_precision: 0.657934\tvalid_0's binary_logloss: 0.00121565\n",
      "[518]\tvalid_0's average_precision: 0.657938\tvalid_0's binary_logloss: 0.00121562\n",
      "[519]\tvalid_0's average_precision: 0.657956\tvalid_0's binary_logloss: 0.00121554\n",
      "[520]\tvalid_0's average_precision: 0.657963\tvalid_0's binary_logloss: 0.00121554\n",
      "[521]\tvalid_0's average_precision: 0.657969\tvalid_0's binary_logloss: 0.00121552\n",
      "[522]\tvalid_0's average_precision: 0.657983\tvalid_0's binary_logloss: 0.00121551\n",
      "[523]\tvalid_0's average_precision: 0.657991\tvalid_0's binary_logloss: 0.00121545\n",
      "[524]\tvalid_0's average_precision: 0.657997\tvalid_0's binary_logloss: 0.0012154\n",
      "[525]\tvalid_0's average_precision: 0.658007\tvalid_0's binary_logloss: 0.00121535\n",
      "[526]\tvalid_0's average_precision: 0.658022\tvalid_0's binary_logloss: 0.00121529\n",
      "[527]\tvalid_0's average_precision: 0.658033\tvalid_0's binary_logloss: 0.0012152\n",
      "[528]\tvalid_0's average_precision: 0.658041\tvalid_0's binary_logloss: 0.00121518\n",
      "[529]\tvalid_0's average_precision: 0.658046\tvalid_0's binary_logloss: 0.00121518\n",
      "[530]\tvalid_0's average_precision: 0.658051\tvalid_0's binary_logloss: 0.00121516\n",
      "[531]\tvalid_0's average_precision: 0.658061\tvalid_0's binary_logloss: 0.00121516\n",
      "[532]\tvalid_0's average_precision: 0.658063\tvalid_0's binary_logloss: 0.00121516\n",
      "[533]\tvalid_0's average_precision: 0.658062\tvalid_0's binary_logloss: 0.00121517\n",
      "[534]\tvalid_0's average_precision: 0.65806\tvalid_0's binary_logloss: 0.00121518\n",
      "[535]\tvalid_0's average_precision: 0.658056\tvalid_0's binary_logloss: 0.00121518\n",
      "[536]\tvalid_0's average_precision: 0.658069\tvalid_0's binary_logloss: 0.00121515\n",
      "[537]\tvalid_0's average_precision: 0.658065\tvalid_0's binary_logloss: 0.00121515\n",
      "[538]\tvalid_0's average_precision: 0.658066\tvalid_0's binary_logloss: 0.00121512\n",
      "[539]\tvalid_0's average_precision: 0.658072\tvalid_0's binary_logloss: 0.00121509\n",
      "[540]\tvalid_0's average_precision: 0.658072\tvalid_0's binary_logloss: 0.0012151\n",
      "[541]\tvalid_0's average_precision: 0.65808\tvalid_0's binary_logloss: 0.00121508\n",
      "[542]\tvalid_0's average_precision: 0.65808\tvalid_0's binary_logloss: 0.00121507\n",
      "[543]\tvalid_0's average_precision: 0.658083\tvalid_0's binary_logloss: 0.00121506\n",
      "[544]\tvalid_0's average_precision: 0.658094\tvalid_0's binary_logloss: 0.00121505\n",
      "[545]\tvalid_0's average_precision: 0.658097\tvalid_0's binary_logloss: 0.00121506\n",
      "[546]\tvalid_0's average_precision: 0.658104\tvalid_0's binary_logloss: 0.00121506\n",
      "[547]\tvalid_0's average_precision: 0.658106\tvalid_0's binary_logloss: 0.00121505\n",
      "[548]\tvalid_0's average_precision: 0.658113\tvalid_0's binary_logloss: 0.00121504\n",
      "[549]\tvalid_0's average_precision: 0.65812\tvalid_0's binary_logloss: 0.00121503\n",
      "[550]\tvalid_0's average_precision: 0.658129\tvalid_0's binary_logloss: 0.00121499\n",
      "[551]\tvalid_0's average_precision: 0.658129\tvalid_0's binary_logloss: 0.00121496\n",
      "[552]\tvalid_0's average_precision: 0.658131\tvalid_0's binary_logloss: 0.00121496\n",
      "[553]\tvalid_0's average_precision: 0.658141\tvalid_0's binary_logloss: 0.00121488\n",
      "[554]\tvalid_0's average_precision: 0.658136\tvalid_0's binary_logloss: 0.00121487\n",
      "[555]\tvalid_0's average_precision: 0.658146\tvalid_0's binary_logloss: 0.0012148\n",
      "[556]\tvalid_0's average_precision: 0.658145\tvalid_0's binary_logloss: 0.00121479\n",
      "[557]\tvalid_0's average_precision: 0.658147\tvalid_0's binary_logloss: 0.0012148\n",
      "[558]\tvalid_0's average_precision: 0.65815\tvalid_0's binary_logloss: 0.0012148\n",
      "[559]\tvalid_0's average_precision: 0.658144\tvalid_0's binary_logloss: 0.00121482\n",
      "[560]\tvalid_0's average_precision: 0.658145\tvalid_0's binary_logloss: 0.00121483\n",
      "[561]\tvalid_0's average_precision: 0.658156\tvalid_0's binary_logloss: 0.00121481\n",
      "[562]\tvalid_0's average_precision: 0.658164\tvalid_0's binary_logloss: 0.00121479\n",
      "[563]\tvalid_0's average_precision: 0.658174\tvalid_0's binary_logloss: 0.00121477\n",
      "[564]\tvalid_0's average_precision: 0.658174\tvalid_0's binary_logloss: 0.00121477\n",
      "[565]\tvalid_0's average_precision: 0.658183\tvalid_0's binary_logloss: 0.00121474\n",
      "[566]\tvalid_0's average_precision: 0.658176\tvalid_0's binary_logloss: 0.00121475\n",
      "[567]\tvalid_0's average_precision: 0.658179\tvalid_0's binary_logloss: 0.00121472\n",
      "[568]\tvalid_0's average_precision: 0.658188\tvalid_0's binary_logloss: 0.0012147\n",
      "[569]\tvalid_0's average_precision: 0.658198\tvalid_0's binary_logloss: 0.00121466\n",
      "[570]\tvalid_0's average_precision: 0.658215\tvalid_0's binary_logloss: 0.00121463\n",
      "[571]\tvalid_0's average_precision: 0.65823\tvalid_0's binary_logloss: 0.00121448\n",
      "[572]\tvalid_0's average_precision: 0.658232\tvalid_0's binary_logloss: 0.00121434\n",
      "[573]\tvalid_0's average_precision: 0.658244\tvalid_0's binary_logloss: 0.00121421\n",
      "[574]\tvalid_0's average_precision: 0.658246\tvalid_0's binary_logloss: 0.00121419\n",
      "[575]\tvalid_0's average_precision: 0.658259\tvalid_0's binary_logloss: 0.00121413\n",
      "[576]\tvalid_0's average_precision: 0.658264\tvalid_0's binary_logloss: 0.0012141\n",
      "[577]\tvalid_0's average_precision: 0.65827\tvalid_0's binary_logloss: 0.00121408\n",
      "[578]\tvalid_0's average_precision: 0.658272\tvalid_0's binary_logloss: 0.00121408\n",
      "[579]\tvalid_0's average_precision: 0.658283\tvalid_0's binary_logloss: 0.00121407\n",
      "[580]\tvalid_0's average_precision: 0.658287\tvalid_0's binary_logloss: 0.00121406\n",
      "[581]\tvalid_0's average_precision: 0.658284\tvalid_0's binary_logloss: 0.00121407\n",
      "[582]\tvalid_0's average_precision: 0.658289\tvalid_0's binary_logloss: 0.00121406\n",
      "[583]\tvalid_0's average_precision: 0.658306\tvalid_0's binary_logloss: 0.00121402\n",
      "[584]\tvalid_0's average_precision: 0.658308\tvalid_0's binary_logloss: 0.00121401\n",
      "[585]\tvalid_0's average_precision: 0.658315\tvalid_0's binary_logloss: 0.00121401\n",
      "[586]\tvalid_0's average_precision: 0.658317\tvalid_0's binary_logloss: 0.00121402\n",
      "[587]\tvalid_0's average_precision: 0.658316\tvalid_0's binary_logloss: 0.00121402\n",
      "[588]\tvalid_0's average_precision: 0.658313\tvalid_0's binary_logloss: 0.00121404\n",
      "[589]\tvalid_0's average_precision: 0.658312\tvalid_0's binary_logloss: 0.00121406\n",
      "[590]\tvalid_0's average_precision: 0.658314\tvalid_0's binary_logloss: 0.00121407\n",
      "[591]\tvalid_0's average_precision: 0.658321\tvalid_0's binary_logloss: 0.00121407\n",
      "[592]\tvalid_0's average_precision: 0.658321\tvalid_0's binary_logloss: 0.00121407\n",
      "[593]\tvalid_0's average_precision: 0.658324\tvalid_0's binary_logloss: 0.00121407\n",
      "[594]\tvalid_0's average_precision: 0.658314\tvalid_0's binary_logloss: 0.00121407\n",
      "[595]\tvalid_0's average_precision: 0.658323\tvalid_0's binary_logloss: 0.00121405\n",
      "[596]\tvalid_0's average_precision: 0.658333\tvalid_0's binary_logloss: 0.00121402\n",
      "[597]\tvalid_0's average_precision: 0.658335\tvalid_0's binary_logloss: 0.00121401\n",
      "[598]\tvalid_0's average_precision: 0.658328\tvalid_0's binary_logloss: 0.00121403\n",
      "[599]\tvalid_0's average_precision: 0.658328\tvalid_0's binary_logloss: 0.00121404\n",
      "[600]\tvalid_0's average_precision: 0.658333\tvalid_0's binary_logloss: 0.00121403\n",
      "[601]\tvalid_0's average_precision: 0.658331\tvalid_0's binary_logloss: 0.00121403\n",
      "[602]\tvalid_0's average_precision: 0.658322\tvalid_0's binary_logloss: 0.00121405\n",
      "[603]\tvalid_0's average_precision: 0.658326\tvalid_0's binary_logloss: 0.00121404\n",
      "[604]\tvalid_0's average_precision: 0.658328\tvalid_0's binary_logloss: 0.001214\n",
      "[605]\tvalid_0's average_precision: 0.658342\tvalid_0's binary_logloss: 0.00121399\n",
      "[606]\tvalid_0's average_precision: 0.65835\tvalid_0's binary_logloss: 0.00121395\n",
      "[607]\tvalid_0's average_precision: 0.658367\tvalid_0's binary_logloss: 0.0012139\n",
      "[608]\tvalid_0's average_precision: 0.658394\tvalid_0's binary_logloss: 0.00121383\n",
      "[609]\tvalid_0's average_precision: 0.658419\tvalid_0's binary_logloss: 0.00121376\n",
      "[610]\tvalid_0's average_precision: 0.658414\tvalid_0's binary_logloss: 0.00121377\n",
      "[611]\tvalid_0's average_precision: 0.658414\tvalid_0's binary_logloss: 0.00121378\n",
      "[612]\tvalid_0's average_precision: 0.658412\tvalid_0's binary_logloss: 0.00121378\n",
      "[613]\tvalid_0's average_precision: 0.658414\tvalid_0's binary_logloss: 0.00121377\n",
      "[614]\tvalid_0's average_precision: 0.658415\tvalid_0's binary_logloss: 0.00121376\n",
      "[615]\tvalid_0's average_precision: 0.658409\tvalid_0's binary_logloss: 0.00121375\n",
      "[616]\tvalid_0's average_precision: 0.65842\tvalid_0's binary_logloss: 0.00121373\n",
      "[617]\tvalid_0's average_precision: 0.658409\tvalid_0's binary_logloss: 0.00121375\n",
      "[618]\tvalid_0's average_precision: 0.658406\tvalid_0's binary_logloss: 0.00121375\n",
      "[619]\tvalid_0's average_precision: 0.658414\tvalid_0's binary_logloss: 0.00121373\n",
      "[620]\tvalid_0's average_precision: 0.658415\tvalid_0's binary_logloss: 0.00121373\n",
      "[621]\tvalid_0's average_precision: 0.658407\tvalid_0's binary_logloss: 0.00121373\n",
      "[622]\tvalid_0's average_precision: 0.658401\tvalid_0's binary_logloss: 0.00121374\n",
      "[623]\tvalid_0's average_precision: 0.658409\tvalid_0's binary_logloss: 0.00121372\n",
      "[624]\tvalid_0's average_precision: 0.658406\tvalid_0's binary_logloss: 0.00121373\n",
      "[625]\tvalid_0's average_precision: 0.658419\tvalid_0's binary_logloss: 0.00121371\n",
      "[626]\tvalid_0's average_precision: 0.658401\tvalid_0's binary_logloss: 0.00121372\n",
      "[627]\tvalid_0's average_precision: 0.658411\tvalid_0's binary_logloss: 0.00121372\n",
      "[628]\tvalid_0's average_precision: 0.65842\tvalid_0's binary_logloss: 0.00121371\n",
      "[629]\tvalid_0's average_precision: 0.658418\tvalid_0's binary_logloss: 0.00121373\n",
      "[630]\tvalid_0's average_precision: 0.658417\tvalid_0's binary_logloss: 0.00121373\n",
      "[631]\tvalid_0's average_precision: 0.658427\tvalid_0's binary_logloss: 0.00121373\n",
      "[632]\tvalid_0's average_precision: 0.658445\tvalid_0's binary_logloss: 0.00121368\n",
      "[633]\tvalid_0's average_precision: 0.658448\tvalid_0's binary_logloss: 0.00121369\n",
      "[634]\tvalid_0's average_precision: 0.658456\tvalid_0's binary_logloss: 0.00121363\n",
      "[635]\tvalid_0's average_precision: 0.658463\tvalid_0's binary_logloss: 0.00121358\n",
      "[636]\tvalid_0's average_precision: 0.658458\tvalid_0's binary_logloss: 0.00121358\n",
      "[637]\tvalid_0's average_precision: 0.65846\tvalid_0's binary_logloss: 0.00121357\n",
      "[638]\tvalid_0's average_precision: 0.658469\tvalid_0's binary_logloss: 0.00121355\n",
      "[639]\tvalid_0's average_precision: 0.658474\tvalid_0's binary_logloss: 0.00121353\n",
      "[640]\tvalid_0's average_precision: 0.658482\tvalid_0's binary_logloss: 0.00121352\n",
      "[641]\tvalid_0's average_precision: 0.658478\tvalid_0's binary_logloss: 0.00121353\n",
      "[642]\tvalid_0's average_precision: 0.658479\tvalid_0's binary_logloss: 0.00121354\n",
      "[643]\tvalid_0's average_precision: 0.658468\tvalid_0's binary_logloss: 0.00121353\n",
      "[644]\tvalid_0's average_precision: 0.65846\tvalid_0's binary_logloss: 0.00121353\n",
      "[645]\tvalid_0's average_precision: 0.658457\tvalid_0's binary_logloss: 0.00121353\n",
      "[646]\tvalid_0's average_precision: 0.658457\tvalid_0's binary_logloss: 0.00121352\n",
      "[647]\tvalid_0's average_precision: 0.658455\tvalid_0's binary_logloss: 0.00121352\n",
      "[648]\tvalid_0's average_precision: 0.658453\tvalid_0's binary_logloss: 0.00121352\n",
      "[649]\tvalid_0's average_precision: 0.658449\tvalid_0's binary_logloss: 0.00121354\n",
      "[650]\tvalid_0's average_precision: 0.65845\tvalid_0's binary_logloss: 0.00121355\n",
      "[651]\tvalid_0's average_precision: 0.658462\tvalid_0's binary_logloss: 0.00121352\n",
      "[652]\tvalid_0's average_precision: 0.658467\tvalid_0's binary_logloss: 0.00121349\n",
      "[653]\tvalid_0's average_precision: 0.658475\tvalid_0's binary_logloss: 0.00121345\n",
      "[654]\tvalid_0's average_precision: 0.658478\tvalid_0's binary_logloss: 0.00121343\n",
      "[655]\tvalid_0's average_precision: 0.658475\tvalid_0's binary_logloss: 0.00121344\n",
      "[656]\tvalid_0's average_precision: 0.65847\tvalid_0's binary_logloss: 0.00121344\n",
      "[657]\tvalid_0's average_precision: 0.658473\tvalid_0's binary_logloss: 0.00121343\n",
      "[658]\tvalid_0's average_precision: 0.658477\tvalid_0's binary_logloss: 0.00121343\n",
      "[659]\tvalid_0's average_precision: 0.658481\tvalid_0's binary_logloss: 0.00121343\n",
      "[660]\tvalid_0's average_precision: 0.658489\tvalid_0's binary_logloss: 0.00121343\n",
      "[661]\tvalid_0's average_precision: 0.658481\tvalid_0's binary_logloss: 0.00121346\n",
      "[662]\tvalid_0's average_precision: 0.658479\tvalid_0's binary_logloss: 0.00121347\n",
      "[663]\tvalid_0's average_precision: 0.658491\tvalid_0's binary_logloss: 0.00121345\n",
      "[664]\tvalid_0's average_precision: 0.658492\tvalid_0's binary_logloss: 0.00121344\n",
      "[665]\tvalid_0's average_precision: 0.658484\tvalid_0's binary_logloss: 0.00121346\n",
      "[666]\tvalid_0's average_precision: 0.658493\tvalid_0's binary_logloss: 0.00121343\n",
      "[667]\tvalid_0's average_precision: 0.658493\tvalid_0's binary_logloss: 0.00121342\n",
      "[668]\tvalid_0's average_precision: 0.658496\tvalid_0's binary_logloss: 0.00121341\n",
      "[669]\tvalid_0's average_precision: 0.6585\tvalid_0's binary_logloss: 0.0012134\n",
      "[670]\tvalid_0's average_precision: 0.658487\tvalid_0's binary_logloss: 0.0012134\n",
      "[671]\tvalid_0's average_precision: 0.658487\tvalid_0's binary_logloss: 0.00121338\n",
      "[672]\tvalid_0's average_precision: 0.658494\tvalid_0's binary_logloss: 0.00121338\n",
      "[673]\tvalid_0's average_precision: 0.658491\tvalid_0's binary_logloss: 0.00121339\n",
      "[674]\tvalid_0's average_precision: 0.658498\tvalid_0's binary_logloss: 0.00121339\n",
      "[675]\tvalid_0's average_precision: 0.658495\tvalid_0's binary_logloss: 0.0012134\n",
      "[676]\tvalid_0's average_precision: 0.658488\tvalid_0's binary_logloss: 0.00121339\n",
      "[677]\tvalid_0's average_precision: 0.658493\tvalid_0's binary_logloss: 0.00121337\n",
      "[678]\tvalid_0's average_precision: 0.658493\tvalid_0's binary_logloss: 0.00121337\n",
      "[679]\tvalid_0's average_precision: 0.658485\tvalid_0's binary_logloss: 0.00121338\n",
      "[680]\tvalid_0's average_precision: 0.658477\tvalid_0's binary_logloss: 0.00121338\n",
      "[681]\tvalid_0's average_precision: 0.658465\tvalid_0's binary_logloss: 0.0012134\n",
      "[682]\tvalid_0's average_precision: 0.658469\tvalid_0's binary_logloss: 0.00121339\n",
      "[683]\tvalid_0's average_precision: 0.658472\tvalid_0's binary_logloss: 0.00121339\n",
      "[684]\tvalid_0's average_precision: 0.658471\tvalid_0's binary_logloss: 0.00121339\n",
      "[685]\tvalid_0's average_precision: 0.65847\tvalid_0's binary_logloss: 0.0012134\n",
      "[686]\tvalid_0's average_precision: 0.658469\tvalid_0's binary_logloss: 0.0012134\n",
      "[687]\tvalid_0's average_precision: 0.658465\tvalid_0's binary_logloss: 0.00121343\n",
      "[688]\tvalid_0's average_precision: 0.65848\tvalid_0's binary_logloss: 0.00121338\n",
      "[689]\tvalid_0's average_precision: 0.658496\tvalid_0's binary_logloss: 0.00121332\n",
      "[690]\tvalid_0's average_precision: 0.658501\tvalid_0's binary_logloss: 0.00121325\n",
      "[691]\tvalid_0's average_precision: 0.658493\tvalid_0's binary_logloss: 0.00121326\n",
      "[692]\tvalid_0's average_precision: 0.658499\tvalid_0's binary_logloss: 0.00121324\n",
      "[693]\tvalid_0's average_precision: 0.658506\tvalid_0's binary_logloss: 0.00121323\n",
      "[694]\tvalid_0's average_precision: 0.658511\tvalid_0's binary_logloss: 0.00121321\n",
      "[695]\tvalid_0's average_precision: 0.65851\tvalid_0's binary_logloss: 0.0012132\n",
      "[696]\tvalid_0's average_precision: 0.658504\tvalid_0's binary_logloss: 0.00121322\n",
      "[697]\tvalid_0's average_precision: 0.65851\tvalid_0's binary_logloss: 0.00121321\n",
      "[698]\tvalid_0's average_precision: 0.658501\tvalid_0's binary_logloss: 0.00121323\n",
      "[699]\tvalid_0's average_precision: 0.658498\tvalid_0's binary_logloss: 0.00121323\n",
      "[700]\tvalid_0's average_precision: 0.658503\tvalid_0's binary_logloss: 0.0012132\n",
      "[701]\tvalid_0's average_precision: 0.658512\tvalid_0's binary_logloss: 0.00121318\n",
      "[702]\tvalid_0's average_precision: 0.658518\tvalid_0's binary_logloss: 0.00121314\n",
      "[703]\tvalid_0's average_precision: 0.658517\tvalid_0's binary_logloss: 0.00121314\n",
      "[704]\tvalid_0's average_precision: 0.658521\tvalid_0's binary_logloss: 0.00121314\n",
      "[705]\tvalid_0's average_precision: 0.658519\tvalid_0's binary_logloss: 0.00121313\n",
      "[706]\tvalid_0's average_precision: 0.658516\tvalid_0's binary_logloss: 0.00121311\n",
      "[707]\tvalid_0's average_precision: 0.658511\tvalid_0's binary_logloss: 0.0012131\n",
      "[708]\tvalid_0's average_precision: 0.658509\tvalid_0's binary_logloss: 0.0012131\n",
      "[709]\tvalid_0's average_precision: 0.658511\tvalid_0's binary_logloss: 0.00121309\n",
      "[710]\tvalid_0's average_precision: 0.65851\tvalid_0's binary_logloss: 0.00121309\n",
      "[711]\tvalid_0's average_precision: 0.658517\tvalid_0's binary_logloss: 0.00121308\n",
      "[712]\tvalid_0's average_precision: 0.658517\tvalid_0's binary_logloss: 0.00121307\n",
      "[713]\tvalid_0's average_precision: 0.658518\tvalid_0's binary_logloss: 0.00121307\n",
      "[714]\tvalid_0's average_precision: 0.658512\tvalid_0's binary_logloss: 0.00121309\n",
      "[715]\tvalid_0's average_precision: 0.658516\tvalid_0's binary_logloss: 0.00121309\n",
      "[716]\tvalid_0's average_precision: 0.658517\tvalid_0's binary_logloss: 0.0012131\n",
      "[717]\tvalid_0's average_precision: 0.658523\tvalid_0's binary_logloss: 0.0012131\n",
      "[718]\tvalid_0's average_precision: 0.658528\tvalid_0's binary_logloss: 0.00121308\n",
      "[719]\tvalid_0's average_precision: 0.65853\tvalid_0's binary_logloss: 0.00121308\n",
      "[720]\tvalid_0's average_precision: 0.658531\tvalid_0's binary_logloss: 0.00121308\n",
      "[721]\tvalid_0's average_precision: 0.658527\tvalid_0's binary_logloss: 0.00121307\n",
      "[722]\tvalid_0's average_precision: 0.658521\tvalid_0's binary_logloss: 0.00121308\n",
      "[723]\tvalid_0's average_precision: 0.65851\tvalid_0's binary_logloss: 0.00121309\n",
      "[724]\tvalid_0's average_precision: 0.658512\tvalid_0's binary_logloss: 0.00121309\n",
      "[725]\tvalid_0's average_precision: 0.658512\tvalid_0's binary_logloss: 0.00121309\n",
      "[726]\tvalid_0's average_precision: 0.658507\tvalid_0's binary_logloss: 0.00121308\n",
      "[727]\tvalid_0's average_precision: 0.658511\tvalid_0's binary_logloss: 0.00121304\n",
      "[728]\tvalid_0's average_precision: 0.658511\tvalid_0's binary_logloss: 0.00121303\n",
      "[729]\tvalid_0's average_precision: 0.658513\tvalid_0's binary_logloss: 0.00121301\n",
      "[730]\tvalid_0's average_precision: 0.65851\tvalid_0's binary_logloss: 0.00121302\n",
      "[731]\tvalid_0's average_precision: 0.658507\tvalid_0's binary_logloss: 0.00121303\n",
      "[732]\tvalid_0's average_precision: 0.658514\tvalid_0's binary_logloss: 0.00121302\n",
      "[733]\tvalid_0's average_precision: 0.65851\tvalid_0's binary_logloss: 0.00121302\n",
      "[734]\tvalid_0's average_precision: 0.65851\tvalid_0's binary_logloss: 0.00121302\n",
      "[735]\tvalid_0's average_precision: 0.6585\tvalid_0's binary_logloss: 0.00121303\n",
      "[736]\tvalid_0's average_precision: 0.658502\tvalid_0's binary_logloss: 0.00121303\n",
      "[737]\tvalid_0's average_precision: 0.658501\tvalid_0's binary_logloss: 0.00121304\n",
      "[738]\tvalid_0's average_precision: 0.658503\tvalid_0's binary_logloss: 0.00121304\n",
      "[739]\tvalid_0's average_precision: 0.658508\tvalid_0's binary_logloss: 0.00121303\n",
      "[740]\tvalid_0's average_precision: 0.658508\tvalid_0's binary_logloss: 0.00121303\n",
      "[741]\tvalid_0's average_precision: 0.658514\tvalid_0's binary_logloss: 0.00121302\n",
      "[742]\tvalid_0's average_precision: 0.658531\tvalid_0's binary_logloss: 0.00121287\n",
      "[743]\tvalid_0's average_precision: 0.658538\tvalid_0's binary_logloss: 0.00121284\n",
      "[744]\tvalid_0's average_precision: 0.658561\tvalid_0's binary_logloss: 0.00121271\n",
      "[745]\tvalid_0's average_precision: 0.658558\tvalid_0's binary_logloss: 0.00121272\n",
      "[746]\tvalid_0's average_precision: 0.658552\tvalid_0's binary_logloss: 0.00121273\n",
      "[747]\tvalid_0's average_precision: 0.658556\tvalid_0's binary_logloss: 0.00121271\n",
      "[748]\tvalid_0's average_precision: 0.65856\tvalid_0's binary_logloss: 0.00121271\n",
      "[749]\tvalid_0's average_precision: 0.658563\tvalid_0's binary_logloss: 0.00121271\n",
      "[750]\tvalid_0's average_precision: 0.658565\tvalid_0's binary_logloss: 0.00121272\n",
      "[751]\tvalid_0's average_precision: 0.658568\tvalid_0's binary_logloss: 0.00121271\n",
      "[752]\tvalid_0's average_precision: 0.658561\tvalid_0's binary_logloss: 0.00121273\n",
      "[753]\tvalid_0's average_precision: 0.658557\tvalid_0's binary_logloss: 0.00121272\n",
      "[754]\tvalid_0's average_precision: 0.658553\tvalid_0's binary_logloss: 0.00121273\n",
      "[755]\tvalid_0's average_precision: 0.65856\tvalid_0's binary_logloss: 0.00121273\n",
      "[756]\tvalid_0's average_precision: 0.658558\tvalid_0's binary_logloss: 0.00121273\n",
      "[757]\tvalid_0's average_precision: 0.658562\tvalid_0's binary_logloss: 0.00121271\n",
      "[758]\tvalid_0's average_precision: 0.658566\tvalid_0's binary_logloss: 0.00121272\n",
      "[759]\tvalid_0's average_precision: 0.658577\tvalid_0's binary_logloss: 0.00121268\n",
      "[760]\tvalid_0's average_precision: 0.658572\tvalid_0's binary_logloss: 0.00121269\n",
      "[761]\tvalid_0's average_precision: 0.658566\tvalid_0's binary_logloss: 0.00121269\n",
      "[762]\tvalid_0's average_precision: 0.658565\tvalid_0's binary_logloss: 0.00121267\n",
      "[763]\tvalid_0's average_precision: 0.658568\tvalid_0's binary_logloss: 0.00121267\n",
      "[764]\tvalid_0's average_precision: 0.658565\tvalid_0's binary_logloss: 0.00121266\n",
      "[765]\tvalid_0's average_precision: 0.658565\tvalid_0's binary_logloss: 0.00121266\n",
      "[766]\tvalid_0's average_precision: 0.658563\tvalid_0's binary_logloss: 0.00121265\n",
      "[767]\tvalid_0's average_precision: 0.65857\tvalid_0's binary_logloss: 0.00121265\n",
      "[768]\tvalid_0's average_precision: 0.658578\tvalid_0's binary_logloss: 0.00121262\n",
      "[769]\tvalid_0's average_precision: 0.658583\tvalid_0's binary_logloss: 0.00121262\n",
      "[770]\tvalid_0's average_precision: 0.658578\tvalid_0's binary_logloss: 0.00121262\n",
      "[771]\tvalid_0's average_precision: 0.658578\tvalid_0's binary_logloss: 0.00121261\n",
      "[772]\tvalid_0's average_precision: 0.658578\tvalid_0's binary_logloss: 0.0012126\n",
      "[773]\tvalid_0's average_precision: 0.658582\tvalid_0's binary_logloss: 0.0012126\n",
      "[774]\tvalid_0's average_precision: 0.658588\tvalid_0's binary_logloss: 0.00121259\n",
      "[775]\tvalid_0's average_precision: 0.658589\tvalid_0's binary_logloss: 0.00121259\n",
      "[776]\tvalid_0's average_precision: 0.65859\tvalid_0's binary_logloss: 0.0012126\n",
      "[777]\tvalid_0's average_precision: 0.658593\tvalid_0's binary_logloss: 0.00121259\n",
      "[778]\tvalid_0's average_precision: 0.6586\tvalid_0's binary_logloss: 0.00121257\n",
      "[779]\tvalid_0's average_precision: 0.658594\tvalid_0's binary_logloss: 0.00121258\n",
      "[780]\tvalid_0's average_precision: 0.658598\tvalid_0's binary_logloss: 0.00121257\n",
      "[781]\tvalid_0's average_precision: 0.658599\tvalid_0's binary_logloss: 0.00121254\n",
      "[782]\tvalid_0's average_precision: 0.658603\tvalid_0's binary_logloss: 0.0012125\n",
      "[783]\tvalid_0's average_precision: 0.658598\tvalid_0's binary_logloss: 0.00121248\n",
      "[784]\tvalid_0's average_precision: 0.658602\tvalid_0's binary_logloss: 0.00121248\n",
      "[785]\tvalid_0's average_precision: 0.658597\tvalid_0's binary_logloss: 0.00121248\n",
      "[786]\tvalid_0's average_precision: 0.658597\tvalid_0's binary_logloss: 0.00121248\n",
      "[787]\tvalid_0's average_precision: 0.658602\tvalid_0's binary_logloss: 0.00121247\n",
      "[788]\tvalid_0's average_precision: 0.658604\tvalid_0's binary_logloss: 0.00121248\n",
      "[789]\tvalid_0's average_precision: 0.658603\tvalid_0's binary_logloss: 0.00121249\n",
      "[790]\tvalid_0's average_precision: 0.658602\tvalid_0's binary_logloss: 0.0012125\n",
      "[791]\tvalid_0's average_precision: 0.658608\tvalid_0's binary_logloss: 0.0012125\n",
      "[792]\tvalid_0's average_precision: 0.658609\tvalid_0's binary_logloss: 0.0012125\n",
      "[793]\tvalid_0's average_precision: 0.658609\tvalid_0's binary_logloss: 0.00121246\n",
      "[794]\tvalid_0's average_precision: 0.658605\tvalid_0's binary_logloss: 0.00121243\n",
      "[795]\tvalid_0's average_precision: 0.6586\tvalid_0's binary_logloss: 0.00121244\n",
      "[796]\tvalid_0's average_precision: 0.658616\tvalid_0's binary_logloss: 0.00121242\n",
      "[797]\tvalid_0's average_precision: 0.658613\tvalid_0's binary_logloss: 0.00121242\n",
      "[798]\tvalid_0's average_precision: 0.658617\tvalid_0's binary_logloss: 0.00121239\n",
      "[799]\tvalid_0's average_precision: 0.658624\tvalid_0's binary_logloss: 0.00121236\n",
      "[800]\tvalid_0's average_precision: 0.658627\tvalid_0's binary_logloss: 0.00121233\n",
      "[801]\tvalid_0's average_precision: 0.658634\tvalid_0's binary_logloss: 0.00121227\n",
      "[802]\tvalid_0's average_precision: 0.658642\tvalid_0's binary_logloss: 0.00121227\n",
      "[803]\tvalid_0's average_precision: 0.658647\tvalid_0's binary_logloss: 0.00121227\n",
      "[804]\tvalid_0's average_precision: 0.658659\tvalid_0's binary_logloss: 0.00121219\n",
      "[805]\tvalid_0's average_precision: 0.65865\tvalid_0's binary_logloss: 0.00121221\n",
      "[806]\tvalid_0's average_precision: 0.65865\tvalid_0's binary_logloss: 0.00121221\n",
      "[807]\tvalid_0's average_precision: 0.658651\tvalid_0's binary_logloss: 0.00121221\n",
      "[808]\tvalid_0's average_precision: 0.658661\tvalid_0's binary_logloss: 0.00121221\n",
      "[809]\tvalid_0's average_precision: 0.658656\tvalid_0's binary_logloss: 0.00121222\n",
      "[810]\tvalid_0's average_precision: 0.658652\tvalid_0's binary_logloss: 0.00121222\n",
      "[811]\tvalid_0's average_precision: 0.658659\tvalid_0's binary_logloss: 0.0012122\n",
      "[812]\tvalid_0's average_precision: 0.658659\tvalid_0's binary_logloss: 0.00121218\n",
      "[813]\tvalid_0's average_precision: 0.658653\tvalid_0's binary_logloss: 0.00121219\n",
      "[814]\tvalid_0's average_precision: 0.658655\tvalid_0's binary_logloss: 0.00121219\n",
      "[815]\tvalid_0's average_precision: 0.658656\tvalid_0's binary_logloss: 0.00121218\n",
      "[816]\tvalid_0's average_precision: 0.65866\tvalid_0's binary_logloss: 0.00121216\n",
      "[817]\tvalid_0's average_precision: 0.658665\tvalid_0's binary_logloss: 0.00121214\n",
      "[818]\tvalid_0's average_precision: 0.658666\tvalid_0's binary_logloss: 0.00121213\n",
      "[819]\tvalid_0's average_precision: 0.658667\tvalid_0's binary_logloss: 0.00121213\n",
      "[820]\tvalid_0's average_precision: 0.65867\tvalid_0's binary_logloss: 0.00121213\n",
      "[821]\tvalid_0's average_precision: 0.658662\tvalid_0's binary_logloss: 0.00121215\n",
      "[822]\tvalid_0's average_precision: 0.658659\tvalid_0's binary_logloss: 0.00121216\n",
      "[823]\tvalid_0's average_precision: 0.65866\tvalid_0's binary_logloss: 0.00121212\n",
      "[824]\tvalid_0's average_precision: 0.658665\tvalid_0's binary_logloss: 0.0012121\n",
      "[825]\tvalid_0's average_precision: 0.658672\tvalid_0's binary_logloss: 0.00121196\n",
      "[826]\tvalid_0's average_precision: 0.658682\tvalid_0's binary_logloss: 0.00121196\n",
      "[827]\tvalid_0's average_precision: 0.658684\tvalid_0's binary_logloss: 0.00121196\n",
      "[828]\tvalid_0's average_precision: 0.658692\tvalid_0's binary_logloss: 0.00121197\n",
      "[829]\tvalid_0's average_precision: 0.658695\tvalid_0's binary_logloss: 0.00121197\n",
      "[830]\tvalid_0's average_precision: 0.658694\tvalid_0's binary_logloss: 0.00121198\n",
      "[831]\tvalid_0's average_precision: 0.658695\tvalid_0's binary_logloss: 0.001212\n",
      "[832]\tvalid_0's average_precision: 0.658694\tvalid_0's binary_logloss: 0.00121198\n",
      "[833]\tvalid_0's average_precision: 0.658693\tvalid_0's binary_logloss: 0.00121198\n",
      "[834]\tvalid_0's average_precision: 0.658686\tvalid_0's binary_logloss: 0.00121194\n",
      "[835]\tvalid_0's average_precision: 0.658687\tvalid_0's binary_logloss: 0.00121194\n",
      "[836]\tvalid_0's average_precision: 0.658685\tvalid_0's binary_logloss: 0.00121194\n",
      "[837]\tvalid_0's average_precision: 0.65868\tvalid_0's binary_logloss: 0.00121195\n",
      "[838]\tvalid_0's average_precision: 0.658678\tvalid_0's binary_logloss: 0.00121195\n",
      "[839]\tvalid_0's average_precision: 0.658674\tvalid_0's binary_logloss: 0.00121197\n",
      "[840]\tvalid_0's average_precision: 0.65867\tvalid_0's binary_logloss: 0.00121196\n",
      "[841]\tvalid_0's average_precision: 0.658664\tvalid_0's binary_logloss: 0.00121197\n",
      "[842]\tvalid_0's average_precision: 0.658668\tvalid_0's binary_logloss: 0.00121197\n",
      "[843]\tvalid_0's average_precision: 0.658672\tvalid_0's binary_logloss: 0.00121196\n",
      "[844]\tvalid_0's average_precision: 0.658677\tvalid_0's binary_logloss: 0.00121197\n",
      "[845]\tvalid_0's average_precision: 0.658684\tvalid_0's binary_logloss: 0.00121198\n",
      "[846]\tvalid_0's average_precision: 0.658689\tvalid_0's binary_logloss: 0.00121196\n",
      "[847]\tvalid_0's average_precision: 0.658694\tvalid_0's binary_logloss: 0.00121195\n",
      "[848]\tvalid_0's average_precision: 0.658696\tvalid_0's binary_logloss: 0.00121193\n",
      "[849]\tvalid_0's average_precision: 0.658701\tvalid_0's binary_logloss: 0.00121193\n",
      "[850]\tvalid_0's average_precision: 0.658708\tvalid_0's binary_logloss: 0.00121193\n",
      "[851]\tvalid_0's average_precision: 0.658713\tvalid_0's binary_logloss: 0.00121194\n",
      "[852]\tvalid_0's average_precision: 0.658722\tvalid_0's binary_logloss: 0.00121192\n",
      "[853]\tvalid_0's average_precision: 0.65874\tvalid_0's binary_logloss: 0.00121185\n",
      "[854]\tvalid_0's average_precision: 0.658757\tvalid_0's binary_logloss: 0.00121178\n",
      "[855]\tvalid_0's average_precision: 0.658768\tvalid_0's binary_logloss: 0.00121172\n",
      "[856]\tvalid_0's average_precision: 0.658764\tvalid_0's binary_logloss: 0.00121172\n",
      "[857]\tvalid_0's average_precision: 0.658771\tvalid_0's binary_logloss: 0.00121172\n",
      "[858]\tvalid_0's average_precision: 0.658768\tvalid_0's binary_logloss: 0.00121173\n",
      "[859]\tvalid_0's average_precision: 0.658777\tvalid_0's binary_logloss: 0.0012117\n",
      "[860]\tvalid_0's average_precision: 0.658781\tvalid_0's binary_logloss: 0.00121165\n",
      "[861]\tvalid_0's average_precision: 0.658778\tvalid_0's binary_logloss: 0.00121161\n",
      "[862]\tvalid_0's average_precision: 0.658781\tvalid_0's binary_logloss: 0.0012116\n",
      "[863]\tvalid_0's average_precision: 0.658791\tvalid_0's binary_logloss: 0.00121158\n",
      "[864]\tvalid_0's average_precision: 0.658781\tvalid_0's binary_logloss: 0.0012116\n",
      "[865]\tvalid_0's average_precision: 0.658782\tvalid_0's binary_logloss: 0.00121156\n",
      "[866]\tvalid_0's average_precision: 0.658792\tvalid_0's binary_logloss: 0.00121148\n",
      "[867]\tvalid_0's average_precision: 0.658795\tvalid_0's binary_logloss: 0.00121146\n",
      "[868]\tvalid_0's average_precision: 0.658801\tvalid_0's binary_logloss: 0.00121145\n",
      "[869]\tvalid_0's average_precision: 0.658801\tvalid_0's binary_logloss: 0.00121143\n",
      "[870]\tvalid_0's average_precision: 0.658799\tvalid_0's binary_logloss: 0.00121144\n",
      "[871]\tvalid_0's average_precision: 0.658803\tvalid_0's binary_logloss: 0.00121142\n",
      "[872]\tvalid_0's average_precision: 0.658812\tvalid_0's binary_logloss: 0.00121141\n",
      "[873]\tvalid_0's average_precision: 0.658817\tvalid_0's binary_logloss: 0.0012114\n",
      "[874]\tvalid_0's average_precision: 0.658814\tvalid_0's binary_logloss: 0.00121141\n",
      "[875]\tvalid_0's average_precision: 0.65882\tvalid_0's binary_logloss: 0.00121141\n",
      "[876]\tvalid_0's average_precision: 0.658819\tvalid_0's binary_logloss: 0.00121141\n",
      "[877]\tvalid_0's average_precision: 0.658822\tvalid_0's binary_logloss: 0.00121141\n",
      "[878]\tvalid_0's average_precision: 0.658829\tvalid_0's binary_logloss: 0.0012114\n",
      "[879]\tvalid_0's average_precision: 0.658821\tvalid_0's binary_logloss: 0.00121142\n",
      "[880]\tvalid_0's average_precision: 0.658824\tvalid_0's binary_logloss: 0.00121143\n",
      "[881]\tvalid_0's average_precision: 0.658825\tvalid_0's binary_logloss: 0.00121145\n",
      "[882]\tvalid_0's average_precision: 0.658833\tvalid_0's binary_logloss: 0.00121145\n",
      "[883]\tvalid_0's average_precision: 0.658827\tvalid_0's binary_logloss: 0.00121142\n",
      "[884]\tvalid_0's average_precision: 0.658834\tvalid_0's binary_logloss: 0.00121141\n",
      "[885]\tvalid_0's average_precision: 0.658819\tvalid_0's binary_logloss: 0.00121143\n",
      "[886]\tvalid_0's average_precision: 0.658834\tvalid_0's binary_logloss: 0.0012114\n",
      "[887]\tvalid_0's average_precision: 0.658828\tvalid_0's binary_logloss: 0.00121141\n",
      "[888]\tvalid_0's average_precision: 0.658825\tvalid_0's binary_logloss: 0.00121142\n",
      "[889]\tvalid_0's average_precision: 0.658827\tvalid_0's binary_logloss: 0.00121141\n",
      "[890]\tvalid_0's average_precision: 0.658831\tvalid_0's binary_logloss: 0.00121141\n",
      "[891]\tvalid_0's average_precision: 0.658825\tvalid_0's binary_logloss: 0.00121143\n",
      "[892]\tvalid_0's average_precision: 0.658819\tvalid_0's binary_logloss: 0.00121138\n",
      "[893]\tvalid_0's average_precision: 0.658813\tvalid_0's binary_logloss: 0.00121134\n",
      "[894]\tvalid_0's average_precision: 0.65881\tvalid_0's binary_logloss: 0.00121129\n",
      "[895]\tvalid_0's average_precision: 0.658818\tvalid_0's binary_logloss: 0.00121128\n",
      "[896]\tvalid_0's average_precision: 0.658815\tvalid_0's binary_logloss: 0.00121128\n",
      "[897]\tvalid_0's average_precision: 0.658813\tvalid_0's binary_logloss: 0.00121128\n",
      "[898]\tvalid_0's average_precision: 0.658815\tvalid_0's binary_logloss: 0.00121127\n",
      "[899]\tvalid_0's average_precision: 0.658811\tvalid_0's binary_logloss: 0.00121128\n",
      "[900]\tvalid_0's average_precision: 0.658808\tvalid_0's binary_logloss: 0.00121129\n",
      "[901]\tvalid_0's average_precision: 0.6588\tvalid_0's binary_logloss: 0.00121129\n",
      "[902]\tvalid_0's average_precision: 0.658801\tvalid_0's binary_logloss: 0.00121128\n",
      "[903]\tvalid_0's average_precision: 0.658808\tvalid_0's binary_logloss: 0.00121127\n",
      "[904]\tvalid_0's average_precision: 0.65881\tvalid_0's binary_logloss: 0.00121127\n",
      "[905]\tvalid_0's average_precision: 0.658803\tvalid_0's binary_logloss: 0.00121129\n",
      "[906]\tvalid_0's average_precision: 0.658802\tvalid_0's binary_logloss: 0.00121129\n",
      "[907]\tvalid_0's average_precision: 0.658804\tvalid_0's binary_logloss: 0.00121129\n",
      "[908]\tvalid_0's average_precision: 0.658805\tvalid_0's binary_logloss: 0.00121127\n",
      "[909]\tvalid_0's average_precision: 0.6588\tvalid_0's binary_logloss: 0.00121128\n",
      "[910]\tvalid_0's average_precision: 0.658795\tvalid_0's binary_logloss: 0.00121128\n",
      "[911]\tvalid_0's average_precision: 0.658794\tvalid_0's binary_logloss: 0.00121128\n",
      "[912]\tvalid_0's average_precision: 0.658801\tvalid_0's binary_logloss: 0.00121127\n",
      "[913]\tvalid_0's average_precision: 0.658806\tvalid_0's binary_logloss: 0.00121126\n",
      "[914]\tvalid_0's average_precision: 0.658813\tvalid_0's binary_logloss: 0.00121127\n",
      "[915]\tvalid_0's average_precision: 0.65882\tvalid_0's binary_logloss: 0.00121126\n",
      "[916]\tvalid_0's average_precision: 0.65882\tvalid_0's binary_logloss: 0.00121127\n",
      "[917]\tvalid_0's average_precision: 0.658818\tvalid_0's binary_logloss: 0.00121129\n",
      "[918]\tvalid_0's average_precision: 0.658819\tvalid_0's binary_logloss: 0.00121127\n",
      "[919]\tvalid_0's average_precision: 0.658827\tvalid_0's binary_logloss: 0.00121127\n",
      "[920]\tvalid_0's average_precision: 0.658832\tvalid_0's binary_logloss: 0.00121127\n",
      "[921]\tvalid_0's average_precision: 0.658834\tvalid_0's binary_logloss: 0.00121126\n",
      "[922]\tvalid_0's average_precision: 0.658833\tvalid_0's binary_logloss: 0.00121125\n",
      "[923]\tvalid_0's average_precision: 0.658824\tvalid_0's binary_logloss: 0.00121126\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Train model"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model_idx = 0\n",
    "model_name = f\"Model {model_idx}\"\n",
    "\n",
    "gbm = lgb.train(\n",
    "    params,\n",
    "    train_data,\n",
    "    num_boost_round=NUM_BOOST_ROUND,\n",
    "    valid_sets=[train_data, valid_data],\n",
    "    valid_names=[\"train\", \"valid\"],\n",
    "    callbacks=[\n",
    "        early_stopping(stopping_rounds=EARLY_STOPPING_ROUNDS),\n",
    "        log_evaluation(period=5)\n",
    "    ]\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "best_iter = gbm.best_iteration\n",
    "gbm.save_model(f\"{OUTPUT_DIR}/model_{model_idx}_{datetime.now().strftime(\"%Y%m%d%H%M\")}.txt\", num_iteration=best_iter)\n",
    "print(\"best_iteration:\", best_iter)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Predict\n",
    "\n",
    "Produce predictions on validation set"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "y_valid_predict = gbm.predict(X_valid, num_iteration=best_iter)",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Evaluate predictions"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "y_valid_predict_auc = roc_auc_score(y_valid, y_valid_predict)\n",
    "y_valid_predict_ap  = average_precision_score(y_valid, y_valid_predict)   # this is \"average_precision\"\n",
    "y_valid_predict_ll  = log_loss(y_valid, y_valid_predict, labels=[0, 1])   # this is \"binary_logloss\"\n",
    "\n",
    "print(f\"Validation AUC:      {y_valid_predict_auc:.4f}\")\n",
    "print(f\"Validation AP:       {y_valid_predict_ap:.6f}\")\n",
    "print(f\"Validation log loss: {y_valid_predict_ll:.6f}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "auc = roc_auc_score(y_valid, y_valid_predict)\n",
    "ap  = average_precision_score(y_valid, y_valid_predict)   # this is \"average_precision\"\n",
    "ll  = log_loss(y_valid, y_valid_predict, labels=[0, 1])   # this is \"binary_logloss\"\n",
    "\n",
    "print(f\"Validation AUC:      {auc:.4f}\")\n",
    "print(f\"Validation AP:       {ap:.6f}\")\n",
    "print(f\"Validation log loss: {ll:.6f}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "importance_gain = gbm.feature_importance(importance_type=\"gain\")\n",
    "\n",
    "df_imp_gain = pd.DataFrame({\n",
    "    \"feature\": features,\n",
    "    \"importance_gain\": importance_gain\n",
    "}).sort_values(\"importance_gain\", ascending=False)\n",
    "\n",
    "df_imp_gain.to_csv(f\"{OUTPUT_DIR}/model_{model_idx}_importance_gain_{datetime.now().strftime(\"%Y%m%d%H%M\")}.csv\", index=False)\n",
    "df_imp_gain"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Feature importance"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "importance_gain = gbm.feature_importance(importance_type=\"gain\")\n",
    "\n",
    "df_imp_gain = pd.DataFrame({\n",
    "    \"feature\": features,\n",
    "    \"importance_gain\": importance_gain\n",
    "}).sort_values(\"importance_gain\", ascending=False)\n",
    "\n",
    "df_imp_gain.to_csv(f\"./output/importance_gain_{datetime.now().strftime(\"%Y%m%d%H%M\")}.csv\", index=False)\n",
    "df_imp_gain"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Evaluation subset for permutation importances and SHAP analysis"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "result = permutation_importance(\n",
    "    model_wrapped,\n",
    "    X_eval,\n",
    "    y_eval,\n",
    "    scoring=ap_scorer,\n",
    "    n_repeats=10,\n",
    "    n_jobs=NUM_THREADS,\n",
    "    random_state=RANDOM_SEED,\n",
    ")\n",
    "\n",
    "perm_importance = pd.DataFrame({\n",
    "    \"feature\": X_eval.columns,\n",
    "    \"importance_mean\": result.importances_mean,\n",
    "    \"importance_std\": result.importances_std,\n",
    "}).sort_values(\"importance_mean\", ascending=False)\n",
    "\n",
    "perm_importance.to_csv(f\"{OUTPUT_DIR}/permutation_importance_{datetime.now().strftime(\"%Y%m%d%H%M\")}.csv\", index=False)\n",
    "perm_importance"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def ap_scorer(estimator, X, y):\n",
    "    proba = estimator.predict_proba(X)[:, 1]\n",
    "    return average_precision_score(y, proba)\n",
    "\n",
    "\n",
    "class LGBMWrapper:\n",
    "    def __init__(self, booster):\n",
    "        self.booster = booster\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # Required by sklearn API; we don't actually train here.\n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        # LightGBM Booster.predict gives P(y=1) for binary by default\n",
    "        p1 = self.booster.predict(X)\n",
    "        p0 = 1.0 - p1\n",
    "        return np.column_stack([p0, p1])\n",
    "\n",
    "    def predict(self, X):\n",
    "        p1 = self.booster.predict(X)\n",
    "        return (p1 >= 0.5).astype(int)\n",
    "\n",
    "\n",
    "model_wrapped = LGBMWrapper(gbm)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "result = permutation_importance(\n",
    "    model_wrapped,\n",
    "    X_eval,\n",
    "    y_eval,\n",
    "    scoring=ap_scorer,\n",
    "    n_repeats=5,\n",
    "    n_jobs=4,\n",
    "    random_state=RANDOM_SEED,\n",
    ")\n",
    "\n",
    "perm_importance = pd.DataFrame({\n",
    "    \"feature\": X_eval.columns,\n",
    "    \"importance_mean\": result.importances_mean,\n",
    "    \"importance_std\": result.importances_std,\n",
    "}).sort_values(\"importance_mean\", ascending=False)\n",
    "\n",
    "perm_importance.to_csv(f\"./output/permutation_importance_{datetime.now().strftime(\"%Y%m%d%H%M\")}.csv\", index=False)\n",
    "perm_importance"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "# need not NA - some columns have many NAs\n",
    "distance_0, corr_0 = stats_utils.distance_corr_dissimilarity(X_eval)\n",
    "condensed_0 = squareform(distance_0, checks=True)\n",
    "dist_linkage_0 = hierarchy.ward(condensed_0)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.figure(figsize=(8, 20))\n",
    "dendro_0 = hierarchy.dendrogram(dist_linkage_0, labels=X_eval.columns.to_list(), orientation=\"right\", ax=plt.axes())\n",
    "plt.vlines(0.5, 0, 500, linestyle=\"--\", color=\"#b2b4549f\", linewidth=2)\n",
    "plt.xlabel(\"Ward linkage distance (increase in within-cluster variance)\")\n",
    "plt.ylabel(\"Predictors\")\n",
    "plt.title(f\"Model 0: Hierarchical clustering of predictors\")\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "dendro_0_idx = np.arange(0, len(dendro_0[\"ivl\"]))\n",
    "\n",
    "with plt.rc_context({'ytick.labelsize': 12, 'xtick.labelsize': 12, 'axes.titlesize': 12}):\n",
    "    plt.figure(figsize=(18, 18))\n",
    "    plt.set_cmap(\"viridis\")\n",
    "    ax = plt.axes()\n",
    "    im = ax.imshow(corr_0[dendro_0[\"leaves\"], :][:, dendro_0[\"leaves\"]])\n",
    "    ax.set_title(f\"Model: Correlation heatmap of predictors\")\n",
    "    ax.set_xticks(dendro_0_idx)\n",
    "    ax.set_yticks(dendro_0_idx)\n",
    "    ax.set_xticklabels(dendro_0[\"ivl\"], rotation=\"vertical\")\n",
    "    ax.set_yticklabels(dendro_0[\"ivl\"])\n",
    "    plt.colorbar(im, ax=ax, fraction=0.03, pad=0.025)\n",
    "    plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Tell SHAP this is a LightGBM model\n",
    "explainer = shap.TreeExplainer(gbm)\n",
    "explanation = explainer(X_eval)\n",
    "clustering_0 = shap.utils.hclust(X_eval, y_eval, linkage=\"average\", random_state=RANDOM_SEED)\n",
    "shap_values = explanation.values\n",
    "\n",
    "# Handle both cases: list or array\n",
    "if isinstance(shap_values, list):\n",
    "    shap_pos = shap_values[1]  # SHAP values for positive class\n",
    "else:\n",
    "    shap_pos = shap_values  # already positive class\n",
    "\n",
    "# Global importance: mean |SHAP|\n",
    "shap_importance = pd.DataFrame({\n",
    "    \"feature\": X_shap.columns,\n",
    "    \"mean_abs_shap\": np.mean(np.abs(shap_pos), axis=0),\n",
    "}).sort_values(\"mean_abs_shap\", ascending=False)\n",
    "\n",
    "shap_importance.to_csv(f\"{OUTPUT_DIR}/model_{model_idx}_shap_importance_{datetime.now().strftime(\"%Y%m%d%H%M\")}.csv\", index=False)\n",
    "shap_importance"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We cannot plot millions of observations, so for SHAP analysis, we take a random selection of 10,000 positives and 50,000 negatives."
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Tell SHAP this is a LightGBM model\n",
    "explainer = shap.TreeExplainer(gbm)\n",
    "explanation = explainer(X_eval)\n",
    "clustering_0 = shap.utils.hclust(X_eval, y_eval, linkage=\"average\", random_state=RANDOM_SEED)\n",
    "shap_values = explanation.values\n",
    "\n",
    "# Handle both cases: list or array\n",
    "if isinstance(shap_values, list):\n",
    "    shap_pos = shap_values[1]  # SHAP values for positive class\n",
    "else:\n",
    "    shap_pos = shap_values  # already positive class\n",
    "\n",
    "# Global importance: mean |SHAP|\n",
    "shap_importance = pd.DataFrame({\n",
    "    \"feature\": X_shap.columns,\n",
    "    \"mean_abs_shap\": np.mean(np.abs(shap_pos), axis=0),\n",
    "}).sort_values(\"mean_abs_shap\", ascending=False)\n",
    "\n",
    "shap_importance.to_csv(f\"./output/shap_importance_{datetime.now().strftime(\"%Y%m%d%H%M\")}.csv\", index=False)\n",
    "shap_importance"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "with plt.rc_context({'axes.titlesize': 12}):\n",
    "    plot = plt.figure(figsize=(8, 16))\n",
    "    ax = plot.subplots()\n",
    "    ax.set_title(f\"Model 0: SHAP values for predictor variables across all samples\")\n",
    "    shap.plots.bar(explanation, max_display=40, ax=ax) # clustering=clustering_0,"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "with plt.rc_context({'axes.titlesize': 12}):\n",
    "    plot = plt.figure()\n",
    "    ax = plot.subplots()\n",
    "    ax.set_title(f\"Model 0: SHAP values for predictor variables across all samples\")\n",
    "    shap.plots.beeswarm(explanation, max_display=40, plot_size=(12, 20))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "X_shap_fp = X_shap.astype(\"float64\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "shap.plots.scatter(explanation[:, \"year\"], color=explanation)",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Calibration"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Top-K precision (what fraction of the top K are truly positive?)\n",
    "order = np.argsort(-y_valid_predict)\n",
    "y_sorted = y_valid.to_numpy()[order]\n",
    "\n",
    "K = 100000\n",
    "precision_at_k = y_sorted[:K].mean()\n",
    "recall_at_k = y_sorted[:K].sum() / y_valid.sum()\n",
    "precision_at_k, recall_at_k\n",
    "\n",
    "print(f\"Precision at {K}: {precision_at_k}\")\n",
    "print(f\"Recall at {K}: {recall_at_k}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Precision/recall at a chosen threshold\n",
    "thr = 0.01\n",
    "y_hat = (y_valid_predict >= thr).astype(int)\n",
    "prec, rec, f1, _ = precision_recall_fscore_support(y_valid, y_hat, average=\"binary\")\n",
    "prec, rec, f1\n",
    "\n",
    "print(f\"Precision (threshold={thr}): {prec}\")\n",
    "print(f\"Recall (threshold={thr}): {rec}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Top-K precision (what fraction of the top K are truly positive?)\n",
    "order = np.argsort(-y_valid_predict)\n",
    "y_sorted = y_valid.to_numpy()[order]\n",
    "\n",
    "K = 100000\n",
    "precision_at_k = y_sorted[:K].mean()\n",
    "recall_at_k = y_sorted[:K].sum() / y_valid.sum()\n",
    "precision_at_k, recall_at_k\n",
    "\n",
    "print(f\"Precision at {K}: {precision_at_k}\")\n",
    "print(f\"Recall at {K}: {recall_at_k}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Precision/recall at a chosen threshold\n",
    "thr = 0.01\n",
    "y_hat = (y_valid_predict >= thr).astype(int)\n",
    "prec, rec, f1, _ = precision_recall_fscore_support(y_valid, y_hat, average=\"binary\")\n",
    "prec, rec, f1\n",
    "\n",
    "print(f\"Precision (threshold={thr}): {prec}\")\n",
    "print(f\"Recall (threshold={thr}): {rec}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Prediction"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def predict_proba_calibrated(gbm, calibrator, X_new, num_iteration=None):\n",
    "    p_raw = gbm.predict(X_new, num_iteration=num_iteration)\n",
    "    return calibrator.predict_proba(p_raw.reshape(-1, 1))[:, 1]\n",
    "\n",
    "# p_new = predict_proba_calibrated(gbm, calibrator, X_new, num_iteration=best_iter)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-stats-models-ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
