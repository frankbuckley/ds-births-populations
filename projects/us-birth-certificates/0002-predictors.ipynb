{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes 2 - Predictors of recorded DS live births\n",
    "\n",
    "Next:\n",
    "\n",
    "- Review data to see if we can go back further - check race\n",
    "- Hyperparameter tuning\n",
    "- Consider bagging vs GOSS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-20T09:01:52.782581900Z",
     "start_time": "2025-12-20T09:01:52.713802100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Environment Information --------------------\n",
      "date: 2025-12-21T13:33:23.340290\n",
      "platform: Windows-11-10.0.26220-SP0\n",
      "platform_version: 10.0.26220\n",
      "cpu: Intel64 Family 6 Model 183 Stepping 1, GenuineIntel\n",
      "cores: 32\n",
      "physical_cores: 24\n",
      "ram: 127 GB\n",
      "ram_available: 83 GB\n",
      "cuda: True\n",
      "cuda_device_count: 1\n",
      "cuda_device_0: NVIDIA GeForce RTX 4070 Ti SUPER\n",
      "python: 3.13.11 | packaged by conda-forge | (main, Dec  6 2025, 11:10:00) [MSC v.1944 64 bit (AMD64)]\n",
      "numpy: 2.3.5\n",
      "pandas: 2.3.3\n",
      "scipy: 1.16.3\n",
      "sklearn: 1.8.0\n",
      "pytorch: 2.9.1\n",
      "pymc: 5.26.1\n",
      "pytensor: 2.35.1\n",
      "arviz: 0.23.0\n",
      "\n",
      "--------------------\n",
      "Output directory: output/0002-predictors/20251221-133323\n",
      "--------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import duckdb, joblib, optuna, os, shap\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from lightgbm import early_stopping, log_evaluation\n",
    "from scipy.spatial.distance import squareform\n",
    "from scipy.cluster import hierarchy\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    average_precision_score,\n",
    "    roc_auc_score,\n",
    "    brier_score_loss,\n",
    "    log_loss,\n",
    "    precision_recall_fscore_support,\n",
    "    roc_curve,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from variables import Variables as vars\n",
    "import repl_utils, stats_utils\n",
    "\n",
    "pd.options.mode.copy_on_write = True\n",
    "\n",
    "plt.style.use(\"../../notebook.mplstyle\")\n",
    "\n",
    "os.makedirs(\"./output\", exist_ok=True)\n",
    "\n",
    "RANDOM_SEED = repl_utils.RANDOM_SEED\n",
    "np.random.seed(RANDOM_SEED)\n",
    "rng = np.random.default_rng(RANDOM_SEED)\n",
    "\n",
    "N_CORES = joblib.cpu_count(only_physical_cores=True)\n",
    "START_TIME = datetime.now()\n",
    "OUTPUT_DIR = f\"output/0002-predictors/{START_TIME:%Y%m%d-%H%M%S}\"\n",
    "\n",
    "SAVE_PLOTS = True\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "repl_utils.print_environment_info()\n",
    "\n",
    "print(f\"\\n--------------------\\nOutput directory: {OUTPUT_DIR}\\n--------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Options\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-20T09:01:52.803505800Z",
     "start_time": "2025-12-20T09:01:52.784585Z"
    }
   },
   "outputs": [],
   "source": [
    "START_YEAR = 2005\n",
    "# LightGBM threads\n",
    "NUM_THREADS = N_CORES\n",
    "# Splitting data for training, validation and calibration\n",
    "TRAINING_SPLIT = 0.5\n",
    "VALIDATION_SPLIT = 0.25\n",
    "CALIBRATION_SPLIT = 1 - TRAINING_SPLIT - VALIDATION_SPLIT\n",
    "#\n",
    "NUM_BOOST_ROUND = 5000  # 10000\n",
    "EARLY_STOPPING_ROUNDS = 10  # 50\n",
    "# True to search for hyperparameters\n",
    "SELECT_HYPERPARAMETERS = False  # True\n",
    "#\n",
    "OPTIMIZE_TRIALS = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-20T09:03:28.429045600Z",
     "start_time": "2025-12-20T09:01:52.812513400Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95bfc22babcd4e13ab6ebe5f86378b29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "count",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "mean",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "std",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "min",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "25%",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "50%",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "75%",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "max",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "ref": "f670659b-fd08-43df-8b27-555c7cc0e086",
       "rows": [
        [
         "ca_down_c_p_n",
         "78161818.0",
         "0.0005083940089520435",
         "0.02254186218981867",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0"
        ],
        [
         "year",
         "78161818.0",
         "2014.217172750511",
         "5.753869488460208",
         "2005.0",
         "2009.0",
         "2014.0",
         "2019.0",
         "2024.0"
        ],
        [
         "bfacil3",
         "78161818.0",
         "1.015354210415116",
         "0.12332742701659292",
         "1.0",
         "1.0",
         "1.0",
         "1.0",
         "3.0"
        ],
        [
         "sex",
         "78161818.0",
         "0.5115849019786106",
         "0.4998657752266318",
         "0.0",
         "0.0",
         "1.0",
         "1.0",
         "1.0"
        ],
        [
         "dbwt",
         "78100022.0",
         "3261.8274459128834",
         "589.7399792448997",
         "227.0",
         "2963.0",
         "3300.0",
         "3629.0",
         "8165.0"
        ],
        [
         "dplural",
         "78161098.0",
         "1.0347015851798806",
         "0.18974228705220308",
         "1.0",
         "1.0",
         "1.0",
         "1.0",
         "4.0"
        ],
        [
         "precare",
         "63370803.0",
         "2.968377692799632",
         "1.5462395837710463",
         "0.0",
         "2.0",
         "3.0",
         "3.0",
         "10.0"
        ],
        [
         "gestrec10",
         "78161818.0",
         "6.867911810853734",
         "2.5615936807381634",
         "1.0",
         "6.0",
         "7.0",
         "8.0",
         "99.0"
        ],
        [
         "pwgt_r",
         "56063606.0",
         "158.14219781010874",
         "41.523377863933554",
         "75.0",
         "130.0",
         "150.0",
         "180.0",
         "375.0"
        ],
        [
         "wtgain",
         "73879773.0",
         "30.046514625863836",
         "14.979685368609205",
         "0.0",
         "20.0",
         "30.0",
         "39.0",
         "98.0"
        ],
        [
         "bmi",
         "55795481.0",
         "27.006921768188477",
         "6.696934223175049",
         "13.0",
         "22.09375",
         "25.5",
         "30.40625",
         "69.875"
        ],
        [
         "rf_pdiab",
         "41249664.0",
         "0.01007615480213366",
         "0.09987305016042992",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0"
        ],
        [
         "rf_gdiab",
         "41249664.0",
         "0.07052023502542953",
         "0.25602174334697336",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0"
        ],
        [
         "rf_phype",
         "41249664.0",
         "0.023257571261671366",
         "0.15072046042720982",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0"
        ],
        [
         "rf_ghype",
         "41249664.0",
         "0.07734433909570754",
         "0.26713703231780284",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0"
        ],
        [
         "rf_ehype",
         "41249664.0",
         "0.002588239264203461",
         "0.05080886088369",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0"
        ],
        [
         "rf_ppterm",
         "64635865.0",
         "0.03004407846943798",
         "0.1707086180285611",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0"
        ],
        [
         "rf_inftr",
         "57487367.0",
         "0.0184734326065064",
         "0.13465572846949955",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0"
        ],
        [
         "rf_fedrg",
         "974676.0",
         "0.43010805642080036",
         "0.495091272096104",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "1.0"
        ],
        [
         "rf_artec",
         "974674.0",
         "0.6582570172180647",
         "0.47429415693643856",
         "0.0",
         "0.0",
         "1.0",
         "1.0",
         "1.0"
        ],
        [
         "no_risks",
         "28050943.0",
         "1.0",
         "0.0",
         "1.0",
         "1.0",
         "1.0",
         "1.0",
         "1.0"
        ],
        [
         "ld_indl",
         "64671204.0",
         "0.26699215310727786",
         "0.4423882303051869",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "1.0"
        ],
        [
         "ld_augm",
         "64673987.0",
         "0.20828466938337975",
         "0.40608148004198896",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0"
        ],
        [
         "me_pres",
         "64711416.0",
         "1.1895196050106522",
         "1.0095028620429753",
         "1.0",
         "1.0",
         "1.0",
         "1.0",
         "9.0"
        ],
        [
         "dmeth_rec",
         "74065870.0",
         "1.3311206767705557",
         "0.5375839877701425",
         "1.0",
         "1.0",
         "1.0",
         "2.0",
         "9.0"
        ],
        [
         "apgar5",
         "3711456.0",
         "44.951096820223654",
         "43.46342090929038",
         "10.0",
         "10.0",
         "10.0",
         "99.0",
         "99.0"
        ],
        [
         "apgar10",
         "290534.0",
         "97.22480329324623",
         "12.4435411563352",
         "10.0",
         "99.0",
         "99.0",
         "99.0",
         "99.0"
        ],
        [
         "ab_aven1",
         "65935786.0",
         "0.045301636352678046",
         "0.20796489788511444",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0"
        ],
        [
         "ab_aven6",
         "65935787.0",
         "0.013907106318454954",
         "0.1171055033731273",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0"
        ],
        [
         "ab_nicu",
         "65935783.0",
         "0.08385217780761017",
         "0.27716599944732184",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0"
        ],
        [
         "ab_surf",
         "65935788.0",
         "0.004386115776761476",
         "0.06608235643027763",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0"
        ],
        [
         "ab_anti",
         "65935790.0",
         "0.020239736264629573",
         "0.1408193510897199",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0"
        ],
        [
         "ab_seiz",
         "65935789.0",
         "0.000328031260837722",
         "0.018108662603925945",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0"
        ],
        [
         "no_abnorm",
         "41351164.0",
         "0.8898029085710865",
         "0.36431088023730873",
         "0.0",
         "1.0",
         "1.0",
         "1.0",
         "9.0"
        ],
        [
         "ca_disor",
         "65977842.0",
         "0.0007144519822276091",
         "0.0359846380781332",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "2.0"
        ],
        [
         "ca_anen",
         "65977842.0",
         "0.0001034589764242365",
         "0.010170952474204069",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0"
        ],
        [
         "ca_mnsb",
         "65977842.0",
         "0.00014512447982157405",
         "0.01204588813274183",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0"
        ],
        [
         "ca_cchd",
         "65977842.0",
         "0.0006393358546040351",
         "0.02527700761468133",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0"
        ],
        [
         "ca_cdh",
         "65977842.0",
         "0.0001302710082575905",
         "0.011412889191444548",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0"
        ],
        [
         "ca_omph",
         "65977842.0",
         "9.613833686770174e-05",
         "0.009804544647504687",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0"
        ],
        [
         "ca_gast",
         "65977842.0",
         "0.00024343021100932643",
         "0.015600351163678167",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0"
        ],
        [
         "ca_limb",
         "65977842.0",
         "0.00013396921954494966",
         "0.011573732061166958",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0"
        ],
        [
         "ca_cleft",
         "65977842.0",
         "0.0005238425348922446",
         "0.022881611215682975",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0"
        ],
        [
         "ca_clpal",
         "65977842.0",
         "0.00022924363000535847",
         "0.015139058122508977",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0"
        ],
        [
         "ca_hypo",
         "65977842.0",
         "0.0005588391326894263",
         "0.023633172448459912",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0"
        ],
        [
         "ca_disor_1",
         "65977842.0",
         "0.0007144519822276091",
         "0.0359846380781332",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "2.0"
        ],
        [
         "no_congen",
         "41285308.0",
         "0.996552332854099",
         "0.05861553395109808",
         "0.0",
         "1.0",
         "1.0",
         "1.0",
         "1.0"
        ],
        [
         "mage_c",
         "78161818.0",
         "28.39852091209035",
         "6.006724022502179",
         "12.0",
         "24.0",
         "28.0",
         "33.0",
         "50.0"
        ],
        [
         "meduc",
         "65977842.0",
         "4.2957722685140265",
         "1.8293552055846038",
         "1.0",
         "3.0",
         "4.0",
         "6.0",
         "9.0"
        ],
        [
         "mracehisp",
         "77703448.0",
         "4.0785129638005255",
         "2.626414672232445",
         "1.0",
         "1.0",
         "6.0",
         "6.0",
         "8.0"
        ]
       ],
       "shape": {
        "columns": 8,
        "rows": 55
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ca_down_c_p_n</th>\n",
       "      <td>78161818.0</td>\n",
       "      <td>0.000508</td>\n",
       "      <td>0.022542</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <td>78161818.0</td>\n",
       "      <td>2014.217173</td>\n",
       "      <td>5.753869</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>2024.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bfacil3</th>\n",
       "      <td>78161818.0</td>\n",
       "      <td>1.015354</td>\n",
       "      <td>0.123327</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex</th>\n",
       "      <td>78161818.0</td>\n",
       "      <td>0.511585</td>\n",
       "      <td>0.499866</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dbwt</th>\n",
       "      <td>78100022.0</td>\n",
       "      <td>3261.827446</td>\n",
       "      <td>589.739979</td>\n",
       "      <td>227.0</td>\n",
       "      <td>2963.0</td>\n",
       "      <td>3300.0</td>\n",
       "      <td>3629.0</td>\n",
       "      <td>8165.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dplural</th>\n",
       "      <td>78161098.0</td>\n",
       "      <td>1.034702</td>\n",
       "      <td>0.189742</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precare</th>\n",
       "      <td>63370803.0</td>\n",
       "      <td>2.968378</td>\n",
       "      <td>1.54624</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gestrec10</th>\n",
       "      <td>78161818.0</td>\n",
       "      <td>6.867912</td>\n",
       "      <td>2.561594</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pwgt_r</th>\n",
       "      <td>56063606.0</td>\n",
       "      <td>158.142198</td>\n",
       "      <td>41.523378</td>\n",
       "      <td>75.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>375.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wtgain</th>\n",
       "      <td>73879773.0</td>\n",
       "      <td>30.046515</td>\n",
       "      <td>14.979685</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>98.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bmi</th>\n",
       "      <td>55795481.0</td>\n",
       "      <td>27.006922</td>\n",
       "      <td>6.696934</td>\n",
       "      <td>13.0</td>\n",
       "      <td>22.09375</td>\n",
       "      <td>25.5</td>\n",
       "      <td>30.40625</td>\n",
       "      <td>69.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_pdiab</th>\n",
       "      <td>41249664.0</td>\n",
       "      <td>0.010076</td>\n",
       "      <td>0.099873</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_gdiab</th>\n",
       "      <td>41249664.0</td>\n",
       "      <td>0.07052</td>\n",
       "      <td>0.256022</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_phype</th>\n",
       "      <td>41249664.0</td>\n",
       "      <td>0.023258</td>\n",
       "      <td>0.15072</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_ghype</th>\n",
       "      <td>41249664.0</td>\n",
       "      <td>0.077344</td>\n",
       "      <td>0.267137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_ehype</th>\n",
       "      <td>41249664.0</td>\n",
       "      <td>0.002588</td>\n",
       "      <td>0.050809</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_ppterm</th>\n",
       "      <td>64635865.0</td>\n",
       "      <td>0.030044</td>\n",
       "      <td>0.170709</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_inftr</th>\n",
       "      <td>57487367.0</td>\n",
       "      <td>0.018473</td>\n",
       "      <td>0.134656</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_fedrg</th>\n",
       "      <td>974676.0</td>\n",
       "      <td>0.430108</td>\n",
       "      <td>0.495091</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_artec</th>\n",
       "      <td>974674.0</td>\n",
       "      <td>0.658257</td>\n",
       "      <td>0.474294</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no_risks</th>\n",
       "      <td>28050943.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ld_indl</th>\n",
       "      <td>64671204.0</td>\n",
       "      <td>0.266992</td>\n",
       "      <td>0.442388</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ld_augm</th>\n",
       "      <td>64673987.0</td>\n",
       "      <td>0.208285</td>\n",
       "      <td>0.406081</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>me_pres</th>\n",
       "      <td>64711416.0</td>\n",
       "      <td>1.18952</td>\n",
       "      <td>1.009503</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dmeth_rec</th>\n",
       "      <td>74065870.0</td>\n",
       "      <td>1.331121</td>\n",
       "      <td>0.537584</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>apgar5</th>\n",
       "      <td>3711456.0</td>\n",
       "      <td>44.951097</td>\n",
       "      <td>43.463421</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>apgar10</th>\n",
       "      <td>290534.0</td>\n",
       "      <td>97.224803</td>\n",
       "      <td>12.443541</td>\n",
       "      <td>10.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ab_aven1</th>\n",
       "      <td>65935786.0</td>\n",
       "      <td>0.045302</td>\n",
       "      <td>0.207965</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ab_aven6</th>\n",
       "      <td>65935787.0</td>\n",
       "      <td>0.013907</td>\n",
       "      <td>0.117106</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ab_nicu</th>\n",
       "      <td>65935783.0</td>\n",
       "      <td>0.083852</td>\n",
       "      <td>0.277166</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ab_surf</th>\n",
       "      <td>65935788.0</td>\n",
       "      <td>0.004386</td>\n",
       "      <td>0.066082</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ab_anti</th>\n",
       "      <td>65935790.0</td>\n",
       "      <td>0.02024</td>\n",
       "      <td>0.140819</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ab_seiz</th>\n",
       "      <td>65935789.0</td>\n",
       "      <td>0.000328</td>\n",
       "      <td>0.018109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no_abnorm</th>\n",
       "      <td>41351164.0</td>\n",
       "      <td>0.889803</td>\n",
       "      <td>0.364311</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca_disor</th>\n",
       "      <td>65977842.0</td>\n",
       "      <td>0.000714</td>\n",
       "      <td>0.035985</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca_anen</th>\n",
       "      <td>65977842.0</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>0.010171</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca_mnsb</th>\n",
       "      <td>65977842.0</td>\n",
       "      <td>0.000145</td>\n",
       "      <td>0.012046</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca_cchd</th>\n",
       "      <td>65977842.0</td>\n",
       "      <td>0.000639</td>\n",
       "      <td>0.025277</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca_cdh</th>\n",
       "      <td>65977842.0</td>\n",
       "      <td>0.00013</td>\n",
       "      <td>0.011413</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca_omph</th>\n",
       "      <td>65977842.0</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>0.009805</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca_gast</th>\n",
       "      <td>65977842.0</td>\n",
       "      <td>0.000243</td>\n",
       "      <td>0.0156</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca_limb</th>\n",
       "      <td>65977842.0</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>0.011574</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca_cleft</th>\n",
       "      <td>65977842.0</td>\n",
       "      <td>0.000524</td>\n",
       "      <td>0.022882</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca_clpal</th>\n",
       "      <td>65977842.0</td>\n",
       "      <td>0.000229</td>\n",
       "      <td>0.015139</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca_hypo</th>\n",
       "      <td>65977842.0</td>\n",
       "      <td>0.000559</td>\n",
       "      <td>0.023633</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca_disor_1</th>\n",
       "      <td>65977842.0</td>\n",
       "      <td>0.000714</td>\n",
       "      <td>0.035985</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no_congen</th>\n",
       "      <td>41285308.0</td>\n",
       "      <td>0.996552</td>\n",
       "      <td>0.058616</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mage_c</th>\n",
       "      <td>78161818.0</td>\n",
       "      <td>28.398521</td>\n",
       "      <td>6.006724</td>\n",
       "      <td>12.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meduc</th>\n",
       "      <td>65977842.0</td>\n",
       "      <td>4.295772</td>\n",
       "      <td>1.829355</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mracehisp</th>\n",
       "      <td>77703448.0</td>\n",
       "      <td>4.078513</td>\n",
       "      <td>2.626415</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fagecomb</th>\n",
       "      <td>58004842.0</td>\n",
       "      <td>31.381893</td>\n",
       "      <td>6.887872</td>\n",
       "      <td>9.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>98.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feduc</th>\n",
       "      <td>49359732.0</td>\n",
       "      <td>4.20256</td>\n",
       "      <td>1.762683</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fracehisp</th>\n",
       "      <td>77961451.0</td>\n",
       "      <td>4.650512</td>\n",
       "      <td>2.899696</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pay_rec</th>\n",
       "      <td>57000133.0</td>\n",
       "      <td>1.699595</td>\n",
       "      <td>0.735702</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wic</th>\n",
       "      <td>56646492.0</td>\n",
       "      <td>0.386296</td>\n",
       "      <td>0.4869</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    count         mean         std     min       25%     50%  \\\n",
       "ca_down_c_p_n  78161818.0     0.000508    0.022542     0.0       0.0     0.0   \n",
       "year           78161818.0  2014.217173    5.753869  2005.0    2009.0  2014.0   \n",
       "bfacil3        78161818.0     1.015354    0.123327     1.0       1.0     1.0   \n",
       "sex            78161818.0     0.511585    0.499866     0.0       0.0     1.0   \n",
       "dbwt           78100022.0  3261.827446  589.739979   227.0    2963.0  3300.0   \n",
       "dplural        78161098.0     1.034702    0.189742     1.0       1.0     1.0   \n",
       "precare        63370803.0     2.968378     1.54624     0.0       2.0     3.0   \n",
       "gestrec10      78161818.0     6.867912    2.561594     1.0       6.0     7.0   \n",
       "pwgt_r         56063606.0   158.142198   41.523378    75.0     130.0   150.0   \n",
       "wtgain         73879773.0    30.046515   14.979685     0.0      20.0    30.0   \n",
       "bmi            55795481.0    27.006922    6.696934    13.0  22.09375    25.5   \n",
       "rf_pdiab       41249664.0     0.010076    0.099873     0.0       0.0     0.0   \n",
       "rf_gdiab       41249664.0      0.07052    0.256022     0.0       0.0     0.0   \n",
       "rf_phype       41249664.0     0.023258     0.15072     0.0       0.0     0.0   \n",
       "rf_ghype       41249664.0     0.077344    0.267137     0.0       0.0     0.0   \n",
       "rf_ehype       41249664.0     0.002588    0.050809     0.0       0.0     0.0   \n",
       "rf_ppterm      64635865.0     0.030044    0.170709     0.0       0.0     0.0   \n",
       "rf_inftr       57487367.0     0.018473    0.134656     0.0       0.0     0.0   \n",
       "rf_fedrg         974676.0     0.430108    0.495091     0.0       0.0     0.0   \n",
       "rf_artec         974674.0     0.658257    0.474294     0.0       0.0     1.0   \n",
       "no_risks       28050943.0          1.0         0.0     1.0       1.0     1.0   \n",
       "ld_indl        64671204.0     0.266992    0.442388     0.0       0.0     0.0   \n",
       "ld_augm        64673987.0     0.208285    0.406081     0.0       0.0     0.0   \n",
       "me_pres        64711416.0      1.18952    1.009503     1.0       1.0     1.0   \n",
       "dmeth_rec      74065870.0     1.331121    0.537584     1.0       1.0     1.0   \n",
       "apgar5          3711456.0    44.951097   43.463421    10.0      10.0    10.0   \n",
       "apgar10          290534.0    97.224803   12.443541    10.0      99.0    99.0   \n",
       "ab_aven1       65935786.0     0.045302    0.207965     0.0       0.0     0.0   \n",
       "ab_aven6       65935787.0     0.013907    0.117106     0.0       0.0     0.0   \n",
       "ab_nicu        65935783.0     0.083852    0.277166     0.0       0.0     0.0   \n",
       "ab_surf        65935788.0     0.004386    0.066082     0.0       0.0     0.0   \n",
       "ab_anti        65935790.0      0.02024    0.140819     0.0       0.0     0.0   \n",
       "ab_seiz        65935789.0     0.000328    0.018109     0.0       0.0     0.0   \n",
       "no_abnorm      41351164.0     0.889803    0.364311     0.0       1.0     1.0   \n",
       "ca_disor       65977842.0     0.000714    0.035985     0.0       0.0     0.0   \n",
       "ca_anen        65977842.0     0.000103    0.010171     0.0       0.0     0.0   \n",
       "ca_mnsb        65977842.0     0.000145    0.012046     0.0       0.0     0.0   \n",
       "ca_cchd        65977842.0     0.000639    0.025277     0.0       0.0     0.0   \n",
       "ca_cdh         65977842.0      0.00013    0.011413     0.0       0.0     0.0   \n",
       "ca_omph        65977842.0     0.000096    0.009805     0.0       0.0     0.0   \n",
       "ca_gast        65977842.0     0.000243      0.0156     0.0       0.0     0.0   \n",
       "ca_limb        65977842.0     0.000134    0.011574     0.0       0.0     0.0   \n",
       "ca_cleft       65977842.0     0.000524    0.022882     0.0       0.0     0.0   \n",
       "ca_clpal       65977842.0     0.000229    0.015139     0.0       0.0     0.0   \n",
       "ca_hypo        65977842.0     0.000559    0.023633     0.0       0.0     0.0   \n",
       "ca_disor_1     65977842.0     0.000714    0.035985     0.0       0.0     0.0   \n",
       "no_congen      41285308.0     0.996552    0.058616     0.0       1.0     1.0   \n",
       "mage_c         78161818.0    28.398521    6.006724    12.0      24.0    28.0   \n",
       "meduc          65977842.0     4.295772    1.829355     1.0       3.0     4.0   \n",
       "mracehisp      77703448.0     4.078513    2.626415     1.0       1.0     6.0   \n",
       "fagecomb       58004842.0    31.381893    6.887872     9.0      27.0    31.0   \n",
       "feduc          49359732.0      4.20256    1.762683     1.0       3.0     4.0   \n",
       "fracehisp      77961451.0     4.650512    2.899696     1.0       1.0     6.0   \n",
       "pay_rec        57000133.0     1.699595    0.735702     1.0       1.0     2.0   \n",
       "wic            56646492.0     0.386296      0.4869     0.0       0.0     0.0   \n",
       "\n",
       "                    75%     max  \n",
       "ca_down_c_p_n       0.0     1.0  \n",
       "year             2019.0  2024.0  \n",
       "bfacil3             1.0     3.0  \n",
       "sex                 1.0     1.0  \n",
       "dbwt             3629.0  8165.0  \n",
       "dplural             1.0     4.0  \n",
       "precare             3.0    10.0  \n",
       "gestrec10           8.0    99.0  \n",
       "pwgt_r            180.0   375.0  \n",
       "wtgain             39.0    98.0  \n",
       "bmi            30.40625  69.875  \n",
       "rf_pdiab            0.0     1.0  \n",
       "rf_gdiab            0.0     1.0  \n",
       "rf_phype            0.0     1.0  \n",
       "rf_ghype            0.0     1.0  \n",
       "rf_ehype            0.0     1.0  \n",
       "rf_ppterm           0.0     1.0  \n",
       "rf_inftr            0.0     1.0  \n",
       "rf_fedrg            1.0     1.0  \n",
       "rf_artec            1.0     1.0  \n",
       "no_risks            1.0     1.0  \n",
       "ld_indl             1.0     1.0  \n",
       "ld_augm             0.0     1.0  \n",
       "me_pres             1.0     9.0  \n",
       "dmeth_rec           2.0     9.0  \n",
       "apgar5             99.0    99.0  \n",
       "apgar10            99.0    99.0  \n",
       "ab_aven1            0.0     1.0  \n",
       "ab_aven6            0.0     1.0  \n",
       "ab_nicu             0.0     1.0  \n",
       "ab_surf             0.0     1.0  \n",
       "ab_anti             0.0     1.0  \n",
       "ab_seiz             0.0     1.0  \n",
       "no_abnorm           1.0     9.0  \n",
       "ca_disor            0.0     2.0  \n",
       "ca_anen             0.0     1.0  \n",
       "ca_mnsb             0.0     1.0  \n",
       "ca_cchd             0.0     1.0  \n",
       "ca_cdh              0.0     1.0  \n",
       "ca_omph             0.0     1.0  \n",
       "ca_gast             0.0     1.0  \n",
       "ca_limb             0.0     1.0  \n",
       "ca_cleft            0.0     1.0  \n",
       "ca_clpal            0.0     1.0  \n",
       "ca_hypo             0.0     1.0  \n",
       "ca_disor_1          0.0     2.0  \n",
       "no_congen           1.0     1.0  \n",
       "mage_c             33.0    50.0  \n",
       "meduc               6.0     9.0  \n",
       "mracehisp           6.0     8.0  \n",
       "fagecomb           36.0    98.0  \n",
       "feduc               6.0     8.0  \n",
       "fracehisp           7.0     9.0  \n",
       "pay_rec             2.0     4.0  \n",
       "wic                 1.0     1.0  "
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con = duckdb.connect(\"./data/us_births.db\", read_only=True)\n",
    "\n",
    "df = con.execute(\n",
    "    f\"\"\"\n",
    "    SELECT\n",
    "        -- (training label) indicated if C or P, not indicated if N, U and missing excluded from training\n",
    "        CASE\n",
    "            WHEN COALESCE (ca_down, ca_downs) = 'C' THEN 1::UTINYINT\n",
    "            WHEN COALESCE (ca_down, ca_downs) = 'P' THEN 1::UTINYINT\n",
    "            WHEN COALESCE (ca_down, ca_downs) = 'N' THEN 0::UTINYINT\n",
    "            WHEN uca_downs = 1 THEN 1::UTINYINT\n",
    "            WHEN uca_downs = 2 THEN 0::UTINYINT\n",
    "            ELSE NULL\n",
    "        END AS ca_down_c_p_n,        \n",
    "        -- ==================== date of birth ====================\n",
    "        year,\n",
    "        -- ==================== birth location ====================\n",
    "        -- birth place (1: hospital, 2: not hospital, 3: unknown/not stated)\n",
    "        bfacil3,\n",
    "        -- ==================== characteristics of baby ====================\n",
    "        -- sex of baby\n",
    "        CASE\n",
    "            WHEN sex = 'M' THEN 1::UTINYINT\n",
    "            WHEN sex = 'F' THEN 0::UTINYINT\n",
    "            ELSE NULL\n",
    "        END AS sex,\n",
    "        -- birth weight (grams)\n",
    "        CASE\n",
    "            WHEN dbwt >= 227 AND dbwt <= 8165 THEN dbwt\n",
    "            -- we ignore \"Not stated\" as we treat this variable as numeric rather than categorical\n",
    "            ELSE NULL\n",
    "        END AS dbwt,\n",
    "        -- ==================== characteristics of pregnancy ====================\n",
    "        -- plurality (1: single... 4 quadpruplet or higher)\n",
    "        dplural,\n",
    "        -- month prenatal care began (1 to 10, 0: no prenatal care)\n",
    "        CASE\n",
    "            WHEN precare >= 0 AND precare <= 10 THEN precare\n",
    "            WHEN precare = 99 THEN precare\n",
    "            ELSE NULL\n",
    "        END AS precare,\n",
    "        -- combined gestation estimate\n",
    "        CASE\n",
    "            WHEN gestrec10 >= 1 AND gestrec10 <= 10 THEN gestrec10\n",
    "            WHEN gestrec10 = 99 THEN gestrec10\n",
    "            ELSE NULL\n",
    "        END AS gestrec10,\n",
    "        -- pre-pregnancy weight recode (in pounds)\n",
    "        CASE\n",
    "            WHEN pwgt_r >= 75 AND pwgt_r <= 375 THEN pwgt_r\n",
    "            -- we ignore \"Unknown or not stated\" as we treat this variable as numeric rather than categorical\n",
    "            ELSE NULL\n",
    "        END AS pwgt_r,\n",
    "        -- weight gain in pounds (98 = 98+)\n",
    "        CASE\n",
    "            WHEN wtgain >= 0 AND wtgain <= 98 THEN wtgain\n",
    "            -- we ignore \"Unknown or not stated\" as we treat this variable as numeric rather than categorical\n",
    "            ELSE NULL\n",
    "        END AS wtgain,\n",
    "        -- maternal body mass index\n",
    "        CASE\n",
    "            WHEN bmi >= 13.0 AND bmi < 69.9 THEN bmi\n",
    "            -- we ignore \"Unknown or not stated\" as we treat this variable as numeric rather than categorical\n",
    "            ELSE NULL\n",
    "        END\n",
    "        AS bmi,\n",
    "        -- ==================== pregnancy risk factors ====================\n",
    "        -- pre-pregnancy diabetes\n",
    "        CASE\n",
    "            WHEN rf_pdiab = 'Y' THEN 1::UTINYINT\n",
    "            WHEN rf_pdiab = 'N' THEN 0::UTINYINT\n",
    "            ELSE NULL\n",
    "        END AS rf_pdiab,\n",
    "        -- gestational diabetes\n",
    "        CASE\n",
    "            WHEN rf_gdiab = 'Y' THEN 1::UTINYINT\n",
    "            WHEN rf_gdiab = 'N' THEN 0::UTINYINT\n",
    "            ELSE NULL\n",
    "        END AS rf_gdiab,\n",
    "        -- pre-pregnancy hypertension\n",
    "        CASE\n",
    "            WHEN rf_phype = 'Y' THEN 1::UTINYINT\n",
    "            WHEN rf_phype = 'N' THEN 0::UTINYINT\n",
    "            ELSE NULL\n",
    "        END AS rf_phype,\n",
    "        -- gestational hypertension\n",
    "        CASE\n",
    "            WHEN rf_ghype = 'Y' THEN 1::UTINYINT\n",
    "            WHEN rf_ghype = 'N' THEN 0::UTINYINT\n",
    "            ELSE NULL\n",
    "        END AS rf_ghype,\n",
    "        -- hypertension eclampsia\n",
    "        CASE\n",
    "            WHEN rf_ehype = 'Y' THEN 1::UTINYINT\n",
    "            WHEN rf_ehype = 'N' THEN 0::UTINYINT\n",
    "            ELSE NULL\n",
    "        END AS rf_ehype,\n",
    "        -- previous preterm birth\n",
    "        CASE\n",
    "            WHEN rf_ppterm = 'Y' THEN 1::UTINYINT\n",
    "            WHEN rf_ppterm = 'N' THEN 0::UTINYINT\n",
    "            ELSE NULL\n",
    "        END AS rf_ppterm,\n",
    "        -- infertility treatment used\n",
    "        CASE\n",
    "            WHEN rf_inftr = 'Y' THEN 1::UTINYINT\n",
    "            WHEN rf_inftr = 'N' THEN 0::UTINYINT\n",
    "            ELSE NULL\n",
    "        END AS rf_inftr,\n",
    "        -- fertility enhancing drugs\n",
    "        CASE\n",
    "            WHEN rf_fedrg = 'Y' THEN 1::UTINYINT\n",
    "            WHEN rf_fedrg = 'N' THEN 0::UTINYINT\n",
    "            ELSE NULL\n",
    "        END AS rf_fedrg,\n",
    "        -- asst. reproductive technology\n",
    "        CASE\n",
    "            WHEN rf_artec = 'Y' THEN 1::UTINYINT\n",
    "            WHEN rf_artec = 'N' THEN 0::UTINYINT\n",
    "            ELSE NULL\n",
    "        END AS rf_artec,\n",
    "        -- no risk factors reported\n",
    "        CASE\n",
    "            WHEN no_risks <= 1 THEN no_risks\n",
    "            ELSE NULL\n",
    "        END AS no_risks,\n",
    "        -- ==================== labor and delivery ====================\n",
    "        -- induction of labor\n",
    "        CASE\n",
    "            WHEN ld_indl = 'Y' THEN 1::UTINYINT\n",
    "            WHEN ld_indl = 'N' THEN 0::UTINYINT\n",
    "            ELSE NULL\n",
    "        END AS ld_indl,\n",
    "        -- augmentation of labor\n",
    "        CASE\n",
    "            WHEN ld_augm = 'Y' THEN 1::UTINYINT\n",
    "            WHEN ld_augm = 'N' THEN 0::UTINYINT\n",
    "            ELSE NULL\n",
    "        END AS ld_augm,\n",
    "        -- fetal presentation at delivery\n",
    "        CASE\n",
    "            WHEN me_pres >= 1 AND me_pres <= 3 THEN me_pres\n",
    "            WHEN me_pres = 9 THEN me_pres\n",
    "            ELSE NULL\n",
    "        END AS me_pres,\n",
    "        -- delivery method recode\n",
    "        CASE\n",
    "            WHEN dmeth_rec >= 1 AND dmeth_rec <= 2 THEN dmeth_rec\n",
    "            WHEN dmeth_rec = 9 THEN dmeth_rec\n",
    "            ELSE NULL\n",
    "        END AS dmeth_rec,\n",
    "        -- ==================== newborn health ====================\n",
    "        -- five minute apgar score\n",
    "        CASE\n",
    "            WHEN apgar5 >= 10 AND apgar5 <= 10 THEN apgar5\n",
    "            WHEN apgar5 = 99 THEN apgar5\n",
    "            ELSE NULL\n",
    "        END AS apgar5,\n",
    "        -- ten minute apgar score\n",
    "        CASE\n",
    "            WHEN apgar10 >= 10 AND apgar10 <= 10 THEN apgar10\n",
    "            WHEN apgar10 = 99 THEN apgar10\n",
    "            ELSE NULL\n",
    "        END AS apgar10,\n",
    "        -- assisted ventilation (immediately)\n",
    "        CASE\n",
    "            WHEN ab_aven1 = 'Y' THEN 1::UTINYINT\n",
    "            WHEN ab_aven1 = 'N' THEN 0::UTINYINT\n",
    "            ELSE NULL\n",
    "        END AS ab_aven1,\n",
    "        -- assisted ventilation > 6 hrs\n",
    "        CASE\n",
    "            WHEN ab_aven6 = 'Y' THEN 1::UTINYINT\n",
    "            WHEN ab_aven6 = 'N' THEN 0::UTINYINT\n",
    "            ELSE NULL\n",
    "        END AS ab_aven6,\n",
    "        -- admitted to nicu\n",
    "        CASE\n",
    "            WHEN ab_nicu = 'Y' THEN 1::UTINYINT\n",
    "            WHEN ab_nicu = 'N' THEN 0::UTINYINT\n",
    "            ELSE NULL\n",
    "        END AS ab_nicu,\n",
    "        -- surfactant\n",
    "        CASE\n",
    "            WHEN ab_surf = 'Y' THEN 1::UTINYINT\n",
    "            WHEN ab_surf = 'N' THEN 0::UTINYINT\n",
    "            ELSE NULL\n",
    "        END AS ab_surf,\n",
    "        -- antibiotics for newborn\n",
    "        CASE\n",
    "            WHEN ab_anti = 'Y' THEN 1::UTINYINT\n",
    "            WHEN ab_anti = 'N' THEN 0::UTINYINT\n",
    "            ELSE NULL\n",
    "        END AS ab_anti,\n",
    "        -- seizures\n",
    "        CASE\n",
    "            WHEN ab_seiz = 'Y' THEN 1::UTINYINT\n",
    "            WHEN ab_seiz = 'N' THEN 0::UTINYINT\n",
    "            ELSE NULL\n",
    "        END AS ab_seiz,\n",
    "        -- no_abnorm\n",
    "        CASE\n",
    "            WHEN no_abnorm >= 0 AND no_abnorm <= 1 THEN no_abnorm\n",
    "            WHEN no_abnorm = 9 THEN no_abnorm\n",
    "            ELSE NULL\n",
    "        END AS no_abnorm,\n",
    "        -- ==================== identified disorders ====================\n",
    "        -- congenital disorder\n",
    "        CASE\n",
    "            WHEN ca_disor = 'C' THEN 1::UTINYINT\n",
    "            WHEN ca_disor = 'P' THEN 2::UTINYINT\n",
    "            WHEN ca_disor = 'N' THEN 0::UTINYINT\n",
    "            ELSE NULL\n",
    "        END\n",
    "        AS ca_disor,\n",
    "        -- anencephaly\n",
    "        CASE\n",
    "            WHEN ca_anen = 'Y' THEN 1::UTINYINT\n",
    "            WHEN ca_anen = 'N' THEN 0::UTINYINT\n",
    "            ELSE NULL\n",
    "        END AS ca_anen,\n",
    "        -- meningomyelocele / spina bifida\n",
    "        CASE\n",
    "            WHEN ca_mnsb = 'Y' THEN 1::UTINYINT\n",
    "            WHEN ca_mnsb = 'N' THEN 0::UTINYINT\n",
    "            ELSE NULL\n",
    "        END AS ca_mnsb,\n",
    "        -- congenital heart defect\n",
    "        CASE\n",
    "            WHEN ca_cchd = 'Y' THEN 1::UTINYINT\n",
    "            WHEN ca_cchd = 'N' THEN 0::UTINYINT\n",
    "            ELSE NULL\n",
    "        END AS ca_cchd,\n",
    "        -- ca_cdh\n",
    "        CASE\n",
    "            WHEN ca_cdh = 'Y' THEN 1::UTINYINT\n",
    "            WHEN ca_cdh = 'N' THEN 0::UTINYINT\n",
    "            ELSE NULL\n",
    "        END AS ca_cdh,\n",
    "        -- omphalocele\n",
    "        CASE\n",
    "            WHEN ca_omph = 'Y' THEN 1::UTINYINT\n",
    "            WHEN ca_omph = 'N' THEN 0::UTINYINT\n",
    "            ELSE NULL\n",
    "        END AS ca_omph,\n",
    "        -- gastroschisis\n",
    "        CASE\n",
    "            WHEN ca_gast = 'Y' THEN 1::UTINYINT\n",
    "            WHEN ca_gast = 'N' THEN 0::UTINYINT\n",
    "            ELSE NULL\n",
    "        END AS ca_gast,\n",
    "        -- limb reduction defect\n",
    "        CASE\n",
    "            WHEN ca_limb = 'Y' THEN 1::UTINYINT\n",
    "            WHEN ca_limb = 'N' THEN 0::UTINYINT\n",
    "            ELSE NULL\n",
    "        END AS ca_limb,\n",
    "        -- cleft lip w/ or w/o cleft palate\n",
    "        CASE\n",
    "            WHEN ca_cleft = 'Y' THEN 1::UTINYINT\n",
    "            WHEN ca_cleft = 'N' THEN 0::UTINYINT\n",
    "            ELSE NULL\n",
    "        END AS ca_cleft,\n",
    "        -- cleft palate alone\n",
    "        CASE\n",
    "            WHEN ca_clpal = 'Y' THEN 1::UTINYINT\n",
    "            WHEN ca_clpal = 'N' THEN 0::UTINYINT\n",
    "            ELSE NULL\n",
    "        END AS ca_clpal,\n",
    "        -- Hypospadias\n",
    "        CASE\n",
    "            WHEN ca_hypo = 'Y' THEN 1::UTINYINT\n",
    "            WHEN ca_hypo = 'N' THEN 0::UTINYINT\n",
    "            ELSE NULL\n",
    "        END AS ca_hypo,\n",
    "        -- suspected chromosomal disorder\n",
    "        CASE\n",
    "            WHEN ca_disor = 'C' THEN 1::UTINYINT\n",
    "            WHEN ca_disor = 'P' THEN 2::UTINYINT\n",
    "            WHEN ca_disor = 'N' THEN 0::UTINYINT\n",
    "            WHEN ca_disor = 'U' THEN 9::UTINYINT\n",
    "            ELSE NULL\n",
    "        END AS ca_disor,\n",
    "        -- no_congen\n",
    "        CASE\n",
    "            WHEN no_congen >= 0 AND no_congen <= 1 THEN no_congen\n",
    "            WHEN no_congen = 9 THEN no_congen\n",
    "            ELSE NULL\n",
    "        END AS no_congen,\n",
    "        -- ==================== maternal characteristics ====================\n",
    "        -- maternal age in years\n",
    "        mage_c,\n",
    "        -- maternal education\n",
    "        CASE\n",
    "            WHEN meduc >= 0 AND meduc < 10 THEN meduc\n",
    "            ELSE NULL\n",
    "        END AS meduc,\n",
    "        -- maternal race\n",
    "        CASE\n",
    "            WHEN  mracehisp >= 1 AND mracehisp <= 8 THEN mracehisp\n",
    "            ELSE NULL\n",
    "        END AS mracehisp,\n",
    "        -- ==================== paternal characteristics ====================\n",
    "        -- father's combined age in years\n",
    "        CASE\n",
    "            WHEN fagecomb >= 9 AND fagecomb < 99 THEN fagecomb\n",
    "            ELSE NULL\n",
    "        END AS fagecomb,\n",
    "        -- paternal education\n",
    "        CASE\n",
    "            WHEN  feduc < 9 THEN feduc\n",
    "            ELSE NULL\n",
    "        END AS feduc,\n",
    "        -- paternal race\n",
    "        CASE\n",
    "            WHEN  fracehisp >= 1 AND fracehisp <= 10 THEN fracehisp\n",
    "            ELSE NULL\n",
    "        END AS fracehisp,\n",
    "        -- ==================== socio-economic indicators ====================\n",
    "        -- payment source recode\n",
    "        CASE\n",
    "            WHEN  pay_rec < 5 THEN pay_rec\n",
    "            ELSE NULL\n",
    "        END AS pay_rec,\n",
    "        -- supplemental nutrition program for women, infants, and children\n",
    "        CASE\n",
    "            WHEN wic = 'Y' THEN 1::UTINYINT\n",
    "            WHEN wic = 'N' THEN 0::UTINYINT\n",
    "            ELSE NULL\n",
    "        END AS wic\n",
    "    FROM\n",
    "        us_births\n",
    "    WHERE year >= {START_YEAR} AND ca_down_c_p_n IS NOT NULL\n",
    "    ORDER BY\n",
    "        year, dob_mm, dob_wk\n",
    "    \"\"\"\n",
    ").df()\n",
    "\n",
    "con.close()\n",
    "\n",
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ap_scorer(estimator, X, y):\n",
    "    proba = estimator.predict_proba(X)[:, 1]\n",
    "    return average_precision_score(y, proba)\n",
    "\n",
    "\n",
    "class LGBMWrapper:\n",
    "    def __init__(self, booster):\n",
    "        self.booster = booster\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # Required by sklearn API; we don't actually train here.\n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        # LightGBM Booster.predict gives P(y=1) for binary by default\n",
    "        p1 = self.booster.predict(X)\n",
    "        p0 = 1.0 - p1\n",
    "        return np.column_stack([p0, p1])\n",
    "\n",
    "    def predict(self, X):\n",
    "        p1 = self.booster.predict(X)\n",
    "        return (p1 >= 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_metrics(y_true, p_valid):\n",
    "    \"\"\"\n",
    "    Compute validation metrics: AUC, AP, log loss, ROC curve.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true : array-like of shape (n_samples,)\n",
    "        True binary labels.\n",
    "    p_valid : array-like of shape (n_samples,)\n",
    "        Predicted probabilities or scores.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    p_valid_auc : float\n",
    "        Area Under the ROC Curve.\n",
    "    p_valid_ap : float\n",
    "        Average Precision score.\n",
    "    p_valid_ll : float\n",
    "        Log loss.\n",
    "    p_valid_fpr : array-like of shape (n_thresholds,)\n",
    "        False Positive Rates for ROC curve.\n",
    "    p_valid_tpr : array-like of shape (n_thresholds,)\n",
    "        True Positive Rates for ROC curve.\n",
    "    p_valid_thresholds : array-like of shape (n_thresholds,)\n",
    "        Thresholds used to compute ROC curve.\n",
    "    \"\"\"\n",
    "    p_valid_auc = roc_auc_score(y_true, p_valid)\n",
    "    p_valid_ap = average_precision_score(y_true, p_valid)\n",
    "    p_valid_ll = log_loss(y_true, p_valid, labels=[0, 1])\n",
    "    p_valid_fpr, p_valid_tpr, p_valid_thresholds = roc_curve(y_true, p_valid)\n",
    "    return (\n",
    "        p_valid_auc,\n",
    "        p_valid_ap,\n",
    "        p_valid_ll,\n",
    "        p_valid_fpr,\n",
    "        p_valid_tpr,\n",
    "        p_valid_thresholds,\n",
    "    )\n",
    "\n",
    "\n",
    "def precision_recall_at_k(y_true, p_valid, K: int = 10000):\n",
    "    \"\"\"\n",
    "    Compute precision and recall at top K predictions.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true : array-like of shape (n_samples,)\n",
    "        True binary labels.\n",
    "    p_valid : array-like of shape (n_samples,)\n",
    "        Predicted probabilities or scores.\n",
    "    K : int\n",
    "        Number of top predictions to consider.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    precision_at_k : float\n",
    "        Precision at top K predictions.\n",
    "    recall_at_k : float\n",
    "        Recall at top K predictions.\n",
    "    \"\"\"\n",
    "    order = np.argsort(-p_valid)\n",
    "    y_sorted = y_true.to_numpy()[order]\n",
    "    precision_at_k = y_sorted[:K].mean()\n",
    "    recall_at_k = y_sorted[:K].sum() / y_true.sum()\n",
    "    return precision_at_k, recall_at_k\n",
    "\n",
    "\n",
    "def precision_recall_at_threshold(y_true, p_valid, thr: float = 0.01):\n",
    "    \"\"\"\n",
    "    Compute precision and recall at a given threshold.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true : array-like of shape (n_samples,)\n",
    "        True binary labels.\n",
    "    p_valid : array-like of shape (n_samples,)\n",
    "        Predicted probabilities or scores.\n",
    "    thr : float\n",
    "        Threshold for converting predicted probabilities to binary predictions.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    prec : float\n",
    "        Precision at the given threshold.\n",
    "    rec : float\n",
    "        Recall at the given threshold.\n",
    "    f1 : float\n",
    "        F1-score at the given threshold.\n",
    "    \"\"\"\n",
    "    y_hat = (p_valid >= thr).astype(int)\n",
    "    prec, rec, f1, _ = precision_recall_fscore_support(y_true, y_hat, average=\"binary\")\n",
    "    return prec, rec, f1\n",
    "\n",
    "\n",
    "def get_metrics(y_true, p_valid, K: int = 10000, thr: float = 0.01):\n",
    "    \"\"\"\n",
    "    Build a DataFrame of validation metrics.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true : array-like of shape (n_samples,)\n",
    "        True binary labels.\n",
    "    p_valid : array-like of shape (n_samples,)\n",
    "        Predicted probabilities or scores.\n",
    "    K : int\n",
    "        Number of top predictions to consider for precision/recall at K.\n",
    "    thr : float\n",
    "        Threshold for precision/recall calculation.\n",
    "    Returns\n",
    "    -------\n",
    "    metrics_df : pd.DataFrame\n",
    "        DataFrame containing validation metrics.\n",
    "    \"\"\"\n",
    "\n",
    "    (\n",
    "        p_valid_auc,\n",
    "        p_valid_ap,\n",
    "        p_valid_ll,\n",
    "        p_valid_fpr,\n",
    "        p_valid_tpr,\n",
    "        p_valid_thresholds,\n",
    "    ) = score_metrics(y_true, p_valid)\n",
    "\n",
    "    precision_at_k, recall_at_k = precision_recall_at_k(y_true, p_valid, K=K)\n",
    "\n",
    "    prec, rec, f1 = precision_recall_at_threshold(y_true, p_valid, thr=thr)\n",
    "\n",
    "    df = pd.DataFrame(\n",
    "        {\n",
    "            \"metric\": [\n",
    "                \"Validation AUC\",\n",
    "                \"Validation AP\",\n",
    "                \"Validation log loss\",\n",
    "                f\"Precision at {K}\",\n",
    "                f\"Recall at {K}\",\n",
    "                f\"Precision (threshold={thr})\",\n",
    "                f\"Recall (threshold={thr})\",\n",
    "            ],\n",
    "            \"value\": [\n",
    "                p_valid_auc,\n",
    "                p_valid_ap,\n",
    "                p_valid_ll,\n",
    "                precision_at_k,\n",
    "                recall_at_k,\n",
    "                prec,\n",
    "                rec,\n",
    "            ],\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return df, p_valid_fpr, p_valid_tpr, p_valid_thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curve(fpr, tpr, model_idx: int, save: bool = False):\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    plt.plot(fpr, tpr, label=\"ROC curve\")\n",
    "    plt.plot([0, 1.0], [0, 1], \"--\", color=\"#999999\", label=\"Random classifier\")\n",
    "    plt.xlim([-0.03, 1.03])\n",
    "    plt.ylim([0, 1.03])\n",
    "    plt.xlabel(\"False Positive Rate (FPR)\")\n",
    "    plt.ylabel(\"True Positive Rate (TPR)\")\n",
    "    plt.title(f\"Model {model_idx}: Receiver Operating Characteristic (ROC) Curve\")\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    if save:\n",
    "        plt.savefig(\n",
    "            f\"{OUTPUT_DIR}/model_{model_idx}_roc_curve_{datetime.now().strftime('%Y%m%d%H%M')}.png\",\n",
    "            dpi=300,\n",
    "            bbox_inches=\"tight\",\n",
    "        )\n",
    "        plt.savefig(\n",
    "            f\"{OUTPUT_DIR}/model_{model_idx}_roc_curve_{datetime.now().strftime('%Y%m%d%H%M')}.svg\",\n",
    "            bbox_inches=\"tight\",\n",
    "        )\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_precision_recall_curve(fpr, tpr, model_idx: int, save: bool = False):\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    plt.plot(fpr, tpr, label=f\"Precision-Recall curve\")\n",
    "    plt.xlim([-0.03, 1.03])\n",
    "    plt.ylim([0, 1.03])\n",
    "    plt.xlabel(\"Recall (TP / (TP + FN))\")\n",
    "    plt.ylabel(\"Precision (TP / (TP + FP))\")\n",
    "    plt.title(f\"Model {model_idx}: Precision-Recall Curve\")\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    if save:\n",
    "        plt.savefig(\n",
    "            f\"{OUTPUT_DIR}/model_{model_idx}_precision_recall_curve_{datetime.now().strftime('%Y%m%d%H%M')}.png\",\n",
    "            dpi=300,\n",
    "            bbox_inches=\"tight\",\n",
    "        )\n",
    "        plt.savefig(\n",
    "            f\"{OUTPUT_DIR}/model_{model_idx}_precision_recall_curve_{datetime.now().strftime('%Y%m%d%H%M')}.svg\",\n",
    "            bbox_inches=\"tight\",\n",
    "        )\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_permutation_importances(result, X_eval, model_idx: int, save: bool = False):\n",
    "    sorted_importances_idx = result.importances_mean.argsort()\n",
    "\n",
    "    importances = pd.DataFrame(\n",
    "        result.importances[sorted_importances_idx].T,\n",
    "        columns=X_eval.columns[sorted_importances_idx],\n",
    "    )\n",
    "    x_size = max(4, min(6, 0.25 * importances.shape[1]))\n",
    "    ax = importances.plot.box(vert=False, whis=10, figsize=(6, x_size))\n",
    "    ax.set_title(f\"Model {model_idx}: Permutation importances\")\n",
    "    ax.axvline(x=0, color=\"k\", linestyle=\"--\")\n",
    "    ax.set_xlabel(\"Decrease in accuracy score\")\n",
    "    ax.set_ylabel(\"Predictor variable\")\n",
    "\n",
    "    if save:\n",
    "        plt.savefig(\n",
    "            f\"{OUTPUT_DIR}/model_{model_idx}_feature_importance_{datetime.now().strftime('%Y%m%d%H%M')}.png\",\n",
    "            dpi=300,\n",
    "            bbox_inches=\"tight\",\n",
    "        )\n",
    "        plt.savefig(\n",
    "            f\"{OUTPUT_DIR}/model_{model_idx}_feature_importance_{datetime.now().strftime('%Y%m%d%H%M')}.svg\",\n",
    "            bbox_inches=\"tight\",\n",
    "        )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define initial feature set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-20T09:03:49.680250500Z",
     "start_time": "2025-12-20T09:03:28.485676Z"
    }
   },
   "outputs": [],
   "source": [
    "numeric = [\n",
    "    \"year\",\n",
    "    \"dbwt\",\n",
    "    \"pwgt_r\",\n",
    "    \"wtgain\",\n",
    "    \"bmi\",\n",
    "    \"mage_c\",\n",
    "    \"fagecomb\",\n",
    "]\n",
    "\n",
    "categorical = [\n",
    "    \"bfacil3\",\n",
    "    \"sex\",\n",
    "    \"precare\",\n",
    "    \"gestrec10\",\n",
    "    \"rf_pdiab\",\n",
    "    \"rf_gdiab\",\n",
    "    \"rf_phype\",\n",
    "    \"rf_ghype\",\n",
    "    \"rf_ehype\",\n",
    "    \"rf_ppterm\",\n",
    "    \"rf_inftr\",\n",
    "    \"rf_fedrg\",\n",
    "    \"rf_artec\",\n",
    "    \"no_risks\",\n",
    "    \"ld_indl\",\n",
    "    \"ld_augm\",\n",
    "    \"me_pres\",\n",
    "    \"dmeth_rec\",\n",
    "    \"apgar5\",\n",
    "    \"apgar10\",\n",
    "    \"ab_aven1\",\n",
    "    \"ab_aven6\",\n",
    "    \"ab_nicu\",\n",
    "    \"ab_surf\",\n",
    "    \"ab_anti\",\n",
    "    \"ab_seiz\",\n",
    "    \"no_abnorm\",\n",
    "    \"ca_anen\",\n",
    "    \"ca_mnsb\",\n",
    "    \"ca_cchd\",\n",
    "    \"ca_cdh\",\n",
    "    \"ca_omph\",\n",
    "    \"ca_gast\",\n",
    "    \"ca_limb\",\n",
    "    \"ca_cleft\",\n",
    "    \"ca_clpal\",\n",
    "    \"ca_hypo\",\n",
    "    \"ca_disor\",\n",
    "    \"no_congen\",\n",
    "    \"meduc\",\n",
    "    \"mracehisp\",\n",
    "    \"feduc\",\n",
    "    \"fracehisp\",\n",
    "    \"pay_rec\",\n",
    "    \"wic\",\n",
    "]\n",
    "\n",
    "features = categorical + numeric\n",
    "\n",
    "X = df[features]\n",
    "y = df[\"ca_down_c_p_n\"]\n",
    "\n",
    "X[categorical] = X[categorical].astype(\"category\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-18T18:32:28.226742800Z",
     "start_time": "2025-12-18T18:32:28.153848900Z"
    }
   },
   "source": [
    "### Split training, validation and calibration data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-20T09:05:14.558206Z",
     "start_time": "2025-12-20T09:03:49.877483900Z"
    }
   },
   "outputs": [],
   "source": [
    "# use half the data for the training set\n",
    "X_train, X_tmp, y_train, y_tmp = train_test_split(\n",
    "    X, y, test_size=TRAINING_SPLIT, stratify=y, random_state=RANDOM_SEED\n",
    ")\n",
    "\n",
    "# use a quarter of the data for training validation and a quarter for calibration\n",
    "X_valid, X_cal, y_valid, y_cal = train_test_split(\n",
    "    X_tmp,\n",
    "    y_tmp,\n",
    "    test_size=(VALIDATION_SPLIT / TRAINING_SPLIT),\n",
    "    stratify=y_tmp,\n",
    "    random_state=RANDOM_SEED,\n",
    ")\n",
    "\n",
    "train_data = lgb.Dataset(\n",
    "    X_train, label=y_train, categorical_feature=categorical, free_raw_data=False\n",
    ")\n",
    "\n",
    "valid_data = lgb.Dataset(\n",
    "    X_valid,\n",
    "    label=y_valid,\n",
    "    categorical_feature=categorical,\n",
    "    reference=train_data,\n",
    "    free_raw_data=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-20T09:05:14.992446900Z",
     "start_time": "2025-12-20T09:05:14.614176800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 39061040 negatives, 19869 positives, probability positive 0.00050867\n",
      "Validation set: 19530520 negatives, 9934 positives, probability positive 0.00050864\n",
      "Calibration set: 19530521 negatives, 9934 positives, probability positive 0.00050864\n"
     ]
    }
   ],
   "source": [
    "neg_count_train = y_train[y_train == 0].count()\n",
    "pos_count_train = y_train[y_train == 1].count()\n",
    "# scale_pos_weight = neg_count_train / pos_count_train\n",
    "\n",
    "neg_count_valid = y_valid[y_valid == 0].count()\n",
    "pos_count_valid = y_valid[y_valid == 1].count()\n",
    "\n",
    "neg_count_cal = y_cal[y_cal == 0].count()\n",
    "pos_count_cal = y_cal[y_cal == 1].count()\n",
    "\n",
    "print(\n",
    "    f\"Training set: {neg_count_train} negatives, {pos_count_train} positives, probability positive {pos_count_train / neg_count_train:.8f}\"\n",
    ")\n",
    "print(\n",
    "    f\"Validation set: {neg_count_valid} negatives, {pos_count_valid} positives, probability positive {pos_count_valid / neg_count_valid:.8f}\"\n",
    ")\n",
    "print(\n",
    "    f\"Calibration set: {neg_count_cal} negatives, {pos_count_cal} positives, probability positive {pos_count_cal / neg_count_cal:.8f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-20T09:05:15.015199200Z",
     "start_time": "2025-12-20T09:05:14.994387100Z"
    }
   },
   "outputs": [],
   "source": [
    "base_params = {\n",
    "    \"objective\": \"binary\",\n",
    "    \"metric\": [\"average_precision\", \"binary_logloss\"],\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    \"max_bin\": 255,  # GPU 63/127; CPU 255\n",
    "    # for now, we do not scale for better interpretability of outputs\n",
    "    \"scale_pos_weight\": 1,\n",
    "    \"force_col_wise\": True,\n",
    "    \"seed\": RANDOM_SEED,\n",
    "    \"num_threads\": NUM_THREADS,\n",
    "    \"verbosity\": 1,\n",
    "}\n",
    "\n",
    "last_best_params = {\n",
    "    \"learning_rate\": 0.01829126776020476,\n",
    "    \"num_leaves\": 102,\n",
    "    \"min_data_in_leaf\": 534,\n",
    "    \"min_gain_to_split\": 0.8303930021015241,\n",
    "    \"feature_fraction\": 0.920035945804595,\n",
    "    \"bagging_fraction\": 0.967714257064493,\n",
    "    \"bagging_freq\": 4,\n",
    "    \"lambda_l1\": 0.00796905087446552,\n",
    "    \"lambda_l2\": 1.0310320881269643,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-18T18:34:50.475698Z",
     "start_time": "2025-12-18T18:34:50.385061200Z"
    }
   },
   "source": [
    "## Hyperparameter tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-20T09:05:15.035955700Z",
     "start_time": "2025-12-20T09:05:15.017199200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters for training:\n",
      "  \"objective\": binary\n",
      "  \"metric\": ['average_precision', 'binary_logloss']\n",
      "  \"boosting_type\": gbdt\n",
      "  \"max_bin\": 255\n",
      "  \"scale_pos_weight\": 1\n",
      "  \"force_col_wise\": True\n",
      "  \"seed\": 202512\n",
      "  \"num_threads\": 24\n",
      "  \"verbosity\": 1\n",
      "  \"learning_rate\": 0.01829126776020476\n",
      "  \"num_leaves\": 102\n",
      "  \"min_data_in_leaf\": 534\n",
      "  \"min_gain_to_split\": 0.8303930021015241\n",
      "  \"feature_fraction\": 0.920035945804595\n",
      "  \"bagging_fraction\": 0.967714257064493\n",
      "  \"bagging_freq\": 4\n",
      "  \"lambda_l1\": 0.00796905087446552\n",
      "  \"lambda_l2\": 1.0310320881269643\n",
      "  \"feature_pre_filter\": True\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    trial_params = {\n",
    "        # required to change min_data_in_leaf across trials without rebuilding the Dataset\n",
    "        \"feature_pre_filter\": False,\n",
    "        # Speed / stability\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.5, log=True),\n",
    "        # Tree complexity\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 32, 512, log=True),\n",
    "        \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 500, 15000, log=True),\n",
    "        \"min_gain_to_split\": trial.suggest_float(\"min_gain_to_split\", 0.0, 1.0),\n",
    "        # Sampling\n",
    "        \"feature_fraction\": trial.suggest_float(\"feature_fraction\", 0.6, 1.0),\n",
    "        \"bagging_fraction\": trial.suggest_float(\"bagging_fraction\", 0.6, 1.0),\n",
    "        \"bagging_freq\": trial.suggest_int(\"bagging_freq\", 1, 10),\n",
    "        # Regularization\n",
    "        \"lambda_l1\": trial.suggest_float(\"lambda_l1\", 1e-8, 10.0, log=True),\n",
    "        \"lambda_l2\": trial.suggest_float(\"lambda_l2\", 1e-8, 10.0, log=True),\n",
    "    }\n",
    "\n",
    "    # Merge: base_params always present; trial_params override if same key exists\n",
    "    params = {**base_params, **trial_params}\n",
    "\n",
    "    pruning_cb = optuna.integration.LightGBMPruningCallback(trial, \"average_precision\")\n",
    "\n",
    "    gbm = lgb.train(\n",
    "        params,\n",
    "        train_data,\n",
    "        num_boost_round=NUM_BOOST_ROUND,\n",
    "        valid_sets=[valid_data],\n",
    "        callbacks=[\n",
    "            lgb.early_stopping(stopping_rounds=EARLY_STOPPING_ROUNDS),\n",
    "            lgb.log_evaluation(period=10),\n",
    "            pruning_cb,\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    # Best score on validation\n",
    "    return gbm.best_score[\"valid_0\"][\"average_precision\"]\n",
    "\n",
    "\n",
    "if SELECT_HYPERPARAMETERS:\n",
    "    study = optuna.create_study(\n",
    "        direction=\"maximize\",\n",
    "        sampler=optuna.samplers.TPESampler(),\n",
    "        pruner=optuna.pruners.HyperbandPruner(),\n",
    "    )\n",
    "\n",
    "    study.optimize(objective, n_trials=OPTIMIZE_TRIALS)\n",
    "\n",
    "    print(study.best_params, study.best_value)\n",
    "\n",
    "    best = study.best_params\n",
    "else:\n",
    "    best = last_best_params\n",
    "\n",
    "# Merge (best overrides base if there are collisions)\n",
    "params = {**base_params, **best}\n",
    "params[\"feature_pre_filter\"] = True  # reset to default for final training\n",
    "\n",
    "print(\"Parameters for training:\")\n",
    "for k, v in params.items():\n",
    "    print(f'  \"{k}\": {v}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 0 (all initial predictors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-20T09:21:26.877789900Z",
     "start_time": "2025-12-20T09:05:15.044465200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 19869, number of negative: 39061040\n",
      "[LightGBM] [Info] Total Bins 1162\n",
      "[LightGBM] [Info] Number of data points in the train set: 39080909, number of used features: 52\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000508 -> initscore=-7.583720\n",
      "[LightGBM] [Info] Start training from score -7.583720\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttrain's average_precision: 0.516727\ttrain's binary_logloss: 0.0027315\tvalid's average_precision: 0.512138\tvalid's binary_logloss: 0.00275202\n",
      "[20]\ttrain's average_precision: 0.532982\ttrain's binary_logloss: 0.00245468\tvalid's average_precision: 0.530261\tvalid's binary_logloss: 0.00247866\n",
      "[30]\ttrain's average_precision: 0.536407\ttrain's binary_logloss: 0.00229348\tvalid's average_precision: 0.533252\tvalid's binary_logloss: 0.00231976\n",
      "[40]\ttrain's average_precision: 0.537152\ttrain's binary_logloss: 0.00217983\tvalid's average_precision: 0.533572\tvalid's binary_logloss: 0.00220888\n",
      "[50]\ttrain's average_precision: 0.537788\ttrain's binary_logloss: 0.00209668\tvalid's average_precision: 0.533834\tvalid's binary_logloss: 0.00212838\n",
      "[60]\ttrain's average_precision: 0.538623\ttrain's binary_logloss: 0.00203504\tvalid's average_precision: 0.534228\tvalid's binary_logloss: 0.00206952\n",
      "[70]\ttrain's average_precision: 0.539425\ttrain's binary_logloss: 0.00198532\tvalid's average_precision: 0.53466\tvalid's binary_logloss: 0.00202204\n",
      "[80]\ttrain's average_precision: 0.540069\ttrain's binary_logloss: 0.00194714\tvalid's average_precision: 0.534959\tvalid's binary_logloss: 0.00198644\n",
      "[90]\ttrain's average_precision: 0.541068\ttrain's binary_logloss: 0.0019167\tvalid's average_precision: 0.535324\tvalid's binary_logloss: 0.00195867\n",
      "[100]\ttrain's average_precision: 0.543545\ttrain's binary_logloss: 0.00189103\tvalid's average_precision: 0.537001\tvalid's binary_logloss: 0.00193578\n",
      "[110]\ttrain's average_precision: 0.546317\ttrain's binary_logloss: 0.00187086\tvalid's average_precision: 0.538839\tvalid's binary_logloss: 0.00191837\n",
      "[120]\ttrain's average_precision: 0.549299\ttrain's binary_logloss: 0.00185382\tvalid's average_precision: 0.540825\tvalid's binary_logloss: 0.00190392\n",
      "[130]\ttrain's average_precision: 0.55308\ttrain's binary_logloss: 0.00183837\tvalid's average_precision: 0.543752\tvalid's binary_logloss: 0.00189116\n",
      "[140]\ttrain's average_precision: 0.556089\ttrain's binary_logloss: 0.00182545\tvalid's average_precision: 0.545925\tvalid's binary_logloss: 0.00188096\n",
      "[150]\ttrain's average_precision: 0.558622\ttrain's binary_logloss: 0.00181418\tvalid's average_precision: 0.54753\tvalid's binary_logloss: 0.00187249\n",
      "[160]\ttrain's average_precision: 0.560934\ttrain's binary_logloss: 0.00180452\tvalid's average_precision: 0.548991\tvalid's binary_logloss: 0.00186555\n",
      "[170]\ttrain's average_precision: 0.563003\ttrain's binary_logloss: 0.00179619\tvalid's average_precision: 0.550308\tvalid's binary_logloss: 0.00186002\n",
      "[180]\ttrain's average_precision: 0.564869\ttrain's binary_logloss: 0.0017884\tvalid's average_precision: 0.551403\tvalid's binary_logloss: 0.00185526\n",
      "[190]\ttrain's average_precision: 0.566355\ttrain's binary_logloss: 0.0017819\tvalid's average_precision: 0.552228\tvalid's binary_logloss: 0.00185167\n",
      "[200]\ttrain's average_precision: 0.567805\ttrain's binary_logloss: 0.00177579\tvalid's average_precision: 0.552955\tvalid's binary_logloss: 0.00184841\n",
      "[210]\ttrain's average_precision: 0.569094\ttrain's binary_logloss: 0.00177036\tvalid's average_precision: 0.553432\tvalid's binary_logloss: 0.00184585\n",
      "[220]\ttrain's average_precision: 0.570325\ttrain's binary_logloss: 0.00176521\tvalid's average_precision: 0.553914\tvalid's binary_logloss: 0.0018436\n",
      "[230]\ttrain's average_precision: 0.571409\ttrain's binary_logloss: 0.00176047\tvalid's average_precision: 0.554285\tvalid's binary_logloss: 0.00184178\n",
      "[240]\ttrain's average_precision: 0.572475\ttrain's binary_logloss: 0.00175591\tvalid's average_precision: 0.554586\tvalid's binary_logloss: 0.00184019\n",
      "[250]\ttrain's average_precision: 0.573551\ttrain's binary_logloss: 0.00175169\tvalid's average_precision: 0.554842\tvalid's binary_logloss: 0.00183886\n",
      "[260]\ttrain's average_precision: 0.574639\ttrain's binary_logloss: 0.00174756\tvalid's average_precision: 0.555089\tvalid's binary_logloss: 0.00183772\n",
      "[270]\ttrain's average_precision: 0.575622\ttrain's binary_logloss: 0.00174385\tvalid's average_precision: 0.555277\tvalid's binary_logloss: 0.00183689\n",
      "[280]\ttrain's average_precision: 0.576567\ttrain's binary_logloss: 0.00174015\tvalid's average_precision: 0.555427\tvalid's binary_logloss: 0.0018361\n",
      "[290]\ttrain's average_precision: 0.577584\ttrain's binary_logloss: 0.00173656\tvalid's average_precision: 0.555549\tvalid's binary_logloss: 0.0018355\n",
      "[300]\ttrain's average_precision: 0.578456\ttrain's binary_logloss: 0.00173321\tvalid's average_precision: 0.555667\tvalid's binary_logloss: 0.00183482\n",
      "[310]\ttrain's average_precision: 0.579338\ttrain's binary_logloss: 0.00172993\tvalid's average_precision: 0.555733\tvalid's binary_logloss: 0.0018344\n",
      "[320]\ttrain's average_precision: 0.580134\ttrain's binary_logloss: 0.00172695\tvalid's average_precision: 0.555852\tvalid's binary_logloss: 0.00183393\n",
      "[330]\ttrain's average_precision: 0.580994\ttrain's binary_logloss: 0.00172392\tvalid's average_precision: 0.555926\tvalid's binary_logloss: 0.00183357\n",
      "[340]\ttrain's average_precision: 0.581968\ttrain's binary_logloss: 0.00172076\tvalid's average_precision: 0.556085\tvalid's binary_logloss: 0.0018331\n",
      "[350]\ttrain's average_precision: 0.582851\ttrain's binary_logloss: 0.00171774\tvalid's average_precision: 0.556165\tvalid's binary_logloss: 0.00183286\n",
      "[360]\ttrain's average_precision: 0.583668\ttrain's binary_logloss: 0.00171508\tvalid's average_precision: 0.556242\tvalid's binary_logloss: 0.00183269\n"
     ]
    }
   ],
   "source": [
    "model_idx = 0\n",
    "model_name = f\"Model {model_idx} (all initial predictors)\"\n",
    "\n",
    "gbm = lgb.train(\n",
    "    params,\n",
    "    train_data,\n",
    "    num_boost_round=NUM_BOOST_ROUND,\n",
    "    valid_sets=[train_data, valid_data],\n",
    "    valid_names=[\"train\", \"valid\"],\n",
    "    callbacks=[\n",
    "        early_stopping(stopping_rounds=EARLY_STOPPING_ROUNDS),\n",
    "        log_evaluation(period=10),\n",
    "    ],\n",
    ")\n",
    "\n",
    "best_iter = gbm.best_iteration\n",
    "gbm.save_model(\n",
    "    f\"{OUTPUT_DIR}/model_{model_idx}_{datetime.now().strftime(\"%Y%m%d%H%M\")}.txt\",\n",
    "    num_iteration=best_iter,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict\n",
    "\n",
    "Produce predictions on validation set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-20T09:22:16.286868700Z",
     "start_time": "2025-12-20T09:21:55.048014700Z"
    }
   },
   "outputs": [],
   "source": [
    "p_valid = gbm.predict(X_valid, num_iteration=best_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df, p_valid_fpr, p_valid_tpr, p_valid_thresholds = get_metrics(\n",
    "    y_valid, p_valid, K=10000, thr=0.01\n",
    ")\n",
    "\n",
    "metrics_df.to_csv(\n",
    "    f\"{OUTPUT_DIR}/model_{model_idx}_validation_metrics_{datetime.now().strftime(\"%Y%m%d%H%M\")}.csv\",\n",
    "    index=False,\n",
    ")\n",
    "\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc_curve(p_valid_fpr, p_valid_tpr, model_idx, save=SAVE_PLOTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_precision_recall_curve(p_valid_fpr, p_valid_tpr, model_idx, save=SAVE_PLOTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature importance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T18:39:26.603322400Z",
     "start_time": "2025-12-19T18:39:26.554641400Z"
    }
   },
   "outputs": [],
   "source": [
    "importance_gain = gbm.feature_importance(importance_type=\"gain\")\n",
    "\n",
    "df_imp_gain = pd.DataFrame(\n",
    "    {\"feature\": features, \"importance_gain\": importance_gain}\n",
    ").sort_values(\"importance_gain\", ascending=False)\n",
    "\n",
    "df_imp_gain.to_csv(\n",
    "    f\"{OUTPUT_DIR}/model_{model_idx}_feature_importance_gain_{datetime.now().strftime(\"%Y%m%d%H%M\")}.csv\",\n",
    "    index=False,\n",
    ")\n",
    "df_imp_gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_explain_set(\n",
    "    booster,\n",
    "    X_valid,\n",
    "    y_valid,\n",
    "    categorical,\n",
    "    n_neg_rand=100_000,\n",
    "    n_neg_hard=100_000,\n",
    "    seed=RANDOM_SEED,\n",
    "):\n",
    "    \"\"\"\n",
    "    Build a validation set for explanation by combining all positives,\n",
    "    a random sample of negatives, and a sample of hard negatives (highest predicted\n",
    "    probabilities among negatives).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    booster : lightgbm.Booster\n",
    "        Trained LightGBM booster.\n",
    "    X_valid : pd.DataFrame\n",
    "        Validation feature set.\n",
    "    y_valid : pd.Series\n",
    "        Validation target values.\n",
    "    categorical : list of str\n",
    "        List of categorical feature names.\n",
    "    n_neg_rand : int\n",
    "        Number of random negatives to include.\n",
    "    n_neg_hard : int\n",
    "        Number of hard negatives to include.\n",
    "    seed : int\n",
    "        Random seed for reproducibility.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    X_explain : pd.DataFrame\n",
    "        Explanation feature set.\n",
    "    y_explain : pd.Series\n",
    "        Explanation target values.\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    yv = np.asarray(y_valid)\n",
    "    idx_pos = np.flatnonzero(yv == 1)\n",
    "    idx_neg = np.flatnonzero(yv == 0)\n",
    "\n",
    "    # predict once on valid to pick hard negatives\n",
    "    p_valid = booster.predict(X_valid, num_iteration=booster.best_iteration)\n",
    "\n",
    "    # random negatives\n",
    "    n_neg_rand = min(n_neg_rand, idx_neg.size)\n",
    "    idx_neg_rand = rng.choice(idx_neg, size=n_neg_rand, replace=False)\n",
    "\n",
    "    # hard negatives (top predicted p among negatives)\n",
    "    n_neg_hard = min(n_neg_hard, idx_neg.size)\n",
    "    p_neg = p_valid[idx_neg]\n",
    "    hard_local = np.argpartition(p_neg, -n_neg_hard)[-n_neg_hard:]\n",
    "    idx_neg_hard = idx_neg[hard_local]\n",
    "\n",
    "    idx = np.unique(np.concatenate([idx_pos, idx_neg_rand, idx_neg_hard]))\n",
    "    rng.shuffle(idx)\n",
    "\n",
    "    X_eval = X_valid.iloc[idx].astype(np.float64).replace({pd.NA: np.nan}).copy()\n",
    "    X_eval[categorical] = X_eval[categorical].astype(\"category\")\n",
    "    y_eval = pd.Series(yv[idx], index=X_valid.index[idx])\n",
    "    return X_eval, y_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation subset for permutation importances and SHAP analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_eval, y_eval = build_explain_set(gbm, X_valid, y_valid, categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_wrapped = LGBMWrapper(gbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = permutation_importance(\n",
    "    model_wrapped,\n",
    "    X_eval,\n",
    "    y_eval,\n",
    "    scoring=ap_scorer,\n",
    "    n_repeats=10,\n",
    "    n_jobs=NUM_THREADS,\n",
    "    random_state=RANDOM_SEED,\n",
    ")\n",
    "\n",
    "perm_importance = pd.DataFrame(\n",
    "    {\n",
    "        \"feature\": X_eval.columns,\n",
    "        \"importance_mean\": result.importances_mean,\n",
    "        \"importance_std\": result.importances_std,\n",
    "    }\n",
    ").sort_values(\"importance_mean\", ascending=False)\n",
    "\n",
    "perm_importance.to_csv(\n",
    "    f\"{OUTPUT_DIR}/permutation_importance_{datetime.now().strftime(\"%Y%m%d%H%M\")}.csv\",\n",
    "    index=False,\n",
    ")\n",
    "perm_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_permutation_importances(result, X_eval, model_idx, save=SAVE_PLOTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance, corr = stats_utils.distance_corr_dissimilarity(X_eval)\n",
    "condensed = squareform(distance, checks=True)\n",
    "dist_linkage = hierarchy.ward(condensed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 8))\n",
    "dendro_0 = hierarchy.dendrogram(\n",
    "    dist_linkage, labels=X_eval.columns.to_list(), orientation=\"right\", ax=plt.axes()\n",
    ")\n",
    "plt.vlines(0.5, 0, 500, linestyle=\"--\", color=\"#b2b4549f\", linewidth=2)\n",
    "plt.xlabel(\"Ward linkage distance (increase in within-cluster variance)\")\n",
    "plt.ylabel(\"Predictors\")\n",
    "plt.title(f\"Model {model_idx}: Hierarchical clustering of predictors\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dendro_idx = np.arange(0, len(dendro_0[\"ivl\"]))\n",
    "\n",
    "with plt.rc_context(\n",
    "    {\"ytick.labelsize\": 12, \"xtick.labelsize\": 12, \"axes.titlesize\": 12}\n",
    "):\n",
    "    plt.figure(figsize=(18, 18))\n",
    "    plt.set_cmap(\"viridis\")\n",
    "    ax = plt.axes()\n",
    "    im = ax.imshow(corr[dendro_0[\"leaves\"], :][:, dendro_0[\"leaves\"]])\n",
    "    ax.set_title(f\"Model {model_idx}: Correlation heatmap of predictors\")\n",
    "    ax.set_xticks(dendro_idx)\n",
    "    ax.set_yticks(dendro_idx)\n",
    "    ax.set_xticklabels(dendro_0[\"ivl\"], rotation=\"vertical\")\n",
    "    ax.set_yticklabels(dendro_0[\"ivl\"])\n",
    "    plt.colorbar(im, ax=ax, fraction=0.03, pad=0.025)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.TreeExplainer(\n",
    "    gbm, feature_perturbation=\"tree_path_dependent\", model_output=\"raw\"\n",
    ")\n",
    "\n",
    "explanation = explainer(X_eval)\n",
    "\n",
    "clustering = shap.utils.hclust(\n",
    "    X_eval, y_eval, linkage=\"average\", random_state=RANDOM_SEED\n",
    ")\n",
    "\n",
    "shap_values = explanation.values\n",
    "\n",
    "shap_importance = pd.DataFrame(\n",
    "    {\n",
    "        \"feature\": X_eval.columns,\n",
    "        \"mean_abs_shap\": np.mean(np.abs(shap_values), axis=0),\n",
    "    }\n",
    ").sort_values(\"mean_abs_shap\", ascending=False)\n",
    "\n",
    "shap_importance.to_csv(\n",
    "    f\"{OUTPUT_DIR}/model_{model_idx}_shap_importance_{datetime.now().strftime(\"%Y%m%d%H%M\")}.csv\",\n",
    "    index=False,\n",
    ")\n",
    "shap_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_importance[\"feature\"].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We cannot plot millions of observations, so for SHAP analysis, we take a random selection of 10,000 positives and 50,000 negatives.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with plt.rc_context({\"axes.titlesize\": 12}):\n",
    "    plot = plt.figure(figsize=(8, 10))\n",
    "    ax = plot.subplots()\n",
    "    ax.set_title(f\"Model 0: SHAP values for predictor variables across all samples\")\n",
    "    shap.plots.bar(explanation, max_display=30, ax=ax)  # clustering=clustering_0,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with plt.rc_context({\"axes.titlesize\": 12}):\n",
    "    plot = plt.figure()\n",
    "    ax = plot.subplots()\n",
    "    ax.set_title(\n",
    "        f\"Model {model_idx}: SHAP values for predictor variables across all samples\"\n",
    "    )\n",
    "    shap.plots.beeswarm(explanation, max_display=30, plot_size=(8, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.scatter(explanation[:, \"year\"], color=explanation[:, \"mage_c\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_remove_0 = [\n",
    "    \"fracehisp\",  # correlated with mracehisp, keep mracehisp\n",
    "    \"fagecomb\",  # correlated with mage_c, keep mage_c\n",
    "    \"pwgt_r\",  # correlated with bmi, keep bmi\n",
    "    \"ab_aven6\",  # correlated with ab_aven1, keep ab_aven\n",
    "    \"feduc\",  # low signal\n",
    "    \"ld_indl\",  # low signal\n",
    "    \"ab_surf\",  # low signal\n",
    "    \"sex\",  # low signal\n",
    "    \"rf_phype\",  # low signal\n",
    "    \"ab_seiz\",  # low signal\n",
    "    \"rf_ghype\",  # low signal\n",
    "    \"rf_gdiab\",  # low signal\n",
    "    \"wic\",  # low signal, correlated with pay_rec, meduc, feduc\n",
    "    \"rf_pdiab\",  # low signal\n",
    "    \"rf_inftr\",  # low signal\n",
    "    \"rf_ppterm\",  # low signal\n",
    "    \"rf_fedrg\",  # low signal\n",
    "    \"rf_artec\",  # low signal\n",
    "    \"apgar10\",  # low signal, we keep apgar5\n",
    "    \"no_risks\",  # low signal\n",
    "]\n",
    "\n",
    "X_train = X_train.drop(columns=features_to_remove_0)\n",
    "X_valid = X_valid.drop(columns=features_to_remove_0)\n",
    "\n",
    "features = X_train.columns.to_list()\n",
    "categorical = [col for col in categorical if col not in features_to_remove_0]\n",
    "\n",
    "train_data = lgb.Dataset(\n",
    "    X_train, label=y_train, categorical_feature=categorical, free_raw_data=False\n",
    ")\n",
    "\n",
    "valid_data = lgb.Dataset(\n",
    "    X_valid,\n",
    "    label=y_valid,\n",
    "    categorical_feature=categorical,\n",
    "    reference=train_data,\n",
    "    free_raw_data=False,\n",
    ")\n",
    "\n",
    "model_idx = 1\n",
    "model_name = (\n",
    "    f\"Model {model_idx} (after removing {len(features_to_remove_0)} predictors)\"\n",
    ")\n",
    "\n",
    "print(f\"Features removed: {features_to_remove_0}\")\n",
    "print(f\"Features remaining: {features}\")\n",
    "print(f\"Number of features in {model_name}: {X_train.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm = lgb.train(\n",
    "    params,\n",
    "    train_data,\n",
    "    num_boost_round=NUM_BOOST_ROUND,\n",
    "    valid_sets=[train_data, valid_data],\n",
    "    valid_names=[\"train\", \"valid\"],\n",
    "    callbacks=[\n",
    "        early_stopping(stopping_rounds=EARLY_STOPPING_ROUNDS),\n",
    "        log_evaluation(period=10),\n",
    "    ],\n",
    ")\n",
    "\n",
    "best_iter = gbm.best_iteration\n",
    "gbm.save_model(\n",
    "    f\"{OUTPUT_DIR}/model_{model_idx}_{datetime.now().strftime(\"%Y%m%d%H%M\")}.txt\",\n",
    "    num_iteration=best_iter,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_valid = gbm.predict(X_valid, num_iteration=best_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df, p_valid_fpr, p_valid_tpr, p_valid_thresholds = get_metrics(\n",
    "    y_valid, p_valid, K=10000, thr=0.01\n",
    ")\n",
    "\n",
    "metrics_df.to_csv(\n",
    "    f\"{OUTPUT_DIR}/model_{model_idx}_validation_metrics_{datetime.now().strftime(\"%Y%m%d%H%M\")}.csv\",\n",
    "    index=False,\n",
    ")\n",
    "\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc_curve(p_valid_fpr, p_valid_tpr, model_idx, save=SAVE_PLOTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_precision_recall_curve(p_valid_fpr, p_valid_tpr, model_idx, save=SAVE_PLOTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_gain = gbm.feature_importance(importance_type=\"gain\")\n",
    "\n",
    "df_imp_gain = pd.DataFrame(\n",
    "    {\"feature\": features, \"importance_gain\": importance_gain}\n",
    ").sort_values(\"importance_gain\", ascending=False)\n",
    "\n",
    "df_imp_gain.to_csv(\n",
    "    f\"{OUTPUT_DIR}/model_{model_idx}_feature_importance_gain_{datetime.now().strftime(\"%Y%m%d%H%M\")}.csv\",\n",
    "    index=False,\n",
    ")\n",
    "df_imp_gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_eval = X_valid.loc[eval_idx].astype(np.float64).replace({pd.NA: np.nan})\n",
    "X_eval[categorical] = X_eval[categorical].astype(\"category\")\n",
    "\n",
    "\n",
    "model_wrapped = LGBMWrapper(gbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = permutation_importance(\n",
    "    model_wrapped,\n",
    "    X_eval,\n",
    "    y_eval,\n",
    "    scoring=ap_scorer,\n",
    "    n_repeats=10,\n",
    "    n_jobs=NUM_THREADS,\n",
    "    random_state=RANDOM_SEED,\n",
    ")\n",
    "\n",
    "perm_importance = pd.DataFrame(\n",
    "    {\n",
    "        \"feature\": X_eval.columns,\n",
    "        \"importance_mean\": result.importances_mean,\n",
    "        \"importance_std\": result.importances_std,\n",
    "    }\n",
    ").sort_values(\"importance_mean\", ascending=False)\n",
    "\n",
    "perm_importance.to_csv(\n",
    "    f\"{OUTPUT_DIR}/permutation_importance_{datetime.now().strftime(\"%Y%m%d%H%M\")}.csv\",\n",
    "    index=False,\n",
    ")\n",
    "perm_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_permutation_importances(result, X_eval, model_idx, save=SAVE_PLOTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance, corr = stats_utils.distance_corr_dissimilarity(X_eval)\n",
    "condensed = squareform(distance, checks=True)\n",
    "dist_linkage = hierarchy.ward(condensed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 6))\n",
    "dendro_0 = hierarchy.dendrogram(\n",
    "    dist_linkage, labels=X_eval.columns.to_list(), orientation=\"right\", ax=plt.axes()\n",
    ")\n",
    "plt.vlines(0.5, 0, 500, linestyle=\"--\", color=\"#b2b4549f\", linewidth=2)\n",
    "plt.xlabel(\"Ward linkage distance (increase in within-cluster variance)\")\n",
    "plt.ylabel(\"Predictors\")\n",
    "plt.title(f\"Model {model_idx}: Hierarchical clustering of predictors\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dendro_idx = np.arange(0, len(dendro_0[\"ivl\"]))\n",
    "\n",
    "with plt.rc_context(\n",
    "    {\"ytick.labelsize\": 12, \"xtick.labelsize\": 12, \"axes.titlesize\": 12}\n",
    "):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.set_cmap(\"viridis\")\n",
    "    ax = plt.axes()\n",
    "    im = ax.imshow(corr[dendro_0[\"leaves\"], :][:, dendro_0[\"leaves\"]])\n",
    "    ax.set_title(f\"Model: Correlation heatmap of predictors\")\n",
    "    ax.set_xticks(dendro_idx)\n",
    "    ax.set_yticks(dendro_idx)\n",
    "    ax.set_xticklabels(dendro_0[\"ivl\"], rotation=\"vertical\")\n",
    "    ax.set_yticklabels(dendro_0[\"ivl\"])\n",
    "    plt.colorbar(im, ax=ax, fraction=0.03, pad=0.025)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.TreeExplainer(gbm)\n",
    "explanation = explainer(X_eval)\n",
    "clustering = shap.utils.hclust(\n",
    "    X_eval, y_eval, linkage=\"average\", random_state=RANDOM_SEED\n",
    ")\n",
    "shap_values = explanation.values\n",
    "\n",
    "shap_importance = pd.DataFrame(\n",
    "    {\n",
    "        \"feature\": X_eval.columns,\n",
    "        \"mean_abs_shap\": np.mean(np.abs(shap_values), axis=0),\n",
    "    }\n",
    ").sort_values(\"mean_abs_shap\", ascending=False)\n",
    "\n",
    "shap_importance.to_csv(\n",
    "    f\"{OUTPUT_DIR}/model_{model_idx}_shap_importance_{datetime.now().strftime(\"%Y%m%d%H%M\")}.csv\",\n",
    "    index=False,\n",
    ")\n",
    "shap_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_importance[\"feature\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with plt.rc_context({\"axes.titlesize\": 12}):\n",
    "    plot = plt.figure(figsize=(8, 10))\n",
    "    ax = plot.subplots()\n",
    "    ax.set_title(\n",
    "        f\"Model {model_idx}: SHAP values for predictor variables across all samples\"\n",
    "    )\n",
    "    shap.plots.bar(explanation, max_display=30, ax=ax)  # clustering=clustering_0,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with plt.rc_context({\"axes.titlesize\": 12}):\n",
    "    plot = plt.figure()\n",
    "    ax = plot.subplots()\n",
    "    ax.set_title(\n",
    "        f\"Model {model_idx}: SHAP values for predictor variables across all samples\"\n",
    "    )\n",
    "    shap.plots.beeswarm(explanation, max_display=30, plot_size=(8, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.scatter(explanation[:, \"year\"], color=explanation[:, \"mage_c\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_remove_1 = [\n",
    "    \"wtgain\",  # correlated with bmi\n",
    "    \"meduc\",  # low signal\n",
    "    \"pay_rec\",  # low signal\n",
    "    \"ca_gast\",  # low signal\n",
    "    \"dmeth_rec\",  # low signal\n",
    "    \"ca_anen\",  # low signal\n",
    "    \"me_pres\",  # low signal\n",
    "    \"ld_augm\",  # low signal\n",
    "    \"bfacil3\",  # low signal\n",
    "    \"sex\",  # low signal\n",
    "]\n",
    "\n",
    "X_train = X_train.drop(columns=features_to_remove_1)\n",
    "X_valid = X_valid.drop(columns=features_to_remove_1)\n",
    "\n",
    "features = X_train.columns.to_list()\n",
    "categorical = [col for col in categorical if col not in features_to_remove_1]\n",
    "\n",
    "train_data = lgb.Dataset(\n",
    "    X_train, label=y_train, categorical_feature=categorical, free_raw_data=False\n",
    ")\n",
    "\n",
    "valid_data = lgb.Dataset(\n",
    "    X_valid,\n",
    "    label=y_valid,\n",
    "    categorical_feature=categorical,\n",
    "    reference=train_data,\n",
    "    free_raw_data=False,\n",
    ")\n",
    "\n",
    "model_idx = 2\n",
    "model_name = (\n",
    "    f\"Model {model_idx} (after removing {len(features_to_remove_1)} predictors)\"\n",
    ")\n",
    "\n",
    "print(f\"Features removed: {features_to_remove_1}\")\n",
    "print(f\"Features remaining: {features}\")\n",
    "print(f\"Number of features in {model_name}: {X_train.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm = lgb.train(\n",
    "    params,\n",
    "    train_data,\n",
    "    num_boost_round=NUM_BOOST_ROUND,\n",
    "    valid_sets=[train_data, valid_data],\n",
    "    valid_names=[\"train\", \"valid\"],\n",
    "    callbacks=[\n",
    "        early_stopping(stopping_rounds=EARLY_STOPPING_ROUNDS),\n",
    "        log_evaluation(period=10),\n",
    "    ],\n",
    ")\n",
    "\n",
    "best_iter = gbm.best_iteration\n",
    "gbm.save_model(\n",
    "    f\"{OUTPUT_DIR}/model_{model_idx}_{datetime.now().strftime(\"%Y%m%d%H%M\")}.txt\",\n",
    "    num_iteration=best_iter,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_valid = gbm.predict(X_valid, num_iteration=best_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df, p_valid_fpr, p_valid_tpr, p_valid_thresholds = get_metrics(\n",
    "    y_valid, p_valid, K=10000, thr=0.01\n",
    ")\n",
    "\n",
    "metrics_df.to_csv(\n",
    "    f\"{OUTPUT_DIR}/model_{model_idx}_validation_metrics_{datetime.now().strftime(\"%Y%m%d%H%M\")}.csv\",\n",
    "    index=False,\n",
    ")\n",
    "\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc_curve(p_valid_fpr, p_valid_tpr, model_idx, save=SAVE_PLOTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_precision_recall_curve(p_valid_fpr, p_valid_tpr, model_idx, save=SAVE_PLOTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_gain = gbm.feature_importance(importance_type=\"gain\")\n",
    "\n",
    "df_imp_gain = pd.DataFrame(\n",
    "    {\"feature\": features, \"importance_gain\": importance_gain}\n",
    ").sort_values(\"importance_gain\", ascending=False)\n",
    "\n",
    "df_imp_gain.to_csv(\n",
    "    f\"{OUTPUT_DIR}/model_{model_idx}_feature_importance_gain_{datetime.now().strftime(\"%Y%m%d%H%M\")}.csv\",\n",
    "    index=False,\n",
    ")\n",
    "df_imp_gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_eval = X_valid.loc[eval_idx].astype(np.float64).replace({pd.NA: np.nan})\n",
    "X_eval[categorical] = X_eval[categorical].astype(\"category\")\n",
    "\n",
    "\n",
    "model_wrapped = LGBMWrapper(gbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = permutation_importance(\n",
    "    model_wrapped,\n",
    "    X_eval,\n",
    "    y_eval,\n",
    "    scoring=ap_scorer,\n",
    "    n_repeats=10,\n",
    "    n_jobs=NUM_THREADS,\n",
    "    random_state=RANDOM_SEED,\n",
    ")\n",
    "\n",
    "perm_importance = pd.DataFrame(\n",
    "    {\n",
    "        \"feature\": X_eval.columns,\n",
    "        \"importance_mean\": result.importances_mean,\n",
    "        \"importance_std\": result.importances_std,\n",
    "    }\n",
    ").sort_values(\"importance_mean\", ascending=False)\n",
    "\n",
    "perm_importance.to_csv(\n",
    "    f\"{OUTPUT_DIR}/permutation_importance_{datetime.now().strftime(\"%Y%m%d%H%M\")}.csv\",\n",
    "    index=False,\n",
    ")\n",
    "perm_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_permutation_importances(result, X_eval, model_idx, save=SAVE_PLOTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance, corr = stats_utils.distance_corr_dissimilarity(X_eval)\n",
    "condensed = squareform(distance, checks=True)\n",
    "dist_linkage = hierarchy.ward(condensed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calibration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_cal_raw = gbm.predict(X_cal, num_iteration=gbm.best_iteration, raw_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calibrator = LogisticRegression(solver=\"lbfgs\", max_iter=1000)\n",
    "calibrator.fit(p_cal_raw.reshape(-1, 1), y_cal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_proba_calibrated(gbm, calibrator, X_new, num_iteration=None):\n",
    "    p_raw = gbm.predict(X_new, num_iteration=num_iteration, raw_score=True)\n",
    "    return calibrator.predict_proba(p_raw.reshape(-1, 1))[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_valid_cal = predict_proba_calibrated(\n",
    "    gbm, calibrator, X_valid, num_iteration=gbm.best_iteration\n",
    ")\n",
    "p_valid_raw = gbm.predict(X_valid, num_iteration=gbm.best_iteration)\n",
    "\n",
    "print(\"Raw logloss:\", log_loss(y_valid, p_valid_raw, labels=[0, 1]))\n",
    "print(\"Cal logloss:\", log_loss(y_valid, p_valid_cal, labels=[0, 1]))\n",
    "print(\"Raw brier:  \", brier_score_loss(y_valid, p_valid_raw))\n",
    "print(\"Cal brier:  \", brier_score_loss(y_valid, p_valid_cal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-stats-models-ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
