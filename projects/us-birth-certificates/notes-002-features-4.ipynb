{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Notes - Features 4"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import duckdb\n",
    "import os\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from variables import Variables as vars\n",
    "\n",
    "plt.style.use(\"../../notebook.mplstyle\")\n",
    "\n",
    "os.makedirs(\"./output\", exist_ok=True)\n",
    "\n",
    "RANDOM_SEED = 1673025012\n",
    "np.random.seed(RANDOM_SEED)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "con = duckdb.connect(\"./data/us_births.db\", read_only=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df = con.execute(\"\"\"\n",
    "    SELECT\n",
    "        year,\n",
    "        me_pres,\n",
    "        count(*)\n",
    "    FROM us_births\n",
    "    GROUP BY year, me_pres\n",
    "    ORDER BY year, me_pres\n",
    "    \"\"\").df()\n",
    "df"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df = con.execute(\n",
    "    \"\"\"\n",
    "    SELECT\n",
    "        year,\n",
    "        -- (training label) indicated if C or P, otherwise not\n",
    "        CASE\n",
    "            WHEN COALESCE (ca_down, ca_downs) = 'C' THEN 1::UTINYINT\n",
    "            WHEN COALESCE (ca_down, ca_downs) = 'P' THEN 1::UTINYINT\n",
    "            ELSE 0::UTINYINT\n",
    "        END AS ca_down_c_or_p,\n",
    "        -- maternal age in years\n",
    "        mage_c,\n",
    "        -- father's combined age in years\n",
    "        CASE\n",
    "            WHEN fagecomb >= 9 AND fagecomb < 99 THEN fagecomb\n",
    "            ELSE NULL\n",
    "        END AS fagecomb,\n",
    "        -- father's age recode\n",
    "        CASE\n",
    "            WHEN fagerec11 >= 1 AND fagerec11 < 10 THEN fagerec11\n",
    "            ELSE NULL\n",
    "        END AS fagerec11,\n",
    "        -- pre-pregnancy weight recode (in pounds)\n",
    "        CASE\n",
    "            WHEN pwgt_r >= 75 AND pwgt_r <= 375 THEN pwgt_r\n",
    "            ELSE NULL\n",
    "        END AS pwgt_r,\n",
    "        -- delivery weight recode (in pounds)\n",
    "        CASE\n",
    "            WHEN dwgt_r >= 100 AND dwgt_r <= 400 THEN dwgt_r\n",
    "            ELSE NULL\n",
    "        END AS dwgt_r,\n",
    "        -- weight gain in pounds (98 = 98+)\n",
    "        CASE\n",
    "            WHEN wtgain >= 0 AND wtgain <= 98 THEN wtgain\n",
    "            ELSE NULL\n",
    "        END AS wtgain,\n",
    "        -- weight gain recode\n",
    "        CASE\n",
    "            WHEN wtgain_rec >= 1 AND wtgain_rec <= 5 THEN wtgain_rec\n",
    "            ELSE NULL\n",
    "        END AS wtgain_rec,\n",
    "        -- previous preterm birth\n",
    "        CASE\n",
    "            WHEN rf_ppterm = 'Y' THEN 1::UTINYINT\n",
    "            WHEN rf_ppterm = 'N' THEN 0::UTINYINT\n",
    "            ELSE NULL\n",
    "        END AS rf_ppterm,\n",
    "        -- fertility enhancing drugs\n",
    "        CASE\n",
    "            WHEN rf_fedrg = 'Y' THEN 1::UTINYINT\n",
    "            WHEN rf_fedrg = 'N' THEN 0::UTINYINT\n",
    "            ELSE NULL\n",
    "        END AS rf_fedrg,\n",
    "        -- asst. reproductive technology\n",
    "        CASE\n",
    "            WHEN rf_artec = 'Y' THEN 1::UTINYINT\n",
    "            WHEN rf_artec = 'N' THEN 0::UTINYINT\n",
    "            ELSE NULL\n",
    "        END AS rf_artec,\n",
    "        -- no risk factors reported\n",
    "        CASE\n",
    "            WHEN no_risks <= 1 THEN no_risks\n",
    "            ELSE NULL\n",
    "        END AS no_risks,\n",
    "        -- induction of labor\n",
    "        CASE\n",
    "            WHEN ld_indl = 'Y' THEN 1::UTINYINT\n",
    "            WHEN ld_indl = 'N' THEN 0::UTINYINT\n",
    "            ELSE NULL\n",
    "        END AS ld_indl,\n",
    "        -- fetal presentation at delivery (TODO: remove cast when import fixed)\n",
    "        CASE\n",
    "            WHEN CAST(me_pres as UTINYINT) >= 1 AND CAST(me_pres as UTINYINT)  <= 3 THEN CAST(me_pres as UTINYINT)\n",
    "            ELSE NULL\n",
    "        END AS me_pres,\n",
    "        -- final route and method of delivery (TODO: remove cast when import fixed)\n",
    "        CASE\n",
    "            WHEN CAST(me_route as UTINYINT) >= 1 AND CAST(me_route as UTINYINT)  <= 3 THEN CAST(me_route as UTINYINT)\n",
    "            ELSE NULL\n",
    "        END AS me_route,\n",
    "        -- delivery method recode\n",
    "        CASE\n",
    "            WHEN dmeth_rec >= 1 AND dmeth_rec <= 2 THEN dmeth_rec\n",
    "            ELSE NULL\n",
    "        END AS dmeth_rec,\n",
    "        -- attendant at birth\n",
    "        CASE\n",
    "            WHEN attendant >= 1 AND attendant <= 5 THEN attendant\n",
    "            ELSE NULL\n",
    "        END AS attendant,\n",
    "        -- sex of baby\n",
    "        CASE\n",
    "            WHEN sex = 'M' THEN 1::UTINYINT\n",
    "            WHEN sex = 'F' THEN 0::UTINYINT\n",
    "            ELSE NULL\n",
    "        END AS sex,\n",
    "        -- congenital disorder\n",
    "        CASE\n",
    "            WHEN ca_disor = 'C' THEN 1::UTINYINT\n",
    "            WHEN ca_disor = 'P' THEN 2::UTINYINT\n",
    "            WHEN ca_disor = 'N' THEN 0::UTINYINT\n",
    "            ELSE NULL\n",
    "        END\n",
    "        AS ca_disor,\n",
    "        -- congenital heart defect\n",
    "        CASE\n",
    "            WHEN ca_cchd = 'Y' THEN 1::UTINYINT\n",
    "            WHEN ca_cchd = 'N' THEN 0::UTINYINT\n",
    "            ELSE NULL\n",
    "        END AS ca_cchd,\n",
    "        -- ca_cdh\n",
    "        CASE\n",
    "            WHEN ca_cdh = 'Y' THEN 1::UTINYINT\n",
    "            WHEN ca_cdh = 'N' THEN 0::UTINYINT\n",
    "            ELSE NULL\n",
    "        END AS ca_cdh,\n",
    "        -- omphalocele\n",
    "        CASE\n",
    "            WHEN ca_omph = 'Y' THEN 1::UTINYINT\n",
    "            WHEN ca_omph = 'N' THEN 0::UTINYINT\n",
    "            ELSE NULL\n",
    "        END AS ca_omph,\n",
    "        -- gastroschisis\n",
    "        CASE\n",
    "            WHEN ca_gast = 'Y' THEN 1::UTINYINT\n",
    "            WHEN ca_gast = 'N' THEN 0::UTINYINT\n",
    "            ELSE NULL\n",
    "        END AS ca_gast,\n",
    "        -- maternal body mass index\n",
    "        CASE\n",
    "            WHEN bmi >= 13.0 AND bmi < 69.9 THEN bmi\n",
    "            ELSE NULL\n",
    "        END\n",
    "        AS bmi,\n",
    "        -- maternal bmi recode\n",
    "        CASE\n",
    "            WHEN bmi_r >= 1 AND bmi_r <= 6 THEN bmi_r\n",
    "            ELSE NULL\n",
    "        END\n",
    "        AS bmi_r,\n",
    "        -- maternal education\n",
    "        CASE\n",
    "            WHEN  meduc < 9 THEN meduc\n",
    "            ELSE NULL\n",
    "        END AS meduc,\n",
    "        -- paternal education\n",
    "        CASE\n",
    "            WHEN  feduc < 9 THEN feduc\n",
    "            ELSE NULL\n",
    "        END AS feduc,\n",
    "        -- maternal race\n",
    "        CASE\n",
    "            WHEN  mrace6 < 7 THEN mrace6\n",
    "            ELSE NULL\n",
    "        END AS mrace6,\n",
    "        -- paternal race\n",
    "        CASE\n",
    "            WHEN  frace6 < 7 THEN frace6\n",
    "            ELSE NULL\n",
    "        END AS frace6,\n",
    "        -- maternal hispanic origin\n",
    "        CASE\n",
    "            WHEN  mhisp_r < 6 THEN mhisp_r\n",
    "            ELSE NULL\n",
    "        END AS mhisp_r,\n",
    "        -- paternal hispanic origin\n",
    "        CASE\n",
    "            WHEN  fhisp_r < 6 THEN fhisp_r\n",
    "            ELSE NULL\n",
    "        END AS fhisp_r,\n",
    "        -- payment source recode\n",
    "        CASE\n",
    "            WHEN  pay_rec < 5 THEN pay_rec\n",
    "            ELSE NULL\n",
    "        END AS pay_rec,\n",
    "        -- supplemental nutrition program for women, infants, and children\n",
    "        CASE\n",
    "            WHEN wic = 'Y' THEN 1::UTINYINT\n",
    "            WHEN wic = 'N' THEN 0::UTINYINT\n",
    "            ELSE NULL\n",
    "        END AS wic\n",
    "    FROM\n",
    "        us_births\n",
    "    WHERE year >= 2009\n",
    "    ORDER BY\n",
    "        year, dob_mm\n",
    "    \"\"\"\n",
    ").df()\n",
    "df"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df.dtypes",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Missing values"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df.isna().mean().sort_values(ascending=False)",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df.columns",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "features = [\n",
    "    \"year\", \"mage_c\", \"fagecomb\", \"pwgt_r\",\n",
    "    \"dwgt_r\", \"wtgain\", \"rf_ppterm\", \"rf_fedrg\", \"rf_artec\",\n",
    "    \"no_risks\", \"ld_indl\", \"me_pres\", \"dmeth_rec\",\n",
    "    \"sex\", \"ca_disor\", \"ca_cchd\", \"ca_cdh\", \"ca_omph\",\n",
    "    \"bmi\", \"meduc\", \"feduc\", \"mrace6\", \"frace6\",\n",
    "    \"mhisp_r\", \"fhisp_r\", \"pay_rec\", \"wic\"\n",
    "]\n",
    "\n",
    "X = df[features]\n",
    "y = df[\"ca_down_c_or_p\"]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.1,\n",
    "    random_state=RANDOM_SEED,\n",
    "    stratify=y\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from lightgbm import early_stopping, log_evaluation\n",
    "\n",
    "categorical = [\n",
    "    \"rf_ppterm\", \"rf_fedrg\", \"rf_artec\",\n",
    "    \"no_risks\", \"ld_indl\", \"me_pres\", \"dmeth_rec\",\n",
    "    \"sex\", \"ca_disor\", \"ca_cchd\", \"ca_cdh\", \"ca_omph\",\n",
    "    \"meduc\", \"feduc\", \"mrace6\", \"frace6\",\n",
    "    \"mhisp_r\", \"fhisp_r\", \"pay_rec\", \"wic\"\n",
    "]\n",
    "\n",
    "numeric = [\n",
    "    \"year\", \"mage_c\", \"fagecomb\", \"pwgt_r\", \"dwgt_r\", \"wtgain\", \"bmi\"\n",
    "]\n",
    "\n",
    "train_data = lgb.Dataset(\n",
    "    X_train,\n",
    "    label=y_train,\n",
    "    categorical_feature=categorical,\n",
    "    free_raw_data=False\n",
    ")\n",
    "\n",
    "valid_data = lgb.Dataset(\n",
    "    X_valid,\n",
    "    label=y_valid,\n",
    "    categorical_feature=categorical,\n",
    "    reference=train_data,\n",
    "    free_raw_data=False\n",
    ")\n",
    "\n",
    "neg_count = (y_train == 0).count()\n",
    "pos_count = (y_train == 1).count()\n",
    "scale_pos_weight = np.sqrt(neg_count / pos_count)\n",
    "\n",
    "params = {\n",
    "    # Core\n",
    "    \"objective\": \"binary\",\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    \"data_sample_strategy\": \"goss\",\n",
    "    \"top_rate\": 0.1,\n",
    "    \"other_rate\": 0.05,\n",
    "    \"learning_rate\": 0.05,\n",
    "\n",
    "    # tree complexity\n",
    "    \"num_leaves\": 4096,\n",
    "    \"max_depth\": 12,\n",
    "    \"min_data_in_leaf\": 5000,\n",
    "    \"max_bin\": 255,\n",
    "\n",
    "    # subsampling for variance reduction\n",
    "    \"feature_fraction\": 0.7,\n",
    "\n",
    "    # Weight regularisation\n",
    "    \"lambda_l1\": 0.0,\n",
    "    \"lambda_l2\": 5.0,\n",
    "\n",
    "    # Splitting threshold\n",
    "    \"min_gain_to_split\": 0.0,\n",
    "\n",
    "    # Imbalance handling\n",
    "    \"scale_pos_weight\": scale_pos_weight,\n",
    "\n",
    "    # categorical one-hot encoding\n",
    "    \"force_col_wise\": True,\n",
    "    \"max_cat_threshold\": 64,\n",
    "    \"max_cat_to_onehot\": 32,\n",
    "\n",
    "    # Metrics and infrastructure\n",
    "    \"metric\": [\"average_precision\", \"auc\"],\n",
    "    \"num_threads\": 22, #14,\n",
    "    \"verbose\": 1,\n",
    "}\n",
    "\n",
    "\n",
    "gbm = lgb.train(\n",
    "    params,\n",
    "    train_data,\n",
    "    num_boost_round=2000,\n",
    "    valid_sets=[train_data, valid_data],\n",
    "    valid_names=[\"train\", \"valid\"],\n",
    "    callbacks=[\n",
    "        early_stopping(stopping_rounds=50),\n",
    "        log_evaluation(period=5)\n",
    "    ]\n",
    ")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from datetime import datetime\n",
    "gbm.save_model(f\"./output/features_model_{datetime.now().strftime(\"%Y%m%d%H%M\")}.txt\", num_iteration=gbm.best_iteration)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "\n",
    "y_valid_pred_proba = gbm.predict(X_valid, num_iteration=gbm.best_iteration)\n",
    "\n",
    "auc = roc_auc_score(y_valid, y_valid_pred_proba)\n",
    "aupr = average_precision_score(y_valid, y_valid_pred_proba)\n",
    "\n",
    "print(f\"Validation AUC:  {auc:.4f}\")\n",
    "print(f\"Validation AUPRC:{aupr:.4f}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "lr_age = LogisticRegression(max_iter=1000)\n",
    "lr_age.fit(X_train[[\"mage_c\"]], y_train)\n",
    "p_age = lr_age.predict_proba(X_valid[[\"mage_c\"]])[:, 1]\n",
    "print(\"AUC (age only):\", roc_auc_score(y_valid, p_age))\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "importance_gain = gbm.feature_importance(importance_type=\"gain\")\n",
    "\n",
    "df_imp_gain = pd.DataFrame({\n",
    "    \"feature\": features,\n",
    "    \"importance_gain\": importance_gain\n",
    "}).sort_values(\"importance_gain\", ascending=False)\n",
    "\n",
    "df_imp_gain.to_csv(f\"./output/importance_gain_{datetime.now().strftime(\"%Y%m%d%H%M\")}.csv\", index=False)\n",
    "\n",
    "df_imp_gain"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "pos_idx = y_valid[y_valid == 1].index\n",
    "neg_idx = y_valid[y_valid == 0].index\n",
    "\n",
    "n_pos_eval = min(10_000, len(pos_idx))\n",
    "n_neg_eval = min(10 * n_pos_eval, len(neg_idx))  # 10:1 negatives:positives\n",
    "\n",
    "rng = np.random.default_rng(123)\n",
    "\n",
    "pos_sample = rng.choice(pos_idx, size=n_pos_eval, replace=False)\n",
    "neg_sample = rng.choice(neg_idx, size=n_neg_eval, replace=False)\n",
    "\n",
    "eval_idx = np.concatenate([pos_sample, neg_sample])\n",
    "eval_idx = rng.permutation(eval_idx)  # shuffle\n",
    "\n",
    "X_eval = X_valid.loc[eval_idx]\n",
    "y_eval = y_valid.loc[eval_idx]\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import average_precision_score, roc_auc_score\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "def ap_scorer(estimator, X, y):\n",
    "    proba = estimator.predict_proba(X)[:, 1]\n",
    "    return average_precision_score(y, proba)\n",
    "\n",
    "class LGBMWrapper:\n",
    "    def __init__(self, booster):\n",
    "        self.booster = booster\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # Required by sklearn API; we don't actually train here.\n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        # LightGBM Booster.predict gives P(y=1) for binary by default\n",
    "        p1 = self.booster.predict(X)\n",
    "        p0 = 1.0 - p1\n",
    "        return np.column_stack([p0, p1])\n",
    "\n",
    "    def predict(self, X):\n",
    "        p1 = self.booster.predict(X)\n",
    "        return (p1 >= 0.5).astype(int)\n",
    "\n",
    "model_wrapped = LGBMWrapper(gbm)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "result = permutation_importance(\n",
    "    model_wrapped,\n",
    "    X_eval,\n",
    "    y_eval,\n",
    "    scoring=ap_scorer,\n",
    "    n_repeats=5,       # small but OK given size\n",
    "    n_jobs=4,          # adjust for your machine\n",
    "    random_state=RANDOM_SEED,\n",
    ")\n",
    "\n",
    "perm_importance = pd.DataFrame({\n",
    "    \"feature\": X_eval.columns,\n",
    "    \"importance_mean\": result.importances_mean,\n",
    "    \"importance_std\": result.importances_std,\n",
    "}).sort_values(\"importance_mean\", ascending=False)\n",
    "\n",
    "perm_importance.to_csv(f\"./output/permutation_importance_{datetime.now().strftime(\"%Y%m%d%H%M\")}.csv\", index=False)\n",
    "perm_importance"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# e.g. take all positives from X_eval and match them 1:2 with negatives\n",
    "pos_eval_idx = y_eval[y_eval == 1].index\n",
    "neg_eval_idx = y_eval[y_eval == 0].index\n",
    "\n",
    "n_pos_shap = min(5_000, len(pos_eval_idx))\n",
    "n_neg_shap = min(2 * n_pos_shap, len(neg_eval_idx))  # 2:1 neg:pos\n",
    "\n",
    "pos_shap = rng.choice(pos_eval_idx, size=n_pos_shap, replace=False)\n",
    "neg_shap = rng.choice(neg_eval_idx, size=n_neg_shap, replace=False)\n",
    "\n",
    "shap_idx = np.concatenate([pos_shap, neg_shap])\n",
    "shap_idx = rng.permutation(shap_idx)\n",
    "\n",
    "X_shap = X_eval.loc[shap_idx]\n",
    "y_shap = y_eval.loc[shap_idx]\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import shap\n",
    "\n",
    "# Tell SHAP this is a LightGBM model\n",
    "explainer = shap.TreeExplainer(gbm)\n",
    "explanation = explainer(X_shap)\n",
    "shap_values = explanation.values\n",
    "\n",
    "# Handle both cases: list or array\n",
    "if isinstance(shap_values, list):\n",
    "    shap_pos = shap_values[1]  # SHAP values for positive class\n",
    "else:\n",
    "    shap_pos = shap_values     # already positive class\n",
    "\n",
    "# Global importance: mean |SHAP|\n",
    "shap_importance = pd.DataFrame({\n",
    "    \"feature\": X_shap.columns,\n",
    "    \"mean_abs_shap\": np.mean(np.abs(shap_pos), axis=0),\n",
    "}).sort_values(\"mean_abs_shap\", ascending=False)\n",
    "\n",
    "shap_importance.to_csv(f\"./output/shap_importance_{datetime.now().strftime(\"%Y%m%d%H%M\")}.csv\", index=False)\n",
    "\n",
    "shap_importance\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "rng = np.random.default_rng(RANDOM_SEED)\n",
    "shap.summary_plot(shap_values, X_shap, rng=rng)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "X_shap_fp = X_shap.astype(\"float32\")\n",
    "for name in X_shap_fp.columns:\n",
    "    print(f\"\\nFeature: {name}\")\n",
    "    shap.dependence_plot(name, shap_values, X_shap_fp)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "#con.close()",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-stats-models-ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
