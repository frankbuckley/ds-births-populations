{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Notes - Features"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import duckdb\n",
    "import os\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from variables import Variables as vars\n",
    "\n",
    "plt.style.use(\"../../notebook.mplstyle\")\n",
    "\n",
    "os.makedirs(\"./output\", exist_ok=True)\n",
    "\n",
    "RANDOM_SEED = 1673025012\n",
    "np.random.seed(RANDOM_SEED)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "con = duckdb.connect(\"./data/us_births.db\", read_only=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df = con.execute(\n",
    "    \"\"\"\n",
    "    SELECT\n",
    "        year,\n",
    "        CASE\n",
    "            WHEN COALESCE (ca_down, ca_downs) = 'C' THEN 1\n",
    "            WHEN COALESCE (ca_down, ca_downs) = 'P' THEN 1\n",
    "            ELSE 0\n",
    "        END\n",
    "        AS ca_down_c_or_p,\n",
    "        COALESCE(f_ca_down, f_ca_downs) AS f_ca_down_c,\n",
    "        CASE\n",
    "            WHEN sex = 'M' THEN 1\n",
    "            WHEN sex = 'F' THEN 0\n",
    "            ELSE NULL\n",
    "        END AS sex,\n",
    "        CASE\n",
    "            WHEN dwgt_r >= 100 AND dwgt_r <= 400 THEN dwgt_r\n",
    "            ELSE NULL\n",
    "        END AS dwgt_r,\n",
    "        CASE\n",
    "            WHEN ca_disor = 'C' THEN 1\n",
    "            WHEN ca_disor = 'P' THEN 2\n",
    "            WHEN ca_disor = 'N' THEN 0\n",
    "            ELSE NULL\n",
    "        END\n",
    "        AS ca_disor,\n",
    "        CASE\n",
    "            WHEN ca_cchd = 'Y' THEN 1\n",
    "            WHEN ca_cchd = 'N' THEN 0\n",
    "            ELSE NULL\n",
    "        END AS ca_cchd,\n",
    "        mage_c,\n",
    "        CASE\n",
    "            WHEN bmi >= 13.0 AND bmi < 69.9 THEN bmi\n",
    "            ELSE NULL\n",
    "        END\n",
    "        AS bmi,\n",
    "        CASE\n",
    "            WHEN  meduc < 9 THEN meduc\n",
    "            ELSE NULL\n",
    "        END AS meduc,\n",
    "        CASE\n",
    "            WHEN  feduc < 9 THEN feduc\n",
    "            ELSE NULL\n",
    "        END AS feduc,\n",
    "        CASE\n",
    "            WHEN  mrace6 < 7 THEN mrace6\n",
    "            ELSE NULL\n",
    "        END AS mrace6,\n",
    "        CASE\n",
    "            WHEN  frace6 < 7 THEN frace6\n",
    "            ELSE NULL\n",
    "        END AS frace6,\n",
    "        CASE\n",
    "            WHEN  mhisp_r < 6 THEN mhisp_r\n",
    "            ELSE NULL\n",
    "        END AS mhisp_r,\n",
    "        CASE\n",
    "            WHEN  fhisp_r < 6 THEN fhisp_r\n",
    "            ELSE NULL\n",
    "        END AS fhisp_r,\n",
    "        CASE\n",
    "            WHEN  pay_rec < 5 THEN pay_rec\n",
    "            ELSE NULL\n",
    "        END AS pay_rec\n",
    "    FROM\n",
    "        us_births\n",
    "    WHERE year >= 2018\n",
    "    ORDER BY\n",
    "        year, dob_mm\n",
    "    \"\"\"\n",
    ").df()\n",
    "df"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df.dtypes"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df[\"ca_down_c_or_p\"] = df[\"ca_down_c_or_p\"].astype(\"UInt8\")\n",
    "df[\"sex\"] = df[\"sex\"].astype(\"UInt8\")\n",
    "df[\"ca_disor\"] = df[\"ca_disor\"].astype(\"UInt8\")\n",
    "df[\"ca_cchd\"] = df[\"ca_cchd\"].astype(\"UInt8\")\n",
    "\n",
    "# todo: check types now updated in duckdb - probably on longer need this\n",
    "\n",
    "df[\"dwgt_r\"] = df[\"dwgt_r\"].astype(\"UInt16\")\n",
    "df[\"mage_c\"] = df[\"mage_c\"].astype(\"UInt16\")\n",
    "df[\"bmi\"] = df[\"bmi\"].astype(\"Float32\")\n",
    "df[\"meduc\"] = df[\"meduc\"].astype(\"UInt8\")\n",
    "df[\"feduc\"] = df[\"feduc\"].astype(\"UInt8\")\n",
    "df[\"mrace6\"] = df[\"mrace6\"].astype(\"UInt8\")\n",
    "df[\"frace6\"] = df[\"frace6\"].astype(\"UInt8\")\n",
    "df[\"mhisp_r\"] = df[\"mhisp_r\"].astype(\"UInt8\")\n",
    "df[\"fhisp_r\"] = df[\"fhisp_r\"].astype(\"UInt8\")\n",
    "df[\"pay_rec\"] = df[\"pay_rec\"].astype(\"UInt8\")\n",
    "df.dtypes"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Missing values"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df.isna().mean().sort_values(ascending=False)",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df.columns",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "features = [\n",
    "    \"year\", \"f_ca_down_c\", \"sex\", \"dwgt_r\", \"ca_disor\", \"ca_cchd\",\n",
    "    \"mage_c\", \"bmi\", \"meduc\", \"feduc\", \"mrace6\", \"frace6\", \"mhisp_r\",\n",
    "    \"fhisp_r\", \"pay_rec\"\n",
    "]\n",
    "\n",
    "X = df[features]\n",
    "y = df[\"ca_down_c_or_p\"]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.1,\n",
    "    random_state=RANDOM_SEED,\n",
    "    stratify=y\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from lightgbm import early_stopping, log_evaluation\n",
    "\n",
    "categorical = [\n",
    "    \"f_ca_down_c\", \"sex\", \"ca_disor\", \"ca_cchd\",\n",
    "    \"meduc\", \"feduc\", \"mrace6\", \"frace6\", \"mhisp_r\",\n",
    "    \"fhisp_r\", \"pay_rec\"\n",
    "]\n",
    "\n",
    "numeric = [ \"year\", \"dwgt_r\", \"mage_c\", \"bmi\" ]\n",
    "\n",
    "train_data = lgb.Dataset(\n",
    "    X_train,\n",
    "    label=y_train,\n",
    "    categorical_feature=categorical,\n",
    "    free_raw_data=False\n",
    ")\n",
    "\n",
    "valid_data = lgb.Dataset(\n",
    "    X_valid,\n",
    "    label=y_valid,\n",
    "    categorical_feature=categorical,\n",
    "    reference=train_data,\n",
    "    free_raw_data=False\n",
    ")\n",
    "\n",
    "# Rough imbalance handling\n",
    "pos_rate = y_train.mean()\n",
    "scale_pos_weight = (1 - pos_rate) / pos_rate # negative/positive ratio\n",
    "\n",
    "params = {\n",
    "    # Core\n",
    "    \"objective\": \"binary\",\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    \"learning_rate\": 0.03,\n",
    "\n",
    "    # Tree complexity (moderate) + strong regularisation via leaf size\n",
    "    \"num_leaves\": 31,\n",
    "    \"max_depth\": -1,\n",
    "    \"min_data_in_leaf\": 8000,\n",
    "    \"max_bin\": 128,\n",
    "\n",
    "    # Subsampling for variance reduction\n",
    "    \"feature_fraction\": 0.7,\n",
    "    \"bagging_fraction\": 0.7,\n",
    "    \"bagging_freq\": 1,\n",
    "\n",
    "    # Weight regularisation\n",
    "    \"lambda_l1\": 0.0,\n",
    "    \"lambda_l2\": 5.0,\n",
    "\n",
    "    # Splitting threshold\n",
    "    \"min_gain_to_split\": 0.0,\n",
    "\n",
    "    # Imbalance handling\n",
    "    \"scale_pos_weight\": scale_pos_weight * 0.1,\n",
    "\n",
    "    # Metrics and infrastructure\n",
    "    \"metric\": [\"average_precision\", \"auc\"],\n",
    "    \"num_threads\": 14,\n",
    "    \"verbose\": 1,\n",
    "}\n",
    "\n",
    "\n",
    "gbm = lgb.train(\n",
    "    params,\n",
    "    train_data,\n",
    "    num_boost_round=200,\n",
    "    valid_sets=[train_data, valid_data],\n",
    "    valid_names=[\"train\", \"valid\"],\n",
    "    callbacks=[\n",
    "        early_stopping(stopping_rounds=20),\n",
    "        log_evaluation(period=5)\n",
    "    ]\n",
    ")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "from datetime import datetime\n",
    "gbm.save_model(f\"./output/features_model_{datetime.now().strftime(\"%Y%m%d%H%M\")}.txt\", num_iteration=gbm.best_iteration)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "\n",
    "y_valid_pred_proba = gbm.predict(X_valid, num_iteration=gbm.best_iteration)\n",
    "\n",
    "auc = roc_auc_score(y_valid, y_valid_pred_proba)\n",
    "aupr = average_precision_score(y_valid, y_valid_pred_proba)\n",
    "\n",
    "print(f\"Validation AUC:  {auc:.4f}\")\n",
    "print(f\"Validation AUPRC:{aupr:.4f}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "lr_age = LogisticRegression(max_iter=1000)\n",
    "lr_age.fit(X_train[[\"mage_c\"]], y_train)\n",
    "p_age = lr_age.predict_proba(X_valid[[\"mage_c\"]])[:, 1]\n",
    "print(\"AUC (age only):\", roc_auc_score(y_valid, p_age))\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "importance_gain = gbm.feature_importance(importance_type=\"gain\")\n",
    "\n",
    "df_imp_gain = pd.DataFrame({\n",
    "    \"feature\": features,\n",
    "    \"importance_gain\": importance_gain\n",
    "}).sort_values(\"importance_gain\", ascending=False)\n",
    "\n",
    "df_imp_gain\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "pos_idx = y_valid[y_valid == 1].index\n",
    "neg_idx = y_valid[y_valid == 0].index\n",
    "\n",
    "n_pos_eval = min(10_000, len(pos_idx))\n",
    "n_neg_eval = min(10 * n_pos_eval, len(neg_idx))  # 10:1 negatives:positives\n",
    "\n",
    "rng = np.random.default_rng(123)\n",
    "\n",
    "pos_sample = rng.choice(pos_idx, size=n_pos_eval, replace=False)\n",
    "neg_sample = rng.choice(neg_idx, size=n_neg_eval, replace=False)\n",
    "\n",
    "eval_idx = np.concatenate([pos_sample, neg_sample])\n",
    "eval_idx = rng.permutation(eval_idx)  # shuffle\n",
    "\n",
    "X_eval = X_valid.loc[eval_idx]\n",
    "y_eval = y_valid.loc[eval_idx]\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import average_precision_score, roc_auc_score\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "def ap_scorer(estimator, X, y):\n",
    "    proba = estimator.predict_proba(X)[:, 1]\n",
    "    return average_precision_score(y, proba)\n",
    "\n",
    "\n",
    "\n",
    "class LGBMWrapper:\n",
    "    def __init__(self, booster):\n",
    "        self.booster = booster\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # Required by sklearn API; we don't actually train here.\n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        # LightGBM Booster.predict gives P(y=1) for binary by default\n",
    "        p1 = self.booster.predict(X)\n",
    "        p0 = 1.0 - p1\n",
    "        return np.column_stack([p0, p1])\n",
    "\n",
    "    def predict(self, X):\n",
    "        p1 = self.booster.predict(X)\n",
    "        return (p1 >= 0.5).astype(int)\n",
    "\n",
    "model_wrapped = LGBMWrapper(gbm)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "result = permutation_importance(\n",
    "    model_wrapped,\n",
    "    X_eval,\n",
    "    y_eval,\n",
    "    scoring=ap_scorer,\n",
    "    n_repeats=5,       # small but OK given size\n",
    "    n_jobs=4,          # adjust for your machine\n",
    "    random_state=RANDOM_SEED,\n",
    ")\n",
    "\n",
    "perm_importance = pd.DataFrame({\n",
    "    \"feature\": X_eval.columns,\n",
    "    \"importance_mean\": result.importances_mean,\n",
    "    \"importance_std\": result.importances_std,\n",
    "}).sort_values(\"importance_mean\", ascending=False)\n",
    "\n",
    "perm_importance"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# e.g. take all positives from X_eval and match them 1:2 with negatives\n",
    "pos_eval_idx = y_eval[y_eval == 1].index\n",
    "neg_eval_idx = y_eval[y_eval == 0].index\n",
    "\n",
    "n_pos_shap = min(5_000, len(pos_eval_idx))\n",
    "n_neg_shap = min(2 * n_pos_shap, len(neg_eval_idx))  # 2:1 neg:pos\n",
    "\n",
    "pos_shap = rng.choice(pos_eval_idx, size=n_pos_shap, replace=False)\n",
    "neg_shap = rng.choice(neg_eval_idx, size=n_neg_shap, replace=False)\n",
    "\n",
    "shap_idx = np.concatenate([pos_shap, neg_shap])\n",
    "shap_idx = rng.permutation(shap_idx)\n",
    "\n",
    "X_shap = X_eval.loc[shap_idx]\n",
    "y_shap = y_eval.loc[shap_idx]\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import shap\n",
    "\n",
    "# Tell SHAP this is a LightGBM model\n",
    "explainer = shap.TreeExplainer(gbm)\n",
    "explanation = explainer(X_shap)\n",
    "shap_values = explanation.values\n",
    "\n",
    "# Handle both cases: list or array\n",
    "if isinstance(shap_values, list):\n",
    "    shap_pos = shap_values[1]  # SHAP values for positive class\n",
    "else:\n",
    "    shap_pos = shap_values     # already positive class\n",
    "\n",
    "# Global importance: mean |SHAP|\n",
    "shap_importance = pd.DataFrame({\n",
    "    \"feature\": X_shap.columns,\n",
    "    \"mean_abs_shap\": np.mean(np.abs(shap_pos), axis=0),\n",
    "}).sort_values(\"mean_abs_shap\", ascending=False)\n",
    "\n",
    "shap_importance\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "rng = np.random.default_rng(RANDOM_SEED)\n",
    "shap.summary_plot(shap_values, X_shap, rng=rng)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "X_shap_fp = X_shap.astype(\"float32\")\n",
    "for name in X_shap_fp.columns:\n",
    "    print(f\"\\nFeature: {name}\")\n",
    "    shap.dependence_plot(name, shap_values, X_shap_fp)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "shap.plots.scatter(shap_values[:, \"mage_c\"])",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "shap.plots.scatter(sv[:, \"mage_c\"], color=sv[:, \"ca_cchd\"])",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "con.close()",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-stats-models-ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
